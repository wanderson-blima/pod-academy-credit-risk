{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Instalacao de pacote para uso de Target/CountEncoder\n",
    "!pip install category-encoders==2.6.3"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure\n",
    "\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.driver.maxResultSize\": \"8g\",\n",
    "        \"spark.driver.memory\": \"54g\",\n",
    "        \"spark.driver.cores\": 8,\n",
    "        \"spark.executor.instances\": 0,\n",
    "        \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "        \"spark.sql.execution.arrow.pyspark.selfDestruct.enabled\": \"true\"\n",
    "    }\n",
    "}"
   ],
   "id": "v5_configure"
  },
  {
   "cell_type": "markdown",
   "id": "3zqt26b18e6",
   "source": [
    "# Modelo Baseline de Risco - Telecom (v5 - LGBM + SHAP + Swap Analysis Corrigido)\n",
    "\n",
    "Este notebook implementa o **modelo otimizado de risco de inadimplencia (FPD)** para clientes Claro.\n",
    "\n",
    "### Evolucao\n",
    "- **v1**: PySpark para limpeza + Pandas para modelagem (original)\n",
    "- **v2**: Python puro com `deltalake` (delta-rs) - falha no Fabric\n",
    "- **v3**: Spark read + Pandas modeling, RL + LGBM + KS Incremental + SHAP\n",
    "- **v4**: Versao otimizada - apenas LGBM, SHAP feature selection, sem KS Incremental\n",
    "- **v5 (este)**: Swap analysis corrigido (modelo vs FPD real) + visualizacoes avancadas\n",
    "\n",
    "### Correcao Swap Analysis (v5 vs v4)\n",
    "- **v4 (bug)**: Comparava populacoes DIFERENTES (OOT1 vs OOT2) por indice de linha → swap-in = swap-out sempre\n",
    "- **v5 (correto)**: Compara ranking do MODELO vs FPD REAL na MESMA populacao\n",
    "  - **Swap-in**: Clientes no top X% do modelo que NAO sao maus reais (falsos alarmes)\n",
    "  - **Swap-out**: Maus reais que o modelo NAO captura no top X% (escapados)\n",
    "  - **Overlap**: Acertos — maus reais capturados pelo modelo\n",
    "\n",
    "### Principais etapas\n",
    "1. Leitura do Gold Feature Store via `spark.read.format(\"delta\")`\n",
    "2. Limpeza de dados (missing, correlacao, leakage)\n",
    "3. Split temporal: Treino (202410-202412), Val (202501), OOS (75%), OOT (202502-202503)\n",
    "4. Amostragem estratificada 25% por (SAFRA, FPD)\n",
    "5. GridSearch LGBM + Treino final\n",
    "6. Avaliacao baseline (AUC, KS por safra)\n",
    "7. Feature selection SHAP TreeExplainer (90% cumulative)\n",
    "8. Modelo final LGBM com features selecionadas\n",
    "9. **Swap analysis correto (modelo vs FPD real)**\n",
    "10. **Analise por decis + Capture Rate + PSI**\n",
    "11. **16 visualizacoes avancadas (salvas em lakehouse + MLflow)**\n",
    "12. Export via MLflow Registry"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "sd5hk9kuodh",
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTS E CONFIGURACAO\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "import shap\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType, DoubleType, LongType\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_recall_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "from category_encoders import CountEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FIX: sklearn >= 1.6 renamed force_all_finite -> ensure_all_finite\n",
    "# LightGBM sklearn wrapper still uses old name, causing TypeError on predict_proba\n",
    "import lightgbm.sklearn as _lgbm_sklearn\n",
    "_orig_check = _lgbm_sklearn._LGBMCheckArray\n",
    "def _patched_lgbm_check(*args, **kwargs):\n",
    "    kwargs.pop('force_all_finite', None)\n",
    "    kwargs.pop('ensure_all_finite', None)\n",
    "    return _orig_check(*args, **kwargs)\n",
    "_lgbm_sklearn._LGBMCheckArray = _patched_lgbm_check\n",
    "\n",
    "# Config centralizado do pipeline\n",
    "import sys; sys.path.insert(0, '/lakehouse/default/Files/projeto-final')\n",
    "from config.pipeline_config import (\n",
    "    PATH_FEATURE_STORE, EXPERIMENT_NAME, SAFRAS,\n",
    "    LEAKAGE_BLACKLIST, TARGET_COLUMNS\n",
    ")\n",
    "\n",
    "# ---- CONSTANTES V5 ----\n",
    "OUTPUT_DIR_V5 = \"/lakehouse/default/Files/projeto-final/docs/analytics/v5\"\n",
    "os.makedirs(OUTPUT_DIR_V5, exist_ok=True)\n",
    "DPI = 150\n",
    "SWAP_CUTOFFS = [0.05, 0.10, 0.20, 0.30]\n",
    "\n",
    "COLORS = {\n",
    "    \"blue\": \"#2196F3\", \"orange\": \"#FF9800\", \"green\": \"#4CAF50\",\n",
    "    \"red\": \"#F44336\", \"purple\": \"#9C27B0\", \"gray\": \"#607D8B\"\n",
    "}\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette([COLORS[\"blue\"], COLORS[\"orange\"], COLORS[\"green\"], COLORS[\"red\"]])\n",
    "\n",
    "print('Imports OK — v5 (LGBM + SHAP + Swap Corrigido + check_array patched)')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jki9qb3jws",
   "source": [
    "# =============================================================================\n",
    "# 2. MLFLOW SETUP\n",
    "# =============================================================================\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.autolog(disable=True)  # Controle manual para evitar conflitos\n",
    "\n",
    "print(f'MLflow experiment: {EXPERIMENT_NAME}')\n",
    "print(f'Tracking URI: {mlflow.get_tracking_uri()}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "s9wzzgub2sk",
   "source": [
    "# =============================================================================\n",
    "# 3. LEITURA OTIMIZADA DO GOLD FEATURE STORE (Spark -> Pandas)\n",
    "# =============================================================================\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.selfDestruct.enabled\", \"true\")\n",
    "\n",
    "print(f'Lendo feature store de: {PATH_FEATURE_STORE}\\n')\n",
    "\n",
    "df_spark = spark.read.format(\"delta\").load(PATH_FEATURE_STORE)\n",
    "n_original = df_spark.count()\n",
    "print(f'Original: {n_original:,} rows x {len(df_spark.columns)} cols')\n",
    "\n",
    "# Drop colunas audit + leakage no Spark\n",
    "cols_audit = ['_execution_id', '_data_inclusao', '_data_alteracao_silver', 'DT_PROCESSAMENTO']\n",
    "cols_drop = [c for c in cols_audit + LEAKAGE_BLACKLIST if c in df_spark.columns]\n",
    "if cols_drop:\n",
    "    df_spark = df_spark.drop(*cols_drop)\n",
    "    print(f'Drop {len(cols_drop)} colunas (audit+leakage): {cols_drop}')\n",
    "\n",
    "# Filtrar FLAG_INSTALACAO == 1 no Spark\n",
    "n_reprovados = 0\n",
    "if 'FLAG_INSTALACAO' in df_spark.columns:\n",
    "    n_reprovados = df_spark.filter(F.col('FLAG_INSTALACAO') == 0).count()\n",
    "    df_spark = df_spark.filter(F.col('FLAG_INSTALACAO') == 1).drop('FLAG_INSTALACAO')\n",
    "    n_pos = n_original - n_reprovados\n",
    "    print(f'FLAG_INSTALACAO: {n_original:,} -> {n_pos:,} ({n_reprovados:,} reprovados removidos)')\n",
    "else:\n",
    "    n_pos = n_original\n",
    "\n",
    "# Cast tipos via .select() (plano flat)\n",
    "cast_exprs = []\n",
    "n_double, n_long = 0, 0\n",
    "for field in df_spark.schema.fields:\n",
    "    if isinstance(field.dataType, DoubleType):\n",
    "        cast_exprs.append(F.col(field.name).cast(FloatType()).alias(field.name))\n",
    "        n_double += 1\n",
    "    elif isinstance(field.dataType, LongType):\n",
    "        cast_exprs.append(F.col(field.name).cast(IntegerType()).alias(field.name))\n",
    "        n_long += 1\n",
    "    else:\n",
    "        cast_exprs.append(F.col(field.name))\n",
    "df_spark = df_spark.select(*cast_exprs)\n",
    "print(f'Cast tipos: {n_double} Double->Float, {n_long} Long->Int')\n",
    "\n",
    "# Conversao chunked por SAFRA\n",
    "safras_disponiveis = sorted([row.SAFRA for row in df_spark.select('SAFRA').distinct().collect()])\n",
    "print(f'\\nSAFRAs: {safras_disponiveis} | Colunas: {len(df_spark.columns)}')\n",
    "print('Convertendo por SAFRA...')\n",
    "\n",
    "chunks = []\n",
    "for safra in safras_disponiveis:\n",
    "    chunk = df_spark.filter(F.col('SAFRA') == safra).toPandas()\n",
    "    mem_mb = chunk.memory_usage(deep=True).sum() / 1e6\n",
    "    print(f'  SAFRA {safra}: {len(chunk):,} rows | {mem_mb:.0f} MB')\n",
    "    chunks.append(chunk)\n",
    "    gc.collect()\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "del chunks\n",
    "gc.collect()\n",
    "\n",
    "print(f'\\nDataset carregado:')\n",
    "print(f'  Shape: {df.shape}')\n",
    "print(f'  Memory: {df.memory_usage(deep=True).sum() / 1e9:.2f} GB')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "se08nb6e8z",
   "source": [
    "## 4. Limpeza de Dados (Pandas puro)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "weqvtlbrwkf",
   "source": [
    "# =============================================================================\n",
    "# 4.1 FUNCOES DE LIMPEZA\n",
    "# =============================================================================\n",
    "\n",
    "def clean_empty_keys(df):\n",
    "    return df.dropna(subset=['NUM_CPF', 'SAFRA'])\n",
    "\n",
    "def convert_cep3_uf_regiao(df):\n",
    "    cep_map = {\n",
    "        '01':('SP','SUDESTE'),'02':('SP','SUDESTE'),'03':('SP','SUDESTE'),\n",
    "        '04':('SP','SUDESTE'),'05':('SP','SUDESTE'),'06':('SP','SUDESTE'),\n",
    "        '07':('SP','SUDESTE'),'08':('SP','SUDESTE'),'09':('SP','SUDESTE'),\n",
    "        '20':('RJ','SUDESTE'),'21':('RJ','SUDESTE'),'22':('RJ','SUDESTE'),\n",
    "        '23':('RJ','SUDESTE'),'24':('RJ','SUDESTE'),'29':('ES','SUDESTE'),\n",
    "        '30':('MG','SUDESTE'),'31':('MG','SUDESTE'),'32':('MG','SUDESTE'),\n",
    "        '33':('MG','SUDESTE'),'34':('MG','SUDESTE'),'35':('MG','SUDESTE'),\n",
    "        '36':('MG','SUDESTE'),'37':('MG','SUDESTE'),'38':('MG','SUDESTE'),\n",
    "        '39':('MG','SUDESTE'),\n",
    "        '40':('BA','NORDESTE'),'41':('BA','NORDESTE'),'42':('BA','NORDESTE'),\n",
    "        '43':('BA','NORDESTE'),'44':('BA','NORDESTE'),'45':('BA','NORDESTE'),\n",
    "        '46':('BA','NORDESTE'),'47':('BA','NORDESTE'),'48':('BA','NORDESTE'),\n",
    "        '49':('SE','NORDESTE'),\n",
    "        '50':('PE','NORDESTE'),'51':('PE','NORDESTE'),'52':('PE','NORDESTE'),\n",
    "        '53':('PE','NORDESTE'),'54':('PE','NORDESTE'),'55':('PE','NORDESTE'),\n",
    "        '56':('AL','NORDESTE'),'57':('AL','NORDESTE'),\n",
    "        '58':('PB','NORDESTE'),'59':('RN','NORDESTE'),\n",
    "        '60':('CE','NORDESTE'),'61':('CE','NORDESTE'),'62':('CE','NORDESTE'),\n",
    "        '63':('PI','NORDESTE'),'64':('PI','NORDESTE'),'65':('MA','NORDESTE'),\n",
    "        '66':('PA','NORTE'),'67':('PA','NORTE'),'68':('AC','NORTE'),\n",
    "        '69':('AM','NORTE'),'77':('TO','NORTE'),\n",
    "        '70':('DF','CENTRO-OESTE'),'71':('DF','CENTRO-OESTE'),\n",
    "        '72':('GO','CENTRO-OESTE'),'73':('GO','CENTRO-OESTE'),\n",
    "        '74':('GO','CENTRO-OESTE'),'75':('GO','CENTRO-OESTE'),\n",
    "        '76':('GO','CENTRO-OESTE'),\n",
    "        '78':('MT','CENTRO-OESTE'),'79':('MS','CENTRO-OESTE'),\n",
    "        '80':('PR','SUL'),'81':('PR','SUL'),'82':('PR','SUL'),\n",
    "        '83':('PR','SUL'),'84':('PR','SUL'),'85':('PR','SUL'),\n",
    "        '86':('PR','SUL'),'87':('PR','SUL'),\n",
    "        '88':('SC','SUL'),'89':('SC','SUL'),\n",
    "        '90':('RS','SUL'),'91':('RS','SUL'),'92':('RS','SUL'),\n",
    "        '93':('RS','SUL'),'94':('RS','SUL'),'95':('RS','SUL'),\n",
    "        '96':('RS','SUL'),'97':('RS','SUL'),'98':('RS','SUL'),'99':('RS','SUL'),\n",
    "    }\n",
    "    if 'CEP_3_digitos' not in df.columns:\n",
    "        return df\n",
    "    cep2 = df['CEP_3_digitos'].astype(str).str[:2]\n",
    "    mapped = cep2.map(cep_map)\n",
    "    df['UF'] = mapped.apply(lambda x: x[0] if isinstance(x, tuple) else 'OUTROS')\n",
    "    df['REGIAO'] = mapped.apply(lambda x: x[1] if isinstance(x, tuple) else 'OUTROS')\n",
    "    return df.drop(columns=['CEP_3_digitos'])\n",
    "\n",
    "def adjust_and_drop_date_cols(df):\n",
    "    if 'var_12' in df.columns:\n",
    "        df['var_12'] = pd.to_datetime(df['var_12'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['DATA_REF_SAFRA'] = pd.to_datetime(df['SAFRA'].astype(str), format='%Y%m')\n",
    "    if 'var_12' in df.columns:\n",
    "        df['DIAS_VAR_12'] = (df['DATA_REF_SAFRA'] - df['var_12']).dt.days\n",
    "    if 'PAG_DT_PRIMEIRA_FATURA' in df.columns:\n",
    "        df['PAG_DT_PRIMEIRA_FATURA'] = pd.to_datetime(df['PAG_DT_PRIMEIRA_FATURA'], errors='coerce')\n",
    "        df['PAG_DIAS_DESDE_PRIMEIRA_FATURA'] = (df['DATA_REF_SAFRA'] - df['PAG_DT_PRIMEIRA_FATURA']).dt.days\n",
    "    date_cols = df.select_dtypes(include=['datetime64', 'datetimetz']).columns.tolist()\n",
    "    date_cols.append('DATA_REF_SAFRA')\n",
    "    return df.drop(columns=[c for c in date_cols if c in df.columns])\n",
    "\n",
    "def remove_high_missing(df, threshold=0.75):\n",
    "    null_pct = df.isnull().mean()\n",
    "    cols_to_drop = null_pct[null_pct >= threshold].index.tolist()\n",
    "    print(f'  High missing (>= {threshold:.0%}): {len(cols_to_drop)} colunas removidas')\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "def remove_low_cardinality(df):\n",
    "    low_card = [c for c in df.columns if df[c].nunique() <= 1]\n",
    "    print(f'  Low cardinality (== 1): {len(low_card)} colunas removidas')\n",
    "    return df.drop(columns=low_card)\n",
    "\n",
    "def remove_high_correlation(df, threshold=0.8, safras_train=None):\n",
    "    if safras_train is not None:\n",
    "        df_corr_base = df[df['SAFRA'].isin(safras_train)]\n",
    "    else:\n",
    "        df_corr_base = df\n",
    "    df_sample = df_corr_base.groupby(['SAFRA', 'FPD'], group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=0.25, random_state=42))\n",
    "    num_cols = df_sample.select_dtypes(include=['int32','int64','float32','float64']).columns\n",
    "    num_cols = [c for c in num_cols if c != 'FPD']\n",
    "    corr_matrix = df_sample[num_cols].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = []\n",
    "    while True:\n",
    "        max_corr = upper.max().max()\n",
    "        if max_corr < threshold:\n",
    "            break\n",
    "        col_to_drop = upper.max().sort_values(ascending=False).index[0]\n",
    "        to_drop.append(col_to_drop)\n",
    "        upper = upper.drop(index=col_to_drop, columns=col_to_drop)\n",
    "    print(f'  High correlation (> {threshold}): {len(to_drop)} colunas removidas')\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "def remove_misused_columns(df):\n",
    "    misused = ['PROD', 'flag_mig2', 'FAT_VLR_FPD', 'FAT_FLAG_MIG2_AQUISICAO']\n",
    "    existing = [c for c in misused if c in df.columns]\n",
    "    if existing:\n",
    "        print(f'  Misused columns removed: {existing}')\n",
    "    return df.drop(columns=existing, errors='ignore')\n",
    "\n",
    "print('Funcoes de limpeza carregadas')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9mkyrxuuwwr",
   "source": [
    "# =============================================================================\n",
    "# 4.2 APLICAR LIMPEZAS\n",
    "# =============================================================================\n",
    "safras_train_val = SAFRAS[:4]\n",
    "\n",
    "print('Aplicando limpezas...')\n",
    "print(f'Shape original: {df.shape}')\n",
    "\n",
    "df = clean_empty_keys(df)\n",
    "df = convert_cep3_uf_regiao(df)\n",
    "df = adjust_and_drop_date_cols(df)\n",
    "df = remove_high_missing(df)\n",
    "df = remove_low_cardinality(df)\n",
    "df = remove_high_correlation(df, threshold=0.8, safras_train=safras_train_val)\n",
    "df = remove_misused_columns(df)\n",
    "\n",
    "print(f'Shape apos limpezas: {df.shape}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fojwgyia1wh",
   "source": [
    "## 5. Split Temporal e Amostragem Estratificada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "5keku9r8hff",
   "source": [
    "# =============================================================================\n",
    "# 5. SPLIT TEMPORAL + AMOSTRAGEM ESTRATIFICADA\n",
    "# =============================================================================\n",
    "safras_ord = sorted(df['SAFRA'].unique())\n",
    "safras_train_oos = safras_ord[:4]  # 202410-202501\n",
    "safras_oot = safras_ord[4:]        # 202502-202503\n",
    "\n",
    "df_4_safras = df[df['SAFRA'].isin(safras_train_oos)]\n",
    "df_oot_full = df[df['SAFRA'].isin(safras_oot)]\n",
    "\n",
    "# Amostragem estratificada 25%\n",
    "df_sample = df_4_safras.groupby(['SAFRA', 'FPD'], group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.25, random_state=42))\n",
    "df_oos = df_4_safras.drop(df_sample.index)\n",
    "\n",
    "df_sample = df_sample.reset_index(drop=True).drop_duplicates()\n",
    "df_oos = df_oos.reset_index(drop=True).drop_duplicates()\n",
    "df_oot = df_oot_full.reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "del df, df_4_safras, df_oot_full\n",
    "gc.collect()\n",
    "\n",
    "print(f'Sample (train+val): {df_sample.shape}')\n",
    "print(f'OOS:                {df_oos.shape}')\n",
    "print(f'OOT:                {df_oot.shape}')\n",
    "\n",
    "# Verificar volumetria\n",
    "for name, data in [('Sample', df_sample), ('OOS', df_oos), ('OOT', df_oot)]:\n",
    "    print(f'\\n--- {name} ---')\n",
    "    print(data[['SAFRA', 'FPD']].value_counts().sort_index().to_string())"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "omh1j3mr7ld",
   "source": [
    "# =============================================================================\n",
    "# 6. SEPARACAO TREINO / VALIDACAO / X / Y\n",
    "# =============================================================================\n",
    "safras_train = [202410, 202411, 202412]\n",
    "safras_val = [202501]\n",
    "\n",
    "df_train = df_sample[df_sample['SAFRA'].isin(safras_train)]\n",
    "df_val = df_sample[df_sample['SAFRA'].isin(safras_val)]\n",
    "\n",
    "X_train = df_train.drop(columns=['FPD'])\n",
    "y_train = df_train['FPD']\n",
    "X_val = df_val.drop(columns=['FPD'])\n",
    "y_val = df_val['FPD']\n",
    "\n",
    "X_train_final = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_train_final = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_oos_agg = df_oos.drop(columns=['FPD'])\n",
    "y_oos_agg = df_oos['FPD']\n",
    "X_oot_agg = df_oot.drop(columns=['FPD'])\n",
    "y_oot_agg = df_oot['FPD']\n",
    "\n",
    "# Variaveis numericas e categoricas\n",
    "num_features = [n for n in X_train.select_dtypes(include=['int32','int64','float32','float64']).columns if n != 'SAFRA']\n",
    "cat_features = [c for c in X_train.select_dtypes(include=['object','category']).columns if c != 'NUM_CPF']\n",
    "\n",
    "print(f'X_train_final: {X_train_final.shape}')\n",
    "print(f'X_oos: {X_oos_agg.shape}')\n",
    "print(f'X_oot: {X_oot_agg.shape}')\n",
    "print(f'Numericas: {len(num_features)} | Categoricas: {len(cat_features)}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8fp6feejakr",
   "source": [
    "## 7. Pipeline LGBM + GridSearch + Treino"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "c61t6f6kbf",
   "source": [
    "# =============================================================================\n",
    "# 7. PIPELINE + GRIDSEARCH + TREINO FINAL\n",
    "# =============================================================================\n",
    "numeric_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0)),\n",
    "])\n",
    "preprocess_lgbm = ColumnTransformer([\n",
    "    ('num', numeric_pipe, num_features),\n",
    "    ('cat', categorical_pipe, cat_features),\n",
    "], remainder='drop')\n",
    "\n",
    "pipeline_LGBM = Pipeline([\n",
    "    ('prep', preprocess_lgbm),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary', boosting_type='gbdt',\n",
    "        learning_rate=0.05, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1, verbosity=-1,\n",
    "    )),\n",
    "])\n",
    "\n",
    "# GridSearch\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "param_grid_LGBM = {\n",
    "    'model__n_estimators': [250, 500],\n",
    "    'model__max_depth': [4, 7],\n",
    "}\n",
    "grid_LGBM = GridSearchCV(\n",
    "    pipeline_LGBM, param_grid=param_grid_LGBM,\n",
    "    scoring='roc_auc', cv=cv, n_jobs=-1, verbose=3, error_score='raise',\n",
    ")\n",
    "grid_LGBM.fit(X_val, y_val)\n",
    "print(f'Melhores HP: {grid_LGBM.best_params_}')\n",
    "print(f'Melhor AUC:  {grid_LGBM.best_score_:.5f}')\n",
    "\n",
    "# Treino final com best params\n",
    "pipeline_LGBM.set_params(**grid_LGBM.best_params_)\n",
    "pipeline_LGBM.fit(X_train_final, y_train_final)\n",
    "print('LGBM treinado com train+val')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f3qv8hw05os",
   "source": [
    "# =============================================================================\n",
    "# 8. FUNCOES DE AVALIACAO + AVALIACAO BASELINE + MLFLOW\n",
    "# =============================================================================\n",
    "\n",
    "def ks_stat(y_true, y_score):\n",
    "    df_ks = pd.DataFrame({'y': y_true.values if hasattr(y_true, 'values') else y_true, 'p': y_score})\n",
    "    df_ks = df_ks.sort_values('p')\n",
    "    df_ks['cum_good'] = (1 - df_ks['y']).cumsum() / (1 - df_ks['y']).sum()\n",
    "    df_ks['cum_bad'] = df_ks['y'].cumsum() / df_ks['y'].sum()\n",
    "    return np.max(np.abs(df_ks['cum_bad'] - df_ks['cum_good']))\n",
    "\n",
    "def evaluation_auc_ks(X, y, pipe, name='', verbose=True):\n",
    "    proba = pipe.predict_proba(X)[:, 1]\n",
    "    auc = round(roc_auc_score(y, proba), 5)\n",
    "    ks = round(ks_stat(y, proba), 5)\n",
    "    if verbose:\n",
    "        print(f'  {name}: AUC={auc}, KS={ks}')\n",
    "    return auc, ks\n",
    "\n",
    "def filter_xy_by_safra(X, y, list_safras):\n",
    "    mask = X['SAFRA'].isin(list_safras)\n",
    "    return X[mask], y.loc[X[mask].index]\n",
    "\n",
    "def _sanitize_mlflow_key(key):\n",
    "    safe = re.sub(r'[^a-zA-Z0-9_\\-]', '_', key)\n",
    "    return re.sub(r'_+', '_', safe).strip('_')\n",
    "\n",
    "# Mapa de splits\n",
    "dict_safras = {\n",
    "    'TREINO - 202410': [202410], 'TREINO - 202411': [202411],\n",
    "    'TREINO - 202412': [202412], 'TREINO / VAL - 202501': [202501],\n",
    "    'TREINO (CONS)': [202410, 202411, 202412, 202501],\n",
    "    'OOS - 202410': [202410], 'OOS - 202411': [202411],\n",
    "    'OOS - 202412': [202412], 'OOS - 202501': [202501],\n",
    "    'OOS (CONS)': [202410, 202411, 202412, 202501],\n",
    "    'OOT - 202502': [202502], 'OOT - 202503': [202503],\n",
    "    'OOT GERAL (CONS)': [202502, 202503],\n",
    "}\n",
    "\n",
    "def generate_map_step_data(X_train, y_train, X_oos, y_oos, X_oot, y_oot):\n",
    "    base = {}\n",
    "    for key in dict_safras:\n",
    "        if 'TREINO' in key:\n",
    "            base[key] = {'X': X_train, 'Y': y_train}\n",
    "        elif 'OOS' in key:\n",
    "            base[key] = {'X': X_oos, 'Y': y_oos}\n",
    "        else:\n",
    "            base[key] = {'X': X_oot, 'Y': y_oot}\n",
    "    return base\n",
    "\n",
    "# Avaliacao LGBM baseline + MLflow\n",
    "with mlflow.start_run(run_name='LightGBM_Baseline_v5') as run_lgbm:\n",
    "    params = pipeline_LGBM.named_steps['model'].get_params()\n",
    "    mlflow.log_param('model_type', 'LightGBM')\n",
    "    mlflow.log_param('n_estimators', params.get('n_estimators'))\n",
    "    mlflow.log_param('max_depth', params.get('max_depth'))\n",
    "    mlflow.log_param('learning_rate', params.get('learning_rate'))\n",
    "    mlflow.log_param('n_features', len(X_train_final.columns))\n",
    "    mlflow.log_param('n_samples_train', len(X_train_final))\n",
    "\n",
    "    print('Avaliacao LGBM baseline por base:')\n",
    "    map_data = generate_map_step_data(X_train_final, y_train_final, X_oos_agg, y_oos_agg, X_oot_agg, y_oot_agg)\n",
    "    for key in dict_safras:\n",
    "        X_f, y_f = filter_xy_by_safra(map_data[key]['X'], map_data[key]['Y'], dict_safras[key])\n",
    "        auc, ks = evaluation_auc_ks(X_f, y_f, pipeline_LGBM, key)\n",
    "        safe_key = _sanitize_mlflow_key(key)\n",
    "        mlflow.log_metric(f'LGBM_AUC_{safe_key}', auc)\n",
    "        mlflow.log_metric(f'LGBM_KS_{safe_key}', ks)\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_LGBM, 'model_lightgbm_baseline')\n",
    "    print(f'\\nMLflow Run ID: {run_lgbm.info.run_id}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pjj2b7y71fe",
   "source": [
    "## 9. Feature Selection (SHAP TreeExplainer)\n",
    "\n",
    "Mede contribuicao real de cada feature para a predicao de FPD, capturando interacoes.\n",
    "Pipeline: Treinar LGBM -> SHAP values -> Ranking global -> Selecionar 90% cumulativo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "i44dz699oea",
   "source": [
    "# =============================================================================\n",
    "# 9.1 TREINAR LGBM PARA SHAP + CALCULAR SHAP VALUES\n",
    "# =============================================================================\n",
    "def _var_num(col):\n",
    "    m = re.search(r'var_(\\d+)', col)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "feats_cadastro = [x for x in X_train_final.columns if 'var_' in x and _var_num(x) <= 25]\n",
    "feats_cadastro += [c for c in ['STATUSRF', 'UF', 'REGIAO', 'DIAS_VAR_12'] if c in X_train_final.columns]\n",
    "\n",
    "feats_to_use = [c for c in X_train_final.columns if c not in feats_cadastro and c not in ['NUM_CPF', 'SAFRA']]\n",
    "X_shap = X_train_final[feats_to_use].copy()\n",
    "\n",
    "num_shap = [n for n in X_shap.select_dtypes(include=['int32','int64','float32','float64']).columns]\n",
    "cat_shap = [c for c in X_shap.select_dtypes(include=['object','category']).columns]\n",
    "\n",
    "prep_shap = ColumnTransformer([\n",
    "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median'))]), num_shap),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0)),\n",
    "    ]), cat_shap),\n",
    "], remainder='drop')\n",
    "\n",
    "pipe_shap = Pipeline([\n",
    "    ('prep', prep_shap),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary', boosting_type='gbdt', learning_rate=0.05,\n",
    "        n_estimators=300, max_depth=7, colsample_bytree=0.8, subsample=0.8,\n",
    "        random_state=42, n_jobs=-1, verbosity=-1,\n",
    "    )),\n",
    "])\n",
    "pipe_shap.fit(X_shap, y_train_final)\n",
    "\n",
    "# SHAP values\n",
    "X_shap_transformed = pipe_shap.named_steps['prep'].transform(X_shap)\n",
    "try:\n",
    "    transformed_names = pipe_shap.named_steps['prep'].get_feature_names_out()\n",
    "except Exception:\n",
    "    transformed_names = num_shap + cat_shap\n",
    "\n",
    "explainer = shap.TreeExplainer(pipe_shap.named_steps['model'])\n",
    "shap_values = explainer.shap_values(X_shap_transformed)\n",
    "shap_vals = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "\n",
    "print(f'SHAP values: {shap_vals.shape}')\n",
    "\n",
    "# Ranking\n",
    "_original_features_ordered = num_shap + cat_shap\n",
    "\n",
    "def _map_transformed_to_original(name):\n",
    "    raw = name.split('__', 1)[-1] if '__' in name else name\n",
    "    try:\n",
    "        idx = int(raw)\n",
    "        if 0 <= idx < len(_original_features_ordered):\n",
    "            return _original_features_ordered[idx]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return raw\n",
    "\n",
    "mean_abs_shap = np.abs(shap_vals).mean(axis=0)\n",
    "df_shap_ranking = pd.DataFrame({\n",
    "    'feature_transformed': list(transformed_names),\n",
    "    'mean_abs_shap': mean_abs_shap,\n",
    "}).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_shap_ranking['feature'] = df_shap_ranking['feature_transformed'].apply(_map_transformed_to_original)\n",
    "\n",
    "def get_book_label(feat):\n",
    "    if feat.startswith('REC_'): return 'Recarga (REC_)'\n",
    "    elif feat.startswith('PAG_'): return 'Pagamento (PAG_)'\n",
    "    elif feat.startswith('FAT_'): return 'Faturamento (FAT_)'\n",
    "    return 'Base (Telco+Score)'\n",
    "\n",
    "df_shap_ranking['book'] = df_shap_ranking['feature'].apply(get_book_label)\n",
    "total_shap = df_shap_ranking['mean_abs_shap'].sum()\n",
    "df_shap_ranking['pct_importance'] = df_shap_ranking['mean_abs_shap'] / total_shap\n",
    "df_shap_ranking['cumulative_pct'] = df_shap_ranking['pct_importance'].cumsum()\n",
    "df_shap_ranking['rank'] = range(1, len(df_shap_ranking) + 1)\n",
    "\n",
    "print(f'\\nTop 15 Features (SHAP):')\n",
    "print(df_shap_ranking[['rank','feature','book','mean_abs_shap','pct_importance']].head(15).to_string(index=False))"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "tl9b9ic5nt",
   "source": [
    "# =============================================================================\n",
    "# 9.2 VISUALIZACOES SHAP + PARETO 90% + EXPORT\n",
    "# =============================================================================\n",
    "BOOK_COLORS = {\n",
    "    'Base (Telco+Score)': '#607D8B', 'Recarga (REC_)': '#2196F3',\n",
    "    'Pagamento (PAG_)': '#FF9800', 'Faturamento (FAT_)': '#9C27B0',\n",
    "}\n",
    "book_names = list(BOOK_COLORS.keys())\n",
    "\n",
    "def get_feature_color(feat):\n",
    "    if feat.startswith('REC_') or '__REC_' in feat: return BOOK_COLORS['Recarga (REC_)']\n",
    "    elif feat.startswith('PAG_') or '__PAG_' in feat: return BOOK_COLORS['Pagamento (PAG_)']\n",
    "    elif feat.startswith('FAT_') or '__FAT_' in feat: return BOOK_COLORS['Faturamento (FAT_)']\n",
    "    return BOOK_COLORS['Base (Telco+Score)']\n",
    "\n",
    "# SHAP Beeswarm\n",
    "fig, ax = plt.subplots(figsize=(12, 14))\n",
    "shap.summary_plot(shap_vals, X_shap_transformed,\n",
    "                  feature_names=list(transformed_names), max_display=40, show=False)\n",
    "plt.title('SHAP Summary Plot - Top 40 Features (FPD)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR_V5}/shap_summary_beeswarm.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Top 30 by Book\n",
    "top30 = df_shap_ranking.head(30)\n",
    "colors_30 = [get_feature_color(f) for f in top30['feature']]\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.barh(range(len(top30)-1, -1, -1), top30['mean_abs_shap'].values,\n",
    "        color=colors_30, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "ax.set_yticks(range(len(top30)-1, -1, -1))\n",
    "ax.set_yticklabels(top30['feature'].values, fontsize=9)\n",
    "ax.set_xlabel('mean(|SHAP value|)', fontsize=11)\n",
    "ax.set_title('Top 30 Features por Importancia SHAP', fontsize=14, fontweight='bold')\n",
    "legend_elements = [Patch(facecolor=c, label=l) for l, c in BOOK_COLORS.items()]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.2, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR_V5}/shap_top30_by_book.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Pareto 90%\n",
    "CUMULATIVE_THRESHOLD = 0.90\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x_range = range(1, len(df_shap_ranking) + 1)\n",
    "colors_cum = [get_feature_color(f) for f in df_shap_ranking['feature']]\n",
    "ax.bar(x_range, df_shap_ranking['pct_importance'].values, color=colors_cum, alpha=0.7, width=1.0)\n",
    "ax2_p = ax.twinx()\n",
    "ax2_p.plot(x_range, df_shap_ranking['cumulative_pct'].values, color='red', linewidth=2)\n",
    "ax2_p.axhline(y=CUMULATIVE_THRESHOLD, color='red', linestyle='--', alpha=0.5)\n",
    "n_90 = (df_shap_ranking['cumulative_pct'] <= CUMULATIVE_THRESHOLD).sum()\n",
    "ax2_p.axvline(x=n_90, color='green', linestyle='--', alpha=0.7)\n",
    "ax2_p.annotate(f'{n_90} features = 90%', xy=(n_90, 0.90), xytext=(n_90+20, 0.80),\n",
    "              arrowprops=dict(arrowstyle='->', color='green'), fontsize=11, fontweight='bold', color='green')\n",
    "ax.set_xlabel('Feature (rank SHAP)'); ax.set_ylabel('Importancia Individual (%)')\n",
    "ax2_p.set_ylabel('Cumulativo (%)')\n",
    "ax.set_title(f'Pareto — {n_90} features capturam 90% importancia SHAP', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR_V5}/shap_pareto_cumulative.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Selecionar features\n",
    "selected_mask = df_shap_ranking['cumulative_pct'] <= CUMULATIVE_THRESHOLD\n",
    "if not selected_mask.all():\n",
    "    first_over = selected_mask[~selected_mask].index[0]\n",
    "    selected_mask.iloc[:first_over + 1] = True\n",
    "final_set_features = df_shap_ranking[selected_mask]['feature'].unique().tolist()\n",
    "print(f'Features selecionadas (SHAP >= 90%): {len(final_set_features)}')\n",
    "\n",
    "# Export SHAP artifacts\n",
    "shap_dir = '/tmp/shap_artifacts'\n",
    "os.makedirs(shap_dir, exist_ok=True)\n",
    "df_shap_ranking.to_csv(f'{shap_dir}/shap_feature_ranking.csv', index=False)\n",
    "with open(f'{shap_dir}/selected_features_shap.pkl', 'wb') as f:\n",
    "    pickle.dump(final_set_features, f)\n",
    "\n",
    "with mlflow.start_run(run_name='SHAP_Feature_Selection_v5'):\n",
    "    mlflow.set_tag('task', 'feature_selection')\n",
    "    mlflow.log_param('n_features_total', len(feats_to_use))\n",
    "    mlflow.log_param('n_features_selected', len(final_set_features))\n",
    "    for fig_path in [f'{OUTPUT_DIR_V5}/shap_summary_beeswarm.png',\n",
    "                     f'{OUTPUT_DIR_V5}/shap_top30_by_book.png',\n",
    "                     f'{OUTPUT_DIR_V5}/shap_pareto_cumulative.png']:\n",
    "        if os.path.exists(fig_path):\n",
    "            mlflow.log_artifact(fig_path, 'shap_plots')\n",
    "    mlflow.log_artifact(f'{shap_dir}/shap_feature_ranking.csv', 'feature_selection')\n",
    "    mlflow.log_artifact(f'{shap_dir}/selected_features_shap.pkl', 'feature_selection')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4md147u7zef",
   "source": [
    "## 10. Modelo Final com Features Selecionadas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pisaue8l3ag",
   "source": [
    "# =============================================================================\n",
    "# 10. TREINO FINAL LGBM COM FEATURES SHAP + AVALIACAO + MLFLOW\n",
    "# =============================================================================\n",
    "dimensions = ['NUM_CPF', 'SAFRA']\n",
    "final_features_with_dims = final_set_features + [d for d in dimensions if d not in final_set_features]\n",
    "\n",
    "X_tr_final_fs = X_train_final[final_features_with_dims]\n",
    "X_oos_fs = X_oos_agg[final_features_with_dims]\n",
    "X_oot_fs = X_oot_agg[final_features_with_dims]\n",
    "\n",
    "nf_final = [n for n in X_tr_final_fs.select_dtypes(include=['int32','int64','float32','float64']).columns if n != 'SAFRA']\n",
    "cf_final = [c for c in X_tr_final_fs.select_dtypes(include=['object','category']).columns if c != 'NUM_CPF']\n",
    "\n",
    "prep_final = ColumnTransformer([\n",
    "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median'))]), nf_final),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0)),\n",
    "    ]), cf_final),\n",
    "], remainder='drop')\n",
    "\n",
    "pipeline_LGBM_final = Pipeline([\n",
    "    ('prep', prep_final),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary', boosting_type='gbdt', learning_rate=0.05,\n",
    "        max_depth=grid_LGBM.best_params_['model__max_depth'],\n",
    "        n_estimators=grid_LGBM.best_params_['model__n_estimators'],\n",
    "        colsample_bytree=0.8, random_state=42, n_jobs=-1, verbosity=-1,\n",
    "    )),\n",
    "])\n",
    "\n",
    "list_results_fs = []\n",
    "\n",
    "with mlflow.start_run(run_name='Final_LGBM_SHAP_v5') as run_final:\n",
    "    pipeline_LGBM_final.fit(X_tr_final_fs, y_train_final)\n",
    "\n",
    "    mlflow.log_param('model_type', 'LightGBM')\n",
    "    mlflow.log_param('n_features', len(final_set_features))\n",
    "    mlflow.log_param('feature_selection', 'SHAP_TreeExplainer_90pct')\n",
    "    model_params = pipeline_LGBM_final.named_steps['model'].get_params()\n",
    "    for k, v in model_params.items():\n",
    "        if isinstance(v, (int, float, str, bool)):\n",
    "            mlflow.log_param(f'model__{k}', v)\n",
    "\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f'MODELO FINAL: LGBM ({len(final_set_features)} features SHAP)')\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    map_data = generate_map_step_data(X_tr_final_fs, y_train_final, X_oos_fs, y_oos_agg, X_oot_fs, y_oot_agg)\n",
    "    for key in dict_safras:\n",
    "        X_f, y_f = filter_xy_by_safra(map_data[key]['X'], map_data[key]['Y'], dict_safras[key])\n",
    "        auc, ks = evaluation_auc_ks(X_f, y_f, pipeline_LGBM_final, key)\n",
    "        safe_key = _sanitize_mlflow_key(key)\n",
    "        mlflow.log_metric(f'AUC_{safe_key}', auc)\n",
    "        mlflow.log_metric(f'KS_{safe_key}', ks)\n",
    "        list_results_fs.append({'MODEL': 'LGBM', 'BASE': key, 'AUC': auc, 'KS': ks})\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_LGBM_final, 'model_final_lgbm_shap')\n",
    "    run_final_id = run_final.info.run_id\n",
    "    print(f'\\nMLflow Run ID: {run_final_id}')\n",
    "\n",
    "df_results_fs = pd.DataFrame(list_results_fs)\n",
    "best_model_pipeline = pipeline_LGBM_final\n",
    "best_model_name = 'LGBM'\n",
    "ks_oot_row = df_results_fs[df_results_fs['BASE'] == 'OOT GERAL (CONS)']\n",
    "best_ks_oot = ks_oot_row['KS'].values[0] if len(ks_oot_row) > 0 else 0\n",
    "\n",
    "print(f'\\nLGBM Final: KS OOT = {best_ks_oot:.5f}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "l7du98doqwl",
   "source": [
    "## 11. Swap Analysis — Modelo vs FPD Real\n",
    "\n",
    "Compara o ranking do modelo (P(FPD=1)) com o ranking real (flag FPD da base score_bureau_movel_full) na **mesma populacao**.\n",
    "\n",
    "**Definicoes**:\n",
    "- **Ranking Oracle**: FPD=1 primeiro, depois FPD=0 (desempate por score modelo)\n",
    "- **Ranking Modelo**: Ordenar por probabilidade P(FPD=1) descendente\n",
    "- **Swap-in**: No top X% do MODELO mas NAO no top X% do ORACLE (falsos alarmes)\n",
    "- **Swap-out**: No top X% do ORACLE mas NAO no top X% do MODELO (maus que escapam)\n",
    "- **Overlap**: No top X% de AMBOS (acertos do modelo)\n",
    "- **Capture Rate**: % de todos os FPD=1 capturados no top X% do modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 11. SWAP ANALYSIS CORRIGIDO — MODELO vs FPD REAL (mesma populacao)\n",
    "# =============================================================================\n",
    "# v5 corrige o bug da v4:\n",
    "#   v4: comparava OOT1 vs OOT2 (populacoes DIFERENTES) → swap-in = swap-out sempre\n",
    "#   v5: compara ranking MODELO vs ranking ORACLE (FPD real) na MESMA populacao\n",
    "\n",
    "print(f'Modelo: {best_model_name}')\n",
    "print('=' * 60)\n",
    "\n",
    "scores_oot = best_model_pipeline.predict_proba(X_oot_fs)[:, 1]\n",
    "df_swap = pd.DataFrame({\n",
    "    'SAFRA': X_oot_fs['SAFRA'].values,\n",
    "    'score': scores_oot,\n",
    "    'FPD': y_oot_agg.values,\n",
    "})\n",
    "\n",
    "total_bad = (df_swap['FPD'] == 1).sum()\n",
    "total_pop = len(df_swap)\n",
    "print(f'Populacao OOT: {total_pop:,} | Maus (FPD=1): {total_bad:,} ({total_bad/total_pop:.2%})')\n",
    "\n",
    "swap_results = []\n",
    "for cutoff in SWAP_CUTOFFS:\n",
    "    n_top = int(total_pop * cutoff)\n",
    "\n",
    "    model_top_idx = df_swap.nlargest(n_top, 'score').index\n",
    "    df_swap['_oracle_rank'] = df_swap['FPD'] * 1e6 + df_swap['score']\n",
    "    oracle_top_idx = df_swap.nlargest(n_top, '_oracle_rank').index\n",
    "\n",
    "    overlap_idx = model_top_idx.intersection(oracle_top_idx)\n",
    "    swap_in_idx = model_top_idx.difference(oracle_top_idx)\n",
    "    swap_out_idx = oracle_top_idx.difference(model_top_idx)\n",
    "\n",
    "    bad_captured = (df_swap.loc[model_top_idx, 'FPD'] == 1).sum()\n",
    "    capture_rate = bad_captured / total_bad if total_bad > 0 else 0\n",
    "    default_rate_model = df_swap.loc[model_top_idx, 'FPD'].mean()\n",
    "    default_rate_oracle = df_swap.loc[oracle_top_idx, 'FPD'].mean()\n",
    "\n",
    "    result = {\n",
    "        'cutoff': f'{cutoff:.0%}',\n",
    "        'n_top': n_top,\n",
    "        'overlap': len(overlap_idx),\n",
    "        'swap_in': len(swap_in_idx),\n",
    "        'swap_out': len(swap_out_idx),\n",
    "        'overlap_pct': len(overlap_idx) / n_top * 100,\n",
    "        'swap_in_pct': len(swap_in_idx) / n_top * 100,\n",
    "        'swap_out_pct': len(swap_out_idx) / n_top * 100,\n",
    "        'capture_rate': capture_rate * 100,\n",
    "        'default_rate_model': default_rate_model * 100,\n",
    "        'default_rate_oracle': default_rate_oracle * 100,\n",
    "    }\n",
    "    swap_results.append(result)\n",
    "\n",
    "    print(f\"\\nTop {cutoff:.0%} (n={n_top:,}):\")\n",
    "    print(f\"  Overlap (acertos):      {result['overlap']:>6,} ({result['overlap_pct']:.1f}%)\")\n",
    "    print(f\"  Swap-in (falso alarme): {result['swap_in']:>6,} ({result['swap_in_pct']:.1f}%)\")\n",
    "    print(f\"  Swap-out (escapados):   {result['swap_out']:>6,} ({result['swap_out_pct']:.1f}%)\")\n",
    "    print(f\"  Capture Rate:           {result['capture_rate']:.1f}%\")\n",
    "    print(f\"  Default Rate (modelo):  {result['default_rate_model']:.1f}%\")\n",
    "    print(f\"  Default Rate (oracle):  {result['default_rate_oracle']:.1f}%\")\n",
    "\n",
    "df_swap.drop(columns=['_oracle_rank'], inplace=True)\n",
    "df_swap_results = pd.DataFrame(swap_results)\n",
    "\n",
    "print(f'\\n=== Resumo Swap Analysis ===')\n",
    "print(df_swap_results[['cutoff','n_top','overlap_pct','swap_in_pct','swap_out_pct','capture_rate']].to_string(index=False))\n"
   ],
   "id": "v5_swap_code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analise por Decis + Capture Rate + PSI\n",
    "\n",
    "- **Decis**: Divide populacao em 10 faixas de score, analisa bad rate e lift por faixa\n",
    "- **Capture Rate**: % de maus (FPD=1) capturados em cada corte cumulativo\n",
    "- **PSI**: Mede estabilidade da distribuicao de scores entre safras\n",
    "  - PSI < 0.10: Estavel | 0.10-0.25: Atencao | > 0.25: Critico"
   ],
   "id": "v5_md_decis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 12. ANALISE POR DECIS + PSI\n",
    "# =============================================================================\n",
    "\n",
    "def decile_analysis(y_true, y_score, n_bins=10):\n",
    "    df_d = pd.DataFrame({'y': y_true, 'score': y_score})\n",
    "    df_d = df_d.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "    df_d['decil'] = pd.qcut(df_d['score'], n_bins, labels=False, duplicates='drop')\n",
    "    df_d['decil'] = df_d['decil'].max() - df_d['decil'] + 1\n",
    "\n",
    "    result = df_d.groupby('decil').agg(\n",
    "        n=('y', 'count'), n_bad=('y', 'sum'),\n",
    "        score_min=('score', 'min'), score_max=('score', 'max'),\n",
    "        score_mean=('score', 'mean'),\n",
    "    ).sort_index().reset_index()\n",
    "\n",
    "    result['n_good'] = result['n'] - result['n_bad']\n",
    "    result['bad_rate'] = result['n_bad'] / result['n'] * 100\n",
    "    result['pct_pop'] = result['n'] / result['n'].sum() * 100\n",
    "    result['pct_bad'] = result['n_bad'] / result['n_bad'].sum() * 100\n",
    "    result['cum_bad_pct'] = result['pct_bad'].cumsum()\n",
    "    result['cum_pop_pct'] = result['pct_pop'].cumsum()\n",
    "    avg_bad_rate = result['n_bad'].sum() / result['n'].sum() * 100\n",
    "    result['lift'] = result['bad_rate'] / avg_bad_rate\n",
    "    return result\n",
    "\n",
    "def calc_psi(expected, actual, bins=10):\n",
    "    breakpoints = np.linspace(0, 1, bins + 1)\n",
    "    exp_pct = np.histogram(expected, bins=breakpoints)[0] / len(expected)\n",
    "    act_pct = np.histogram(actual, bins=breakpoints)[0] / len(actual)\n",
    "    exp_pct = np.where(exp_pct == 0, 0.0001, exp_pct)\n",
    "    act_pct = np.where(act_pct == 0, 0.0001, act_pct)\n",
    "    return float(np.sum((act_pct - exp_pct) * np.log(act_pct / exp_pct)))\n",
    "\n",
    "# Decis OOT consolidado\n",
    "print('=== Analise por Decis — OOT Consolidado ===')\n",
    "dec_oot = decile_analysis(y_oot_agg.values, scores_oot)\n",
    "print(dec_oot[['decil','n','n_bad','bad_rate','cum_bad_pct','lift','score_min','score_max']].to_string(index=False))\n",
    "\n",
    "bad_rates = dec_oot['bad_rate'].values\n",
    "is_monotonic = all(bad_rates[i] >= bad_rates[i+1] for i in range(len(bad_rates)-1))\n",
    "print(f'\\nMonotonia bad_rate: {\"SIM\" if is_monotonic else \"NAO\"} (decil 1 deve ter maior bad rate)')\n",
    "\n",
    "# Decis por SAFRA\n",
    "safras_oot_list = sorted(df_swap['SAFRA'].unique())\n",
    "dec_by_safra = {}\n",
    "for safra in safras_oot_list:\n",
    "    mask = df_swap['SAFRA'] == safra\n",
    "    dec = decile_analysis(df_swap.loc[mask, 'FPD'].values, df_swap.loc[mask, 'score'].values)\n",
    "    dec_by_safra[safra] = dec\n",
    "    print(f'\\n--- Decis SAFRA {safra} ---')\n",
    "    print(dec[['decil','n','n_bad','bad_rate','cum_bad_pct','lift']].to_string(index=False))\n",
    "\n",
    "# PSI\n",
    "scores_train = best_model_pipeline.predict_proba(X_tr_final_fs)[:, 1]\n",
    "\n",
    "print(f'\\n=== PSI (Population Stability Index) ===')\n",
    "psi_results = []\n",
    "psi_train_oot = calc_psi(scores_train, scores_oot)\n",
    "status = 'OK' if psi_train_oot < 0.1 else 'ATENCAO' if psi_train_oot < 0.25 else 'CRITICO'\n",
    "print(f'PSI Train vs OOT: {psi_train_oot:.4f} [{status}]')\n",
    "psi_results.append({'comparacao': 'Train vs OOT', 'psi': psi_train_oot, 'status': status})\n",
    "\n",
    "for safra in safras_oot_list:\n",
    "    mask = df_swap['SAFRA'] == safra\n",
    "    psi_val = calc_psi(scores_train, df_swap.loc[mask, 'score'].values)\n",
    "    status = 'OK' if psi_val < 0.1 else 'ATENCAO' if psi_val < 0.25 else 'CRITICO'\n",
    "    print(f'PSI Train vs OOT-{safra}: {psi_val:.4f} [{status}]')\n",
    "    psi_results.append({'comparacao': f'Train vs OOT-{safra}', 'psi': psi_val, 'status': status})\n",
    "\n",
    "if len(safras_oot_list) >= 2:\n",
    "    psi_12 = calc_psi(\n",
    "        df_swap.loc[df_swap['SAFRA'] == safras_oot_list[0], 'score'].values,\n",
    "        df_swap.loc[df_swap['SAFRA'] == safras_oot_list[1], 'score'].values,\n",
    "    )\n",
    "    status = 'OK' if psi_12 < 0.1 else 'ATENCAO' if psi_12 < 0.25 else 'CRITICO'\n",
    "    print(f'PSI OOT1 vs OOT2: {psi_12:.4f} [{status}]')\n",
    "    psi_results.append({'comparacao': 'OOT1 vs OOT2', 'psi': psi_12, 'status': status})\n",
    "\n",
    "df_psi = pd.DataFrame(psi_results)\n"
   ],
   "id": "v5_decis_code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualizacoes Avancadas (16 graficos)\n",
    "\n",
    "**Performance**: KS Curve, ROC Curve, Precision-Recall, Score Distribution\n",
    "**Ranking**: Confusion Matrix, Decile Bad Rate, Decile Lift, Cumulative Bad %\n",
    "**Estabilidade**: KS por Base, Score por SAFRA, PSI, Swap Stacked Bar\n",
    "**Analise**: Capture Rate, AUC por Split, Feature Importance, Calibracao"
   ],
   "id": "v5_md_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 13.1 VISUALIZACOES — PERFORMANCE (8 graficos)\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 4, figsize=(28, 12))\n",
    "fig.suptitle(f'Modelo {best_model_name} — Performance OOT', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. KS Curve\n",
    "ax = axes[0, 0]\n",
    "df_ks = pd.DataFrame({'y': y_oot_agg.values, 'score': scores_oot}).sort_values('score')\n",
    "df_ks['cum_good'] = (1 - df_ks['y']).cumsum() / (1 - df_ks['y']).sum()\n",
    "df_ks['cum_bad'] = df_ks['y'].cumsum() / df_ks['y'].sum()\n",
    "df_ks['ks_diff'] = np.abs(df_ks['cum_bad'] - df_ks['cum_good'])\n",
    "ks_max_idx = df_ks['ks_diff'].idxmax()\n",
    "ks_max_val = df_ks.loc[ks_max_idx, 'ks_diff']\n",
    "x_pct = np.linspace(0, 1, len(df_ks))\n",
    "ax.plot(x_pct, df_ks['cum_good'].values, label='Bons', color=COLORS['blue'])\n",
    "ax.plot(x_pct, df_ks['cum_bad'].values, label='Maus', color=COLORS['red'])\n",
    "ks_x = x_pct[df_ks.index.get_loc(ks_max_idx)]\n",
    "ax.axvline(x=ks_x, color=COLORS['green'], linestyle='--', alpha=0.7)\n",
    "ax.annotate(f'KS={ks_max_val:.4f}', xy=(ks_x, 0.5), fontsize=10, fontweight='bold', color=COLORS['green'])\n",
    "ax.set_title('1. KS Curve', fontweight='bold'); ax.set_xlabel('Pop (%)'); ax.set_ylabel('CDF')\n",
    "ax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. ROC Curve\n",
    "ax = axes[0, 1]\n",
    "fpr, tpr, _ = roc_curve(y_oot_agg, scores_oot)\n",
    "auc_val = roc_auc_score(y_oot_agg, scores_oot)\n",
    "ax.plot(fpr, tpr, color=COLORS['blue'], linewidth=2, label=f'AUC={auc_val:.4f}')\n",
    "ax.plot([0,1],[0,1],'k--',alpha=0.3); ax.fill_between(fpr, tpr, alpha=0.1, color=COLORS['blue'])\n",
    "ax.set_title('2. ROC Curve', fontweight='bold'); ax.set_xlabel('FPR'); ax.set_ylabel('TPR')\n",
    "ax.legend(fontsize=10); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall\n",
    "ax = axes[0, 2]\n",
    "prec, rec, _ = precision_recall_curve(y_oot_agg, scores_oot)\n",
    "ax.plot(rec, prec, color=COLORS['orange'], linewidth=2)\n",
    "ax.fill_between(rec, prec, alpha=0.1, color=COLORS['orange'])\n",
    "baseline = y_oot_agg.mean()\n",
    "ax.axhline(y=baseline, color='gray', linestyle='--', alpha=0.5, label=f'Base={baseline:.3f}')\n",
    "ax.set_title('3. Precision-Recall', fontweight='bold'); ax.set_xlabel('Recall'); ax.set_ylabel('Precision')\n",
    "ax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Score Distribution\n",
    "ax = axes[0, 3]\n",
    "ax.hist(scores_oot[y_oot_agg.values==0], bins=50, alpha=0.6, label='Bons', color=COLORS['green'], density=True)\n",
    "ax.hist(scores_oot[y_oot_agg.values==1], bins=50, alpha=0.6, label='Maus', color=COLORS['red'], density=True)\n",
    "ax.set_title('4. Score Distribution', fontweight='bold'); ax.set_xlabel('P(FPD=1)'); ax.set_ylabel('Dens.')\n",
    "ax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Confusion Matrix\n",
    "ax = axes[1, 0]\n",
    "y_pred = (scores_oot >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_oot_agg, y_pred)\n",
    "ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.set_title('5. Confusion Matrix (t=0.5)', fontweight='bold')\n",
    "ax.set_ylabel('Real'); ax.set_xlabel('Predito')\n",
    "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(['Bom','Mau']); ax.set_yticklabels(['Bom','Mau'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, f'{cm[i,j]:,}', ha='center', va='center',\n",
    "                color='white' if cm[i,j] > cm.max()/2 else 'black', fontsize=11)\n",
    "\n",
    "# 6. Decile Bad Rate\n",
    "ax = axes[1, 1]\n",
    "bars = ax.bar(dec_oot['decil'], dec_oot['bad_rate'], color=COLORS['red'], alpha=0.8, edgecolor='white')\n",
    "avg_br = dec_oot['n_bad'].sum() / dec_oot['n'].sum() * 100\n",
    "ax.axhline(y=avg_br, color='gray', linestyle='--', alpha=0.7, label=f'Media={avg_br:.1f}%')\n",
    "ax.set_title('6. Bad Rate por Decil', fontweight='bold'); ax.set_xlabel('Decil (1=pior)')\n",
    "ax.set_ylabel('Bad Rate (%)'); ax.legend(fontsize=8); ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars, dec_oot['bad_rate']):\n",
    "    ax.text(bar.get_x()+bar.get_width()/2, val+0.3, f'{val:.1f}%', ha='center', fontsize=7)\n",
    "\n",
    "# 7. Decile Lift\n",
    "ax = axes[1, 2]\n",
    "ax.bar(dec_oot['decil'], dec_oot['lift'], color=COLORS['purple'], alpha=0.8, edgecolor='white')\n",
    "ax.axhline(y=1.0, color='gray', linestyle='--', alpha=0.7, label='Lift=1')\n",
    "ax.set_title('7. Lift por Decil', fontweight='bold'); ax.set_xlabel('Decil (1=pior)')\n",
    "ax.set_ylabel('Lift'); ax.legend(fontsize=8); ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 8. Cumulative Bad %\n",
    "ax = axes[1, 3]\n",
    "ax.plot(dec_oot['cum_pop_pct'], dec_oot['cum_bad_pct'], 'ro-', linewidth=2, markersize=6, label='Modelo')\n",
    "ax.plot([0,100],[0,100],'k--',alpha=0.3, label='Aleatorio')\n",
    "ax.fill_between(dec_oot['cum_pop_pct'], dec_oot['cum_bad_pct'], dec_oot['cum_pop_pct'],\n",
    "                alpha=0.1, color=COLORS['red'])\n",
    "ax.set_title('8. Curva de Captura', fontweight='bold'); ax.set_xlabel('% Pop')\n",
    "ax.set_ylabel('% Maus Capturados'); ax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(f'{OUTPUT_DIR_V5}/viz_performance_8plots.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Graficos 1-8 salvos')\n"
   ],
   "id": "v5_viz_part1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 13.2 VISUALIZACOES — ESTABILIDADE + SWAP + RESUMO (8 graficos)\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 4, figsize=(28, 12))\n",
    "fig.suptitle(f'Modelo {best_model_name} — Estabilidade, Swap & Resumo', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 9. KS por Base\n",
    "ax = axes[0, 0]\n",
    "oos_oot_res = df_results_fs[df_results_fs['BASE'].str.contains('OOS|OOT')]\n",
    "bars = ax.bar(range(len(oos_oot_res)), oos_oot_res['KS'].values, color=COLORS['blue'], edgecolor='white')\n",
    "ax.set_xticks(range(len(oos_oot_res)))\n",
    "ax.set_xticklabels(oos_oot_res['BASE'].values, rotation=45, ha='right', fontsize=7)\n",
    "ax.axhline(y=0.20, color='gray', linestyle='--', alpha=0.5, label='Min KS=0.20')\n",
    "ax.set_title('9. KS por Base', fontweight='bold'); ax.set_ylabel('KS')\n",
    "ax.legend(fontsize=8); ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars, oos_oot_res['KS'].values):\n",
    "    ax.text(bar.get_x()+bar.get_width()/2, val+0.003, f'{val:.3f}', ha='center', fontsize=7)\n",
    "\n",
    "# 10. Score por SAFRA (Boxplot)\n",
    "ax = axes[0, 1]\n",
    "safra_scores = [df_swap.loc[df_swap['SAFRA']==s, 'score'].values for s in safras_oot_list]\n",
    "bp = ax.boxplot(safra_scores, labels=[str(s) for s in safras_oot_list], patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], [COLORS['blue'], COLORS['orange']]):\n",
    "    patch.set_facecolor(color); patch.set_alpha(0.6)\n",
    "ax.set_title('10. Score por SAFRA OOT', fontweight='bold')\n",
    "ax.set_xlabel('SAFRA'); ax.set_ylabel('Score'); ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 11. PSI Bar Chart\n",
    "ax = axes[0, 2]\n",
    "psi_colors = [COLORS['green'] if r['psi']<0.1 else COLORS['orange'] if r['psi']<0.25 else COLORS['red']\n",
    "              for r in psi_results]\n",
    "ax.barh(range(len(psi_results)), [r['psi'] for r in psi_results], color=psi_colors, edgecolor='white')\n",
    "ax.set_yticks(range(len(psi_results)))\n",
    "ax.set_yticklabels([r['comparacao'] for r in psi_results], fontsize=8)\n",
    "ax.axvline(x=0.10, color='orange', linestyle='--', alpha=0.5, label='Atencao')\n",
    "ax.axvline(x=0.25, color='red', linestyle='--', alpha=0.5, label='Critico')\n",
    "ax.set_title('11. PSI', fontweight='bold'); ax.set_xlabel('PSI')\n",
    "ax.legend(fontsize=7); ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 12. Swap Stacked Bar\n",
    "ax = axes[0, 3]\n",
    "x_sw = range(len(df_swap_results))\n",
    "ax.bar(x_sw, df_swap_results['overlap_pct'], label='Overlap', color=COLORS['green'], alpha=0.8)\n",
    "ax.bar(x_sw, df_swap_results['swap_in_pct'], bottom=df_swap_results['overlap_pct'],\n",
    "       label='Swap-in', color=COLORS['orange'], alpha=0.8)\n",
    "ax.bar(x_sw, df_swap_results['swap_out_pct'],\n",
    "       bottom=df_swap_results['overlap_pct']+df_swap_results['swap_in_pct'],\n",
    "       label='Swap-out', color=COLORS['red'], alpha=0.8)\n",
    "ax.set_xticks(x_sw); ax.set_xticklabels(df_swap_results['cutoff'], fontsize=9)\n",
    "ax.set_title('12. Swap Analysis', fontweight='bold'); ax.set_xlabel('Top %')\n",
    "ax.set_ylabel('% do Top'); ax.legend(fontsize=7); ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 13. Capture Rate Curve\n",
    "ax = axes[1, 0]\n",
    "pcts = np.arange(0.01, 1.01, 0.01)\n",
    "capture_rates = []\n",
    "for p in pcts:\n",
    "    n = int(total_pop * p)\n",
    "    top_idx = df_swap.nlargest(n, 'score').index\n",
    "    captured = (df_swap.loc[top_idx, 'FPD'] == 1).sum()\n",
    "    capture_rates.append(captured / total_bad * 100)\n",
    "ax.plot(pcts*100, capture_rates, color=COLORS['red'], linewidth=2, label='Modelo')\n",
    "ax.plot([0,100],[0,100],'k--',alpha=0.3, label='Aleatorio')\n",
    "ax.fill_between(pcts*100, capture_rates, pcts*100, alpha=0.1, color=COLORS['red'])\n",
    "for cutoff in SWAP_CUTOFFS:\n",
    "    idx = int(cutoff*100)-1\n",
    "    ax.plot(cutoff*100, capture_rates[idx], 'go', markersize=8)\n",
    "    ax.annotate(f'{capture_rates[idx]:.0f}%', xy=(cutoff*100, capture_rates[idx]),\n",
    "               xytext=(5,5), textcoords='offset points', fontsize=8, color=COLORS['green'])\n",
    "ax.set_title('13. Capture Rate', fontweight='bold'); ax.set_xlabel('% Pop Avaliada')\n",
    "ax.set_ylabel('% Maus Capturados'); ax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 14. AUC por Split\n",
    "ax = axes[1, 1]\n",
    "groups = {'TREINO': [], 'OOS': [], 'OOT': []}\n",
    "for _, row in df_results_fs.iterrows():\n",
    "    if 'TREINO' in row['BASE'] and 'CONS' not in row['BASE']:\n",
    "        groups['TREINO'].append(row['AUC'])\n",
    "    elif 'OOS' in row['BASE'] and 'CONS' not in row['BASE']:\n",
    "        groups['OOS'].append(row['AUC'])\n",
    "    elif 'OOT' in row['BASE'] and 'CONS' not in row['BASE']:\n",
    "        groups['OOT'].append(row['AUC'])\n",
    "gm = {k: np.mean(v) if v else 0 for k, v in groups.items()}\n",
    "bars = ax.bar(gm.keys(), gm.values(), color=[COLORS['blue'],COLORS['orange'],COLORS['red']],\n",
    "              alpha=0.8, edgecolor='white')\n",
    "ax.axhline(y=0.65, color='gray', linestyle='--', alpha=0.5, label='Min AUC')\n",
    "ax.set_title('14. AUC Medio por Split', fontweight='bold'); ax.set_ylabel('AUC')\n",
    "ax.legend(fontsize=8); ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars, gm.values()):\n",
    "    ax.text(bar.get_x()+bar.get_width()/2, val+0.002, f'{val:.4f}', ha='center', fontsize=9)\n",
    "\n",
    "# 15. Feature Importance (top 20)\n",
    "ax = axes[1, 2]\n",
    "lgbm_final = best_model_pipeline.named_steps['model']\n",
    "try:\n",
    "    feat_names_final = best_model_pipeline.named_steps['prep'].get_feature_names_out()\n",
    "except Exception:\n",
    "    feat_names_final = nf_final + cf_final\n",
    "df_imp = pd.DataFrame({'feature': feat_names_final, 'importance': lgbm_final.feature_importances_})\n",
    "df_imp = df_imp.sort_values('importance', ascending=False).head(20)\n",
    "colors_imp = [get_feature_color(f.split('__')[-1] if '__' in f else f) for f in df_imp['feature']]\n",
    "ax.barh(range(len(df_imp)-1,-1,-1), df_imp['importance'].values, color=colors_imp, alpha=0.85)\n",
    "ax.set_yticks(range(len(df_imp)-1,-1,-1))\n",
    "ax.set_yticklabels(df_imp['feature'].values, fontsize=7)\n",
    "ax.set_title('15. Top 20 Feature Importance', fontweight='bold')\n",
    "ax.set_xlabel('Importance'); ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 16. Calibration\n",
    "ax = axes[1, 3]\n",
    "df_cal = pd.DataFrame({'y': y_oot_agg.values, 'score': scores_oot})\n",
    "df_cal['bin'] = pd.qcut(df_cal['score'], 10, duplicates='drop')\n",
    "cal = df_cal.groupby('bin', observed=True).agg(pred=('score','mean'), obs=('y','mean')).reset_index()\n",
    "ax.plot(cal['pred'], cal['obs'], 'bo-', markersize=8, label='Modelo')\n",
    "ax.plot([0, cal['pred'].max()], [0, cal['pred'].max()], 'k--', alpha=0.3, label='Perfeito')\n",
    "ax.set_title('16. Calibracao', fontweight='bold'); ax.set_xlabel('Score Predito')\n",
    "ax.set_ylabel('Bad Rate Obs'); ax.legend(fontsize=8); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(f'{OUTPUT_DIR_V5}/viz_stability_swap_8plots.png', dpi=DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Graficos 9-16 salvos')\n"
   ],
   "id": "v5_viz_part2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 13.3 LOG VISUALIZACOES NO MLFLOW\n",
    "# =============================================================================\n",
    "import glob as glob_mod\n",
    "\n",
    "with mlflow.start_run(run_name='Final_Visualizations_v5') as run_viz:\n",
    "    mlflow.set_tag('task', 'visualization')\n",
    "    mlflow.set_tag('version', 'v5')\n",
    "\n",
    "    for fig_path in glob_mod.glob(f'{OUTPUT_DIR_V5}/*.png'):\n",
    "        mlflow.log_artifact(fig_path, 'plots_v5')\n",
    "\n",
    "    df_swap_results.to_csv(f'{OUTPUT_DIR_V5}/swap_analysis_results.csv', index=False)\n",
    "    mlflow.log_artifact(f'{OUTPUT_DIR_V5}/swap_analysis_results.csv', 'swap_analysis')\n",
    "\n",
    "    dec_oot.to_csv(f'{OUTPUT_DIR_V5}/decile_analysis_oot.csv', index=False)\n",
    "    mlflow.log_artifact(f'{OUTPUT_DIR_V5}/decile_analysis_oot.csv', 'decile_analysis')\n",
    "\n",
    "    df_psi.to_csv(f'{OUTPUT_DIR_V5}/psi_results.csv', index=False)\n",
    "    mlflow.log_artifact(f'{OUTPUT_DIR_V5}/psi_results.csv', 'psi')\n",
    "\n",
    "    mlflow.log_metric('ks_oot', ks_max_val)\n",
    "    mlflow.log_metric('auc_oot', auc_val)\n",
    "    mlflow.log_metric('gini_oot', (2 * auc_val - 1) * 100)\n",
    "    mlflow.log_metric('psi_train_vs_oot', psi_train_oot)\n",
    "\n",
    "    print(f'MLflow Run ID (viz): {run_viz.info.run_id}')\n",
    "    print(f'Artifacts: {OUTPUT_DIR_V5}/')\n",
    "    print(f'16 visualizacoes logadas no MLflow')\n"
   ],
   "id": "v5_mlflow_viz"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export do Modelo\n",
    "\n",
    "Export do modelo final via MLflow Model Registry + pickle local.\n",
    "Promove automaticamente para Production no Registry do Fabric."
   ],
   "id": "v5_md_export"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 14. EXPORT DO MODELO PARA MLFLOW REGISTRY\n",
    "# =============================================================================\n",
    "sys.path.insert(0, '/lakehouse/default/Files/projeto-final/5-treinamento-modelos')\n",
    "from export_model import export_model, promote_to_production\n",
    "\n",
    "feature_names_export = [f for f in final_set_features if f not in ['NUM_CPF', 'SAFRA']]\n",
    "X_oot_exp = X_oot_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore')\n",
    "\n",
    "print(f'Modelo: {best_model_name} (SHAP feature selection)')\n",
    "print(f'Features: {len(feature_names_export)}')\n",
    "print(f'KS OOT: {best_ks_oot:.5f}')\n",
    "print('=' * 60)\n",
    "\n",
    "ks_oot_final = ks_stat(y_oot_agg, best_model_pipeline.predict_proba(X_oot_fs)[:, 1])\n",
    "auc_oot_final = roc_auc_score(y_oot_agg, best_model_pipeline.predict_proba(X_oot_fs)[:, 1])\n",
    "ks_oos_final = ks_stat(y_oos_agg, best_model_pipeline.predict_proba(X_oos_fs)[:, 1])\n",
    "auc_oos_final = roc_auc_score(y_oos_agg, best_model_pipeline.predict_proba(X_oos_fs)[:, 1])\n",
    "\n",
    "metrics = {\n",
    "    'ks_oot': ks_oot_final, 'auc_oot': auc_oot_final,\n",
    "    'ks_oos': ks_oos_final, 'auc_oos': auc_oos_final,\n",
    "    'gini_oot': (2 * auc_oot_final - 1) * 100,\n",
    "    'gini_oos': (2 * auc_oos_final - 1) * 100,\n",
    "    'psi_train_vs_oot': psi_train_oot,\n",
    "    'n_features': len(feature_names_export),\n",
    "    'version': 'v5',\n",
    "}\n",
    "\n",
    "X_oos_501, y_oos_501 = filter_xy_by_safra(X_oos_fs, y_oos_agg, [202501])\n",
    "if len(y_oos_501) > 0:\n",
    "    proba_501 = best_model_pipeline.predict_proba(X_oos_501)[:, 1]\n",
    "    metrics['ks_oos_202501'] = ks_stat(y_oos_501, proba_501)\n",
    "    metrics['auc_oos_202501'] = roc_auc_score(y_oos_501, proba_501)\n",
    "    metrics['gini_oos_202501'] = (2 * metrics['auc_oos_202501'] - 1) * 100\n",
    "\n",
    "result = export_model(\n",
    "    pipeline=best_model_pipeline, model_name='lgbm_baseline_v5',\n",
    "    X_test=X_oot_exp, y_test=y_oot_agg,\n",
    "    feature_names=feature_names_export,\n",
    "    metrics_dict=metrics,\n",
    ")\n",
    "\n",
    "print(f\"\\nModelo exportado: {result['registered_name']}\")\n",
    "print(f\"  MLflow Run ID: {result['mlflow_run_id']}\")\n",
    "print(f\"  PKL: {result['pkl_path']}\")\n",
    "print(f\"  KS OOT: {ks_oot_final:.5f}\")\n",
    "print(f\"  KS OOS: {ks_oos_final:.5f}\")\n",
    "print(f\"  Gini OOT: {metrics['gini_oot']:.1f}%\")\n",
    "print(f\"  PSI: {psi_train_oot:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print('Promovendo modelo para Production...')\n",
    "version = promote_to_production(result['registered_name'])\n",
    "print(f\"Modelo {result['registered_name']} v{version} em Production!\")\n",
    "print(f\"{'='*60}\")\n",
    "print('\\nExport + Promote concluido!')\n",
    "print('v5 completo — swap corrigido, 16 visualizacoes, decis, PSI')\n"
   ],
   "id": "v5_export"
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  },
  "microsoft": {
   "language": "python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}