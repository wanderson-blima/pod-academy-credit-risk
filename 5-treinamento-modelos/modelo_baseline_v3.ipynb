{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  },
  "microsoft": {
   "language": "python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%%configure\n",
    "\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.driver.maxResultSize\": \"8g\",\n",
    "        \"spark.driver.memory\": \"54g\",\n",
    "        \"spark.driver.cores\": 8,\n",
    "        \"spark.executor.instances\": 0,\n",
    "        \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "        \"spark.sql.execution.arrow.pyspark.selfDestruct.enabled\": \"true\"\n",
    "    }\n",
    "}"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Baseline de Risco – Telecom (v3 — Spark Read + Pandas Modeling)\n",
    "\n",
    "Este notebook implementa um **modelo baseline de risco de inadimplencia (FPD)** para clientes Claro.\n",
    "\n",
    "### Diferencas em relacao ao v1 e v2\n",
    "- **v1**: PySpark para limpeza + Pandas para modelagem (original)\n",
    "- **v2**: Python puro com `deltalake` (delta-rs) — falha no Fabric por falta de Spark context para MLflow\n",
    "- **v3 (este)**: Usa `spark.read` para carregar dados, converte para Pandas, e segue com modelagem 100% Pandas\n",
    "- Codigo limpo e organizado do v2, compatibilidade Fabric do v1\n",
    "\n",
    "### Otimizacao de Memoria (toPandas)\n",
    "O dataset completo (3.9M x 402 cols) gera ~8.8 GiB serializado, excedendo `spark.driver.maxResultSize`.\n",
    "Estrategia de 5 camadas aplicada:\n",
    "1. **Arrow + selfDestruct** — serializacao 2-3x mais eficiente\n",
    "2. **Drop colunas audit/leakage no Spark** — menos dados para serializar\n",
    "3. **FLAG_INSTALACAO == 1 filtrado no Spark** — reduz ~30-40% das linhas antes do toPandas\n",
    "4. **Cast Double→Float, Long→Int no Spark** — metade do tamanho numerico\n",
    "5. **Conversao chunked por SAFRA** + gc.collect() entre chunks (~1 GiB por chunk)\n",
    "\n",
    "### Principais etapas\n",
    "- Leitura do Gold Feature Store via `spark.read.format(\"delta\")`\n",
    "- Amostragem de **25%** por safra e FPD, de forma estratificada\n",
    "- Separacao em **Treino (2024-10 a 2024-12)**, **Validacao (2025-01)**, **OOS** e **OOT (2025-02 e 2025-03)**\n",
    "- Modelos: Logistic Regression (L1) + LightGBM (GBDT)\n",
    "- Ajuste de hiperparametros no conjunto de validacao\n",
    "- Metricas: AUC, KS, Gini\n",
    "- Analise incremental de KS por fonte de dados\n",
    "- Feature selection: IV + L1 coefs + alta correlacao\n",
    "- Swap analysis OOT1 vs OOT2\n",
    "- Export via MLflow Registry"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTS E CONFIGURACAO\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "import shap\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType, DoubleType, LongType\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "from category_encoders import CountEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config centralizado do pipeline\n",
    "import sys; sys.path.insert(0, '/lakehouse/default/Files/projeto-final')\n",
    "from config.pipeline_config import (\n",
    "    PATH_FEATURE_STORE, EXPERIMENT_NAME, SAFRAS,\n",
    "    LEAKAGE_BLACKLIST, TARGET_COLUMNS\n",
    ")\n",
    "\n",
    "print('Imports OK')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 2. MLFLOW SETUP\n",
    "# =============================================================================\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.autolog(disable=True)  # Controle manual para evitar conflitos\n",
    "\n",
    "print(f'MLflow experiment: {EXPERIMENT_NAME}')\n",
    "print(f'Tracking URI: {mlflow.get_tracking_uri()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 3. LEITURA OTIMIZADA DO GOLD FEATURE STORE (Spark -> Pandas)\n",
    "# =============================================================================\n",
    "# Problema: toPandas() direto com 3.9M x 402 cols gera ~8.8 GiB serializado,\n",
    "# estourando spark.driver.maxResultSize (8 GiB).\n",
    "#\n",
    "# Estrategia de otimizacao (5 camadas):\n",
    "#   1. Arrow + selfDestruct — serializacao 2-3x mais eficiente\n",
    "#   2. Drop colunas audit/leakage no Spark — menos dados para serializar\n",
    "#   3. Filtrar FLAG_INSTALACAO == 1 no Spark — reduz ~30-40% das linhas\n",
    "#   4. Cast Double->Float, Long->Int via .select() — metade do tamanho numerico\n",
    "#   5. Conversao chunked por SAFRA + gc.collect() entre chunks\n",
    "\n",
    "# ---- 3.1 Habilitar Arrow para toPandas ----\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.selfDestruct.enabled\", \"true\")\n",
    "\n",
    "print(f'Lendo feature store de: {PATH_FEATURE_STORE}\\n')\n",
    "\n",
    "df_spark = spark.read.format(\"delta\").load(PATH_FEATURE_STORE)\n",
    "n_original = df_spark.count()\n",
    "print(f'Original: {n_original:,} rows x {len(df_spark.columns)} cols')\n",
    "\n",
    "# ---- 3.2 Drop colunas audit + leakage no Spark ----\n",
    "cols_audit = ['_execution_id', '_data_inclusao', '_data_alteracao_silver', 'DT_PROCESSAMENTO']\n",
    "cols_drop = [c for c in cols_audit + LEAKAGE_BLACKLIST if c in df_spark.columns]\n",
    "if cols_drop:\n",
    "    df_spark = df_spark.drop(*cols_drop)\n",
    "    print(f'Drop {len(cols_drop)} colunas (audit+leakage): {cols_drop}')\n",
    "\n",
    "# ---- 3.3 Filtrar FLAG_INSTALACAO == 1 no Spark (ANTES do toPandas) ----\n",
    "# Essa filtragem aqui (e nao no Pandas) reduz significativamente o volume\n",
    "n_reprovados = 0\n",
    "if 'FLAG_INSTALACAO' in df_spark.columns:\n",
    "    n_reprovados = df_spark.filter(F.col('FLAG_INSTALACAO') == 0).count()\n",
    "    df_spark = df_spark.filter(F.col('FLAG_INSTALACAO') == 1).drop('FLAG_INSTALACAO')\n",
    "    n_pos = n_original - n_reprovados  # evita .count() redundante\n",
    "    print(f'FLAG_INSTALACAO: {n_original:,} -> {n_pos:,} pos-instalacao ({n_reprovados:,} reprovados removidos)')\n",
    "else:\n",
    "    n_pos = n_original\n",
    "\n",
    "# ---- 3.4 Cast tipos via .select() (plano flat, evita deep Spark plan) ----\n",
    "# withColumn sequencial com 300+ colunas gera arvore profunda no Catalyst.\n",
    "# .select() com lista de expressoes gera plano flat (1 no).\n",
    "cast_exprs = []\n",
    "n_double, n_long = 0, 0\n",
    "for field in df_spark.schema.fields:\n",
    "    if isinstance(field.dataType, DoubleType):\n",
    "        cast_exprs.append(F.col(field.name).cast(FloatType()).alias(field.name))\n",
    "        n_double += 1\n",
    "    elif isinstance(field.dataType, LongType):\n",
    "        cast_exprs.append(F.col(field.name).cast(IntegerType()).alias(field.name))\n",
    "        n_long += 1\n",
    "    else:\n",
    "        cast_exprs.append(F.col(field.name))\n",
    "df_spark = df_spark.select(*cast_exprs)\n",
    "\n",
    "print(f'Cast tipos (.select flat): {n_double} Double->Float, {n_long} Long->Int')\n",
    "\n",
    "# ---- 3.5 Conversao chunked por SAFRA ----\n",
    "safras_disponiveis = sorted([row.SAFRA for row in df_spark.select('SAFRA').distinct().collect()])\n",
    "print(f'\\nSAFRAs: {safras_disponiveis} | Colunas: {len(df_spark.columns)}')\n",
    "print('Convertendo por SAFRA...')\n",
    "\n",
    "chunks = []\n",
    "for safra in safras_disponiveis:\n",
    "    chunk = df_spark.filter(F.col('SAFRA') == safra).toPandas()\n",
    "    mem_mb = chunk.memory_usage(deep=True).sum() / 1e6\n",
    "    print(f'  SAFRA {safra}: {len(chunk):,} rows | {mem_mb:.0f} MB')\n",
    "    chunks.append(chunk)\n",
    "    gc.collect()\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "del chunks\n",
    "gc.collect()\n",
    "\n",
    "print(f'\\nDataset carregado (apenas pos-instalacao):')\n",
    "print(f'  Shape: {df.shape}')\n",
    "print(f'  Memory: {df.memory_usage(deep=True).sum() / 1e9:.2f} GB')\n",
    "print(f'  Reprovados (nao carregados): {n_reprovados:,}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limpeza de Dados (Pandas puro)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 4.1 FUNCOES DE LIMPEZA\n",
    "# =============================================================================\n",
    "\n",
    "def clean_empty_keys(df):\n",
    "    \"\"\"Remove registros com chaves (CPF, SAFRA) vazias.\"\"\"\n",
    "    return df.dropna(subset=['NUM_CPF', 'SAFRA'])\n",
    "\n",
    "\n",
    "def convert_cep3_uf_regiao(df):\n",
    "    \"\"\"Converte CEP_3_digitos em UF e Regiao via mapeamento.\"\"\"\n",
    "    cep_map = {\n",
    "        '01': ('SP', 'SUDESTE'), '02': ('SP', 'SUDESTE'), '03': ('SP', 'SUDESTE'),\n",
    "        '04': ('SP', 'SUDESTE'), '05': ('SP', 'SUDESTE'), '06': ('SP', 'SUDESTE'),\n",
    "        '07': ('SP', 'SUDESTE'), '08': ('SP', 'SUDESTE'), '09': ('SP', 'SUDESTE'),\n",
    "        '20': ('RJ', 'SUDESTE'), '21': ('RJ', 'SUDESTE'), '22': ('RJ', 'SUDESTE'),\n",
    "        '23': ('RJ', 'SUDESTE'), '24': ('RJ', 'SUDESTE'),\n",
    "        '29': ('ES', 'SUDESTE'),\n",
    "        '30': ('MG', 'SUDESTE'), '31': ('MG', 'SUDESTE'), '32': ('MG', 'SUDESTE'),\n",
    "        '33': ('MG', 'SUDESTE'), '34': ('MG', 'SUDESTE'), '35': ('MG', 'SUDESTE'),\n",
    "        '36': ('MG', 'SUDESTE'), '37': ('MG', 'SUDESTE'), '38': ('MG', 'SUDESTE'),\n",
    "        '39': ('MG', 'SUDESTE'),\n",
    "        '40': ('BA', 'NORDESTE'), '41': ('BA', 'NORDESTE'), '42': ('BA', 'NORDESTE'),\n",
    "        '43': ('BA', 'NORDESTE'), '44': ('BA', 'NORDESTE'), '45': ('BA', 'NORDESTE'),\n",
    "        '46': ('BA', 'NORDESTE'), '47': ('BA', 'NORDESTE'), '48': ('BA', 'NORDESTE'),\n",
    "        '49': ('SE', 'NORDESTE'),\n",
    "        '50': ('PE', 'NORDESTE'), '51': ('PE', 'NORDESTE'), '52': ('PE', 'NORDESTE'),\n",
    "        '53': ('PE', 'NORDESTE'), '54': ('PE', 'NORDESTE'), '55': ('PE', 'NORDESTE'),\n",
    "        '56': ('AL', 'NORDESTE'), '57': ('AL', 'NORDESTE'),\n",
    "        '58': ('PB', 'NORDESTE'), '59': ('RN', 'NORDESTE'),\n",
    "        '60': ('CE', 'NORDESTE'), '61': ('CE', 'NORDESTE'), '62': ('CE', 'NORDESTE'),\n",
    "        '63': ('PI', 'NORDESTE'), '64': ('PI', 'NORDESTE'),\n",
    "        '65': ('MA', 'NORDESTE'),\n",
    "        '66': ('PA', 'NORTE'), '67': ('PA', 'NORTE'),\n",
    "        '68': ('AC', 'NORTE'), '69': ('AM', 'NORTE'),\n",
    "        '77': ('TO', 'NORTE'),\n",
    "        '70': ('DF', 'CENTRO-OESTE'), '71': ('DF', 'CENTRO-OESTE'),\n",
    "        '72': ('GO', 'CENTRO-OESTE'), '73': ('GO', 'CENTRO-OESTE'),\n",
    "        '74': ('GO', 'CENTRO-OESTE'), '75': ('GO', 'CENTRO-OESTE'),\n",
    "        '76': ('GO', 'CENTRO-OESTE'),\n",
    "        '78': ('MT', 'CENTRO-OESTE'), '79': ('MS', 'CENTRO-OESTE'),\n",
    "        '80': ('PR', 'SUL'), '81': ('PR', 'SUL'), '82': ('PR', 'SUL'),\n",
    "        '83': ('PR', 'SUL'), '84': ('PR', 'SUL'), '85': ('PR', 'SUL'),\n",
    "        '86': ('PR', 'SUL'), '87': ('PR', 'SUL'),\n",
    "        '88': ('SC', 'SUL'), '89': ('SC', 'SUL'),\n",
    "        '90': ('RS', 'SUL'), '91': ('RS', 'SUL'), '92': ('RS', 'SUL'),\n",
    "        '93': ('RS', 'SUL'), '94': ('RS', 'SUL'), '95': ('RS', 'SUL'),\n",
    "        '96': ('RS', 'SUL'), '97': ('RS', 'SUL'), '98': ('RS', 'SUL'),\n",
    "        '99': ('RS', 'SUL'),\n",
    "    }\n",
    "    if 'CEP_3_digitos' not in df.columns:\n",
    "        return df\n",
    "    cep2 = df['CEP_3_digitos'].astype(str).str[:2]\n",
    "    mapped = cep2.map(cep_map)\n",
    "    df['UF'] = mapped.apply(lambda x: x[0] if isinstance(x, tuple) else 'OUTROS')\n",
    "    df['REGIAO'] = mapped.apply(lambda x: x[1] if isinstance(x, tuple) else 'OUTROS')\n",
    "    df = df.drop(columns=['CEP_3_digitos'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def adjust_and_drop_date_cols(df):\n",
    "    \"\"\"Cria features datediff e remove colunas de data.\"\"\"\n",
    "    if 'var_12' in df.columns:\n",
    "        df['var_12'] = pd.to_datetime(df['var_12'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['DATA_REF_SAFRA'] = pd.to_datetime(df['SAFRA'].astype(str), format='%Y%m')\n",
    "    if 'var_12' in df.columns:\n",
    "        df['DIAS_VAR_12'] = (df['DATA_REF_SAFRA'] - df['var_12']).dt.days\n",
    "    if 'PAG_DT_PRIMEIRA_FATURA' in df.columns:\n",
    "        df['PAG_DT_PRIMEIRA_FATURA'] = pd.to_datetime(df['PAG_DT_PRIMEIRA_FATURA'], errors='coerce')\n",
    "        df['PAG_DIAS_DESDE_PRIMEIRA_FATURA'] = (df['DATA_REF_SAFRA'] - df['PAG_DT_PRIMEIRA_FATURA']).dt.days\n",
    "    date_cols = df.select_dtypes(include=['datetime64', 'datetimetz']).columns.tolist()\n",
    "    date_cols.append('DATA_REF_SAFRA')\n",
    "    df = df.drop(columns=[c for c in date_cols if c in df.columns])\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_high_missing(df, threshold=0.75):\n",
    "    \"\"\"Remove colunas com mais de threshold% de missing.\"\"\"\n",
    "    null_pct = df.isnull().mean()\n",
    "    cols_to_drop = null_pct[null_pct >= threshold].index.tolist()\n",
    "    print(f'  High missing (>= {threshold:.0%}): {len(cols_to_drop)} colunas removidas')\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "def remove_low_cardinality(df):\n",
    "    \"\"\"Remove colunas com apenas 1 valor unico.\"\"\"\n",
    "    low_card = [c for c in df.columns if df[c].nunique() <= 1]\n",
    "    print(f'  Low cardinality (== 1): {len(low_card)} colunas removidas')\n",
    "    return df.drop(columns=low_card)\n",
    "\n",
    "\n",
    "def remove_high_correlation(df, threshold=0.8, safras_train=None):\n",
    "    \"\"\"Remove colunas com correlacao > threshold (apenas nas safras de treino).\"\"\"\n",
    "    if safras_train is not None:\n",
    "        df_corr_base = df[df['SAFRA'].isin(safras_train)]\n",
    "    else:\n",
    "        df_corr_base = df\n",
    "    df_sample = df_corr_base.groupby(['SAFRA', 'FPD'], group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=0.25, random_state=42)\n",
    "    )\n",
    "    num_cols = df_sample.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns\n",
    "    num_cols = [c for c in num_cols if c != 'FPD']\n",
    "    corr_matrix = df_sample[num_cols].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = []\n",
    "    while True:\n",
    "        max_corr = upper.max().max()\n",
    "        if max_corr < threshold:\n",
    "            break\n",
    "        col_to_drop = upper.max().sort_values(ascending=False).index[0]\n",
    "        to_drop.append(col_to_drop)\n",
    "        upper = upper.drop(index=col_to_drop, columns=col_to_drop)\n",
    "    print(f'  High correlation (> {threshold}): {len(to_drop)} colunas removidas')\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "\n",
    "def remove_misused_columns(df):\n",
    "    \"\"\"Remove colunas de leakage e duplicatas conhecidas.\"\"\"\n",
    "    misused = ['PROD', 'flag_mig2', 'FAT_VLR_FPD', 'FAT_FLAG_MIG2_AQUISICAO']\n",
    "    existing = [c for c in misused if c in df.columns]\n",
    "    if existing:\n",
    "        print(f'  Misused columns removed: {existing}')\n",
    "    return df.drop(columns=existing, errors='ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 4.2 APLICAR LIMPEZAS\n",
    "# =============================================================================\n",
    "safras_train_val = SAFRAS[:4]  # 202410, 202411, 202412, 202501\n",
    "\n",
    "print('Aplicando limpezas...')\n",
    "print(f'Shape original: {df.shape}')\n",
    "\n",
    "df = clean_empty_keys(df)\n",
    "df = convert_cep3_uf_regiao(df)\n",
    "df = adjust_and_drop_date_cols(df)\n",
    "df = remove_high_missing(df)\n",
    "df = remove_low_cardinality(df)\n",
    "df = remove_high_correlation(df, threshold=0.8, safras_train=safras_train_val)\n",
    "df = remove_misused_columns(df)\n",
    "\n",
    "print(f'Shape apos limpezas: {df.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Temporal e Amostragem Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5. SPLIT TEMPORAL + AMOSTRAGEM ESTRATIFICADA\n",
    "# =============================================================================\n",
    "# Nota: FLAG_INSTALACAO ja filtrado no Spark (Cell 3) — df contem apenas pos-instalacao\n",
    "\n",
    "# Separar safras\n",
    "safras_ord = sorted(df['SAFRA'].unique())\n",
    "safras_train_oos = safras_ord[:4]  # 202410-202501\n",
    "safras_oot = safras_ord[4:]        # 202502-202503\n",
    "\n",
    "df_4_safras = df[df['SAFRA'].isin(safras_train_oos)]\n",
    "df_oot_full = df[df['SAFRA'].isin(safras_oot)]\n",
    "\n",
    "# Amostragem estratificada 25% por (SAFRA, FPD)\n",
    "df_sample = df_4_safras.groupby(['SAFRA', 'FPD'], group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.25, random_state=42)\n",
    ")\n",
    "df_oos = df_4_safras.drop(df_sample.index)\n",
    "\n",
    "# Reset indices\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "df_oos = df_oos.reset_index(drop=True)\n",
    "df_oot = df_oot_full.reset_index(drop=True)\n",
    "\n",
    "# Remover duplicatas\n",
    "df_sample = df_sample.drop_duplicates()\n",
    "df_oos = df_oos.drop_duplicates()\n",
    "df_oot = df_oot.drop_duplicates()\n",
    "\n",
    "# Liberar df original (nao mais necessario apos split)\n",
    "del df, df_4_safras, df_oot_full\n",
    "gc.collect()\n",
    "\n",
    "print(f'Shapes finais:')\n",
    "print(f'  Sample (train+val): {df_sample.shape}')\n",
    "print(f'  OOS:                {df_oos.shape}')\n",
    "print(f'  OOT:                {df_oot.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5.1 VERIFICAR VOLUMETRIA POR SAFRA E TARGET\n",
    "# =============================================================================\n",
    "for name, data in [('Sample', df_sample), ('OOS', df_oos), ('OOT', df_oot)]:\n",
    "    print(f'\\n--- {name} ---')\n",
    "    print(data[['SAFRA', 'FPD']].value_counts().sort_index().to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Separacao Treino / Validacao e Preparacao X/Y"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 6. SEPARACAO TREINO / VALIDACAO / X / Y\n",
    "# =============================================================================\n",
    "safras_train = [202410, 202411, 202412]\n",
    "safras_val = [202501]\n",
    "\n",
    "df_train = df_sample[df_sample['SAFRA'].isin(safras_train)]\n",
    "df_val = df_sample[df_sample['SAFRA'].isin(safras_val)]\n",
    "\n",
    "X_train = df_train.drop(columns=['FPD'])\n",
    "y_train = df_train['FPD']\n",
    "\n",
    "X_val = df_val.drop(columns=['FPD'])\n",
    "y_val = df_val['FPD']\n",
    "\n",
    "# Train + Val combinado para treino final\n",
    "X_train_final = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_train_final = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# OOS e OOT\n",
    "X_oos_agg = df_oos.drop(columns=['FPD'])\n",
    "y_oos_agg = df_oos['FPD']\n",
    "\n",
    "X_oot_agg = df_oot.drop(columns=['FPD'])\n",
    "y_oot_agg = df_oot['FPD']\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_val:   {X_val.shape}')\n",
    "print(f'X_train_final: {X_train_final.shape}')\n",
    "print(f'X_oos: {X_oos_agg.shape}')\n",
    "print(f'X_oot: {X_oot_agg.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Separacao de Variaveis por Tipo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 7. VARIAVEIS NUMERICAS E CATEGORICAS\n",
    "# =============================================================================\n",
    "num_features = [\n",
    "    n for n in X_train.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns\n",
    "    if n != 'SAFRA'\n",
    "]\n",
    "cat_features = [\n",
    "    c for c in X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    if c != 'NUM_CPF'\n",
    "]\n",
    "\n",
    "print(f'Numericas: {len(num_features)}')\n",
    "print(f'Categoricas: {len(cat_features)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Montagem dos Pipelines sklearn"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 8. PIPELINES\n",
    "# =============================================================================\n",
    "\n",
    "# --- Regressao Logistica ---\n",
    "numeric_pipe_rl = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_pipe_rl = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', CountEncoder(normalize=True)),\n",
    "])\n",
    "preprocess_rl = ColumnTransformer([\n",
    "    ('num', numeric_pipe_rl, num_features),\n",
    "    ('cat', categorical_pipe_rl, cat_features),\n",
    "])\n",
    "pipeline_RL = Pipeline([\n",
    "    ('prep', preprocess_rl),\n",
    "    ('model', LogisticRegression(\n",
    "        solver='liblinear', penalty='l1',\n",
    "        max_iter=2000, tol=1e-3,\n",
    "        class_weight='balanced', random_state=42,\n",
    "    )),\n",
    "])\n",
    "\n",
    "# --- LightGBM ---\n",
    "numeric_pipe_lgbm = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "categorical_pipe_lgbm = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0)),\n",
    "])\n",
    "preprocess_lgbm = ColumnTransformer([\n",
    "    ('num', numeric_pipe_lgbm, num_features),\n",
    "    ('cat', categorical_pipe_lgbm, cat_features),\n",
    "], remainder='drop')\n",
    "pipeline_LGBM = Pipeline([\n",
    "    ('prep', preprocess_lgbm),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary', boosting_type='gbdt',\n",
    "        learning_rate=0.05, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1, verbosity=-1,\n",
    "    )),\n",
    "])\n",
    "\n",
    "print('Pipelines criados: RL (prep) + LGBM (prep)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ajuste de Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 9.1 GRID SEARCH - REGRESSAO LOGISTICA\n",
    "# =============================================================================\n",
    "param_grid_RL = {'model__C': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid_RL = GridSearchCV(\n",
    "    pipeline_RL, param_grid=param_grid_RL,\n",
    "    scoring='roc_auc', cv=cv, n_jobs=-1, verbose=3,\n",
    ")\n",
    "grid_RL.fit(X_val, y_val)\n",
    "\n",
    "print(f'Melhores HP RL: {grid_RL.best_params_}')\n",
    "print(f'Melhor AUC RL:  {grid_RL.best_score_:.5f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Treino final RL com best params (train + val)\n",
    "pipeline_RL.set_params(**grid_RL.best_params_)\n",
    "pipeline_RL.fit(X_train_final, y_train_final)\n",
    "print('RL treinado com train+val')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 9.2 GRID SEARCH - LIGHTGBM\n",
    "# =============================================================================\n",
    "param_grid_LGBM = {\n",
    "    'model__n_estimators': [250, 500],\n",
    "    'model__max_depth': [4, 7],\n",
    "}\n",
    "\n",
    "grid_LGBM = GridSearchCV(\n",
    "    pipeline_LGBM, param_grid=param_grid_LGBM,\n",
    "    scoring='roc_auc', cv=cv, n_jobs=-1, verbose=3, error_score='raise',\n",
    ")\n",
    "grid_LGBM.fit(X_val, y_val)\n",
    "\n",
    "print(f'Melhores HP LGBM: {grid_LGBM.best_params_}')\n",
    "print(f'Melhor AUC LGBM:  {grid_LGBM.best_score_:.5f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Treino final LGBM com best params (train + val)\n",
    "pipeline_LGBM.set_params(**grid_LGBM.best_params_)\n",
    "pipeline_LGBM.fit(X_train_final, y_train_final)\n",
    "print('LGBM treinado com train+val')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Avaliacao por Safra (AUC e KS)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 10. FUNCOES DE AVALIACAO\n",
    "# =============================================================================\n",
    "\n",
    "def ks_stat(y_true, y_score):\n",
    "    \"\"\"Calcula KS statistic.\"\"\"\n",
    "    df_ks = pd.DataFrame({'y': y_true.values, 'p': y_score})\n",
    "    df_ks = df_ks.sort_values('p')\n",
    "    df_ks['cum_good'] = (1 - df_ks['y']).cumsum() / (1 - df_ks['y']).sum()\n",
    "    df_ks['cum_bad'] = df_ks['y'].cumsum() / df_ks['y'].sum()\n",
    "    return np.max(np.abs(df_ks['cum_bad'] - df_ks['cum_good']))\n",
    "\n",
    "\n",
    "def evaluation_auc_ks(X, y, pipe, name='', verbose=True):\n",
    "    \"\"\"Calcula AUC e KS para um dado split.\"\"\"\n",
    "    proba = pipe.predict_proba(X)[:, 1]\n",
    "    auc = round(roc_auc_score(y, proba), 5)\n",
    "    ks = round(ks_stat(y, proba), 5)\n",
    "    if verbose:\n",
    "        print(f'AVALIACAO {name}: AUC={auc}, KS={ks}')\n",
    "        print('-' * 40)\n",
    "    return auc, ks\n",
    "\n",
    "\n",
    "def filter_xy_by_safra(X, y, list_safras):\n",
    "    \"\"\"Filtra X e y por lista de SAFRAs.\"\"\"\n",
    "    mask = X['SAFRA'].isin(list_safras)\n",
    "    return X[mask], y.loc[X[mask].index]\n",
    "\n",
    "\n",
    "def _sanitize_mlflow_key(key):\n",
    "    \"\"\"Sanitiza nome de metrica para MLflow Fabric.\n",
    "\n",
    "    Fabric MLflow rejeita backslash, barras e outros caracteres especiais.\n",
    "    Mantem apenas alfanumericos, underscore e hifen.\n",
    "    Colapsa underscores consecutivos em um unico.\n",
    "    \"\"\"\n",
    "    safe = re.sub(r'[^a-zA-Z0-9_\\-]', '_', key)\n",
    "    safe = re.sub(r'_+', '_', safe)\n",
    "    return safe.strip('_')\n",
    "\n",
    "\n",
    "# Mapa de splits para avaliacao\n",
    "dict_safras = {\n",
    "    'TREINO - 202410': [202410],\n",
    "    'TREINO - 202411': [202411],\n",
    "    'TREINO - 202412': [202412],\n",
    "    'TREINO / VAL - 202501': [202501],\n",
    "    'TREINO (CONS)': [202410, 202411, 202412, 202501],\n",
    "    'OOS - 202410': [202410],\n",
    "    'OOS - 202411': [202411],\n",
    "    'OOS - 202412': [202412],\n",
    "    'OOS - 202501': [202501],\n",
    "    'OOS (CONS)': [202410, 202411, 202412, 202501],\n",
    "    'OOT - 202502': [202502],\n",
    "    'OOT - 202503': [202503],\n",
    "    'OOT GERAL (CONS)': [202502, 202503],\n",
    "}\n",
    "\n",
    "\n",
    "def generate_map_step_data(X_train, y_train, X_oos, y_oos, X_oot, y_oot):\n",
    "    \"\"\"Gera mapa de datasets por split.\"\"\"\n",
    "    return {\n",
    "        'TREINO - 202410': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO - 202411': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO - 202412': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO / VAL - 202501': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO (CONS)': {'X': X_train, 'Y': y_train},\n",
    "        'OOS - 202410': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS - 202411': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS - 202412': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS - 202501': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS (CONS)': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOT - 202502': {'X': X_oot, 'Y': y_oot},\n",
    "        'OOT - 202503': {'X': X_oot, 'Y': y_oot},\n",
    "        'OOT GERAL (CONS)': {'X': X_oot, 'Y': y_oot},\n",
    "    }\n",
    "\n",
    "\n",
    "def log_safra_metrics_mlflow(model_name, dict_safras, X_train, y_train,\n",
    "                              X_oos, y_oos, X_oot, y_oot, pipeline):\n",
    "    \"\"\"Loga metricas AUC e KS por safra no MLflow.\"\"\"\n",
    "    results = {}\n",
    "    for key in dict_safras:\n",
    "        map_data = generate_map_step_data(X_train, y_train, X_oos, y_oos, X_oot, y_oot)\n",
    "        X = map_data[key]['X']\n",
    "        y = map_data[key]['Y']\n",
    "        X_f, y_f = filter_xy_by_safra(X, y, dict_safras[key])\n",
    "        auc, ks = evaluation_auc_ks(X_f, y_f, pipeline, key)\n",
    "        safe_key = _sanitize_mlflow_key(key)\n",
    "        mlflow.log_metric(f'{model_name}_AUC_{safe_key}', auc)\n",
    "        mlflow.log_metric(f'{model_name}_KS_{safe_key}', ks)\n",
    "        results[key] = {'AUC': auc, 'KS': ks}\n",
    "    return results\n",
    "\n",
    "print('Funcoes de avaliacao carregadas')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 10.1 AVALIACAO - REGRESSAO LOGISTICA\n",
    "# =============================================================================\n",
    "with mlflow.start_run(run_name='LogisticRegression_Baseline') as run_rl:\n",
    "    params_rl = pipeline_RL.named_steps['model'].get_params()\n",
    "    mlflow.log_param('model_type', 'LogisticRegression')\n",
    "    mlflow.log_param('penalty', params_rl.get('penalty', 'l1'))\n",
    "    mlflow.log_param('solver', params_rl.get('solver'))\n",
    "    mlflow.log_param('C', params_rl.get('C'))\n",
    "    mlflow.log_param('max_iter', params_rl.get('max_iter'))\n",
    "    mlflow.log_param('n_features', len(X_train_final.columns))\n",
    "    mlflow.log_param('n_samples_train', len(X_train_final))\n",
    "\n",
    "    print('Avaliacao RL por base:')\n",
    "    results_rl = log_safra_metrics_mlflow(\n",
    "        'RL', dict_safras, X_train_final, y_train_final,\n",
    "        X_oos_agg, y_oos_agg, X_oot_agg, y_oot_agg, pipeline_RL,\n",
    "    )\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_RL, 'model_logistic_regression')\n",
    "\n",
    "    coefs = pipeline_RL.named_steps['model'].coef_[0]\n",
    "    feat_names = pipeline_RL.named_steps['prep'].get_feature_names_out()\n",
    "    df_coefs = pd.DataFrame({'feature': feat_names, 'coef': coefs}).sort_values('coef', key=abs, ascending=False)\n",
    "    df_coefs.to_csv('/tmp/lr_coefficients.csv', index=False)\n",
    "    mlflow.log_artifact('/tmp/lr_coefficients.csv', 'feature_analysis')\n",
    "\n",
    "    print(f'\\nMLflow Run ID (RL): {run_rl.info.run_id}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 10.2 AVALIACAO - LIGHTGBM\n",
    "# =============================================================================\n",
    "with mlflow.start_run(run_name='LightGBM_Baseline') as run_lgbm:\n",
    "    params_lgbm = pipeline_LGBM.named_steps['model'].get_params()\n",
    "    mlflow.log_param('model_type', 'LightGBM')\n",
    "    mlflow.log_param('n_estimators', params_lgbm.get('n_estimators'))\n",
    "    mlflow.log_param('max_depth', params_lgbm.get('max_depth'))\n",
    "    mlflow.log_param('learning_rate', params_lgbm.get('learning_rate'))\n",
    "    mlflow.log_param('num_leaves', params_lgbm.get('num_leaves'))\n",
    "    mlflow.log_param('boosting_type', params_lgbm.get('boosting_type', 'gbdt'))\n",
    "    mlflow.log_param('n_features', len(X_train_final.columns))\n",
    "    mlflow.log_param('n_samples_train', len(X_train_final))\n",
    "\n",
    "    print('Avaliacao LGBM por base:')\n",
    "    results_lgbm = log_safra_metrics_mlflow(\n",
    "        'LGBM', dict_safras, X_train_final, y_train_final,\n",
    "        X_oos_agg, y_oos_agg, X_oot_agg, y_oot_agg, pipeline_LGBM,\n",
    "    )\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_LGBM, 'model_lightgbm')\n",
    "\n",
    "    lgbm_model = pipeline_LGBM.named_steps['model']\n",
    "    feat_names_lgbm = pipeline_LGBM.named_steps['prep'].get_feature_names_out()\n",
    "    df_importance = pd.DataFrame({\n",
    "        'feature': feat_names_lgbm,\n",
    "        'importance': lgbm_model.feature_importances_,\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    df_importance.to_csv('/tmp/lgbm_feature_importance.csv', index=False)\n",
    "    mlflow.log_artifact('/tmp/lgbm_feature_importance.csv', 'feature_analysis')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_30 = df_importance.head(30)\n",
    "    ax.barh(range(len(top_30)), top_30['importance'].values)\n",
    "    ax.set_yticks(range(len(top_30)))\n",
    "    ax.set_yticklabels(top_30['feature'].values, fontsize=8)\n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_title('Top 30 Features - LightGBM')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('/tmp/lgbm_feature_importance.png', dpi=150)\n",
    "    mlflow.log_artifact('/tmp/lgbm_feature_importance.png', 'plots')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'\\nMLflow Run ID (LGBM): {run_lgbm.info.run_id}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Analise Incremental de KS por Fonte"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 11. FUNCAO AUXILIAR: UPDATE PIPELINE + VAR CLASSIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "def _var_num(col):\n",
    "    \"\"\"Extrai numero de colunas var_XX para comparacao numerica.\"\"\"\n",
    "    m = re.search(r'var_(\\d+)', col)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def update_pipeline(X, name_model):\n",
    "    \"\"\"Reconstroi pipeline com features atuais.\"\"\"\n",
    "    nf = [n for n in X.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns if n != 'SAFRA']\n",
    "    cf = [c for c in X.select_dtypes(include=['object', 'category']).columns if c != 'NUM_CPF']\n",
    "\n",
    "    if name_model == 'Reg Log':\n",
    "        num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "        cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', CountEncoder(normalize=True))])\n",
    "        prep = ColumnTransformer([('num', num_pipe, nf), ('cat', cat_pipe, cf)])\n",
    "        model = LogisticRegression(\n",
    "            solver='liblinear', penalty='l1', max_iter=2000,\n",
    "            C=grid_RL.best_params_['model__C'],\n",
    "            tol=1e-3, class_weight='balanced', random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "        cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                             ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0))])\n",
    "        prep = ColumnTransformer([('num', num_pipe, nf), ('cat', cat_pipe, cf)], remainder='drop')\n",
    "        model = LGBMClassifier(\n",
    "            objective='binary', boosting_type='gbdt', learning_rate=0.05,\n",
    "            max_depth=grid_LGBM.best_params_['model__max_depth'],\n",
    "            n_estimators=grid_LGBM.best_params_['model__n_estimators'],\n",
    "            colsample_bytree=0.8, random_state=42, n_jobs=-1, verbosity=-1,\n",
    "        )\n",
    "\n",
    "    return Pipeline([('prep', prep), ('model', model)])\n",
    "\n",
    "\n",
    "def current_step(step_num):\n",
    "    \"\"\"Nome do incremento de features.\"\"\"\n",
    "    return {\n",
    "        0: 'SC 1', 1: 'SC 1 + SC 2', 2: 'SC 1 + SC 2 + CAD',\n",
    "        3: 'SC 1 + SC 2 + CAD + TELCO', 4: 'SC 1 + SC 2 + CAD + TELCO + REC',\n",
    "        5: 'SC 1 + SC 2 + CAD + TELCO + REC + PAG',\n",
    "        6: 'SC 1 + SC 2 + CAD + TELCO + REC + PAG + FAT',\n",
    "    }[step_num]\n",
    "\n",
    "print('Funcoes auxiliares carregadas')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 11.1 KS INCREMENTAL POR FONTE\n",
    "# =============================================================================\n",
    "feat_score_1 = ['TARGET_SCORE_01']\n",
    "feat_score_2 = ['TARGET_SCORE_02']\n",
    "feats_cadastro = [x for x in X_train_final.columns if 'var_' in x and _var_num(x) <= 25] + ['STATUSRF', 'UF', 'REGIAO', 'DIAS_VAR_12']\n",
    "feats_telco = [x for x in X_train_final.columns if 'var_' in x and _var_num(x) >= 26]\n",
    "feats_recargas = [x for x in X_train_final.columns if x.startswith('REC_')]\n",
    "feats_pagamentos = [x for x in X_train_final.columns if x.startswith('PAG_')]\n",
    "feats_faturamento = [x for x in X_train_final.columns if x.startswith('FAT_')]\n",
    "\n",
    "list_sources = [feat_score_1, feat_score_2, feats_cadastro, feats_telco, feats_recargas, feats_pagamentos, feats_faturamento]\n",
    "list_features = ['NUM_CPF', 'SAFRA']\n",
    "list_dict_results = []\n",
    "list_models = ['Reg Log', 'LGBM']\n",
    "\n",
    "for idx, source in enumerate(list_sources):\n",
    "    list_features.extend(source)\n",
    "\n",
    "    X_tr_filt = X_train_final[list_features]\n",
    "    X_oos_filt = X_oos_agg[list_features]\n",
    "    X_oot_filt = X_oot_agg[list_features]\n",
    "\n",
    "    for model in list_models:\n",
    "        pipe = update_pipeline(X_tr_filt, name_model=model)\n",
    "        pipe.fit(X_tr_filt, y_train_final)\n",
    "\n",
    "        for key in dict_safras:\n",
    "            map_data = generate_map_step_data(\n",
    "                X_tr_filt, y_train_final,\n",
    "                X_oos_filt, y_oos_agg,\n",
    "                X_oot_filt, y_oot_agg,\n",
    "            )\n",
    "            X_f, y_f = filter_xy_by_safra(map_data[key]['X'], map_data[key]['Y'], dict_safras[key])\n",
    "            auc, ks = evaluation_auc_ks(X_f, y_f, pipe, key, verbose=False)\n",
    "            list_dict_results.append({\n",
    "                'MODELO': model, 'CONJ FEATURES': current_step(idx),\n",
    "                'BASE': key, 'AUC': auc, 'KS': ks,\n",
    "            })\n",
    "\n",
    "df_results_ks_inc = pd.DataFrame(list_dict_results)\n",
    "\n",
    "print('\\n--- TREINO (CONS) ---')\n",
    "display(df_results_ks_inc[df_results_ks_inc['BASE'] == 'TREINO (CONS)'])\n",
    "\n",
    "print('\\n--- OOT GERAL (CONS) ---')\n",
    "display(df_results_ks_inc[df_results_ks_inc['BASE'] == 'OOT GERAL (CONS)'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Selection (SHAP TreeExplainer)\n",
    "\n",
    "Abordagem baseada em SHAP — mede contribuicao real de cada feature\n",
    "para a predicao de FPD, capturando interacoes que IV univariado nao detecta.\n",
    "\n",
    "Pipeline:\n",
    "1. Treinar LGBM com todas as features\n",
    "2. Calcular SHAP values via TreeExplainer\n",
    "3. Ranking global por mean(|SHAP|)\n",
    "4. Selecionar features que acumulam 90% da importancia\n",
    "5. Gerar visualizacoes por book para apresentacao"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# 12.1 TREINAR LGBM PARA SHAP (TODAS FEATURES)\n",
    "# =============================================================================\n",
    "# Remove cadastro (baixo ganho historico) — manter score, telco, books\n",
    "import re\n",
    "\n",
    "def _var_num(col):\n",
    "    m = re.search(r'var_(\\d+)', col)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "feats_cadastro = [\n",
    "    x for x in X_train_final.columns\n",
    "    if 'var_' in x and _var_num(x) <= 25\n",
    "] + ['STATUSRF', 'UF', 'REGIAO', 'DIAS_VAR_12']\n",
    "feats_cadastro = [c for c in feats_cadastro if c in X_train_final.columns]\n",
    "\n",
    "feats_to_use = [c for c in X_train_final.columns if c not in feats_cadastro\n",
    "                and c not in ['NUM_CPF', 'SAFRA']]\n",
    "\n",
    "X_shap = X_train_final[feats_to_use].copy()\n",
    "\n",
    "num_shap = [n for n in X_shap.select_dtypes(include=['int32','int64','float32','float64']).columns]\n",
    "cat_shap = [c for c in X_shap.select_dtypes(include=['object','category']).columns]\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import CountEncoder\n",
    "\n",
    "num_pipe_shap = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "cat_pipe_shap = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0)),\n",
    "])\n",
    "prep_shap = ColumnTransformer([\n",
    "    ('num', num_pipe_shap, num_shap),\n",
    "    ('cat', cat_pipe_shap, cat_shap),\n",
    "], remainder='drop')\n",
    "\n",
    "lgbm_shap = LGBMClassifier(\n",
    "    objective='binary', boosting_type='gbdt',\n",
    "    learning_rate=0.05, n_estimators=300, max_depth=7,\n",
    "    colsample_bytree=0.8, subsample=0.8,\n",
    "    random_state=42, n_jobs=-1, verbosity=-1,\n",
    ")\n",
    "pipe_shap = Pipeline([('prep', prep_shap), ('model', lgbm_shap)])\n",
    "pipe_shap.fit(X_shap, y_train_final)\n",
    "\n",
    "print(f'LGBM treinado para SHAP: {len(feats_to_use)} features ({len(num_shap)} num + {len(cat_shap)} cat)')\n",
    "print(f'Cadastro removido: {len(feats_cadastro)} features')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# 12.2 CALCULAR SHAP VALUES (TreeExplainer)\n",
    "# =============================================================================\n",
    "X_shap_transformed = pipe_shap.named_steps['prep'].transform(X_shap)\n",
    "\n",
    "try:\n",
    "    transformed_names = pipe_shap.named_steps['prep'].get_feature_names_out()\n",
    "except Exception:\n",
    "    transformed_names = num_shap + cat_shap\n",
    "\n",
    "explainer = shap.TreeExplainer(pipe_shap.named_steps['model'])\n",
    "shap_values = explainer.shap_values(X_shap_transformed)\n",
    "\n",
    "# Para classificacao binaria, pode ser lista [class_0, class_1]\n",
    "if isinstance(shap_values, list):\n",
    "    shap_vals = shap_values[1]  # FPD=1\n",
    "else:\n",
    "    shap_vals = shap_values\n",
    "\n",
    "print(f'SHAP values: {shap_vals.shape}')\n",
    "\n",
    "# Ranking global por mean(|SHAP|)\n",
    "mean_abs_shap = np.abs(shap_vals).mean(axis=0)\n",
    "df_shap_ranking = pd.DataFrame({\n",
    "    'feature_transformed': list(transformed_names),\n",
    "    'mean_abs_shap': mean_abs_shap,\n",
    "}).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mapear para nome original\n",
    "df_shap_ranking['feature'] = df_shap_ranking['feature_transformed'].apply(\n",
    "    lambda x: x.split('__', 1)[-1] if '__' in x else x\n",
    ")\n",
    "\n",
    "def get_book_label(feat):\n",
    "    if feat.startswith('REC_'): return 'Recarga (REC_)'\n",
    "    elif feat.startswith('PAG_'): return 'Pagamento (PAG_)'\n",
    "    elif feat.startswith('FAT_'): return 'Faturamento (FAT_)'\n",
    "    return 'Base (Telco+Score)'\n",
    "\n",
    "df_shap_ranking['book'] = df_shap_ranking['feature'].apply(get_book_label)\n",
    "total_shap = df_shap_ranking['mean_abs_shap'].sum()\n",
    "df_shap_ranking['pct_importance'] = df_shap_ranking['mean_abs_shap'] / total_shap\n",
    "df_shap_ranking['cumulative_pct'] = df_shap_ranking['pct_importance'].cumsum()\n",
    "df_shap_ranking['rank'] = range(1, len(df_shap_ranking) + 1)\n",
    "\n",
    "print(f'\\nTop 20 Features (SHAP):')\n",
    "print(df_shap_ranking[['rank','feature','book','mean_abs_shap','pct_importance','cumulative_pct']].head(20).to_string(index=False))\n",
    "\n",
    "# Contribuicao por book\n",
    "print(f'\\nContribuicao por Book:')\n",
    "for book in ['Base (Telco+Score)', 'Recarga (REC_)', 'Pagamento (PAG_)', 'Faturamento (FAT_)']:\n",
    "    pct = df_shap_ranking[df_shap_ranking['book'] == book]['mean_abs_shap'].sum() / total_shap * 100\n",
    "    n = len(df_shap_ranking[df_shap_ranking['book'] == book])\n",
    "    print(f'  {book}: {pct:.1f}% ({n} features)')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# 12.3 VISUALIZACOES SHAP PARA APRESENTACAO\n",
    "# =============================================================================\n",
    "BOOK_COLORS = {\n",
    "    'Base (Telco+Score)': '#607D8B',\n",
    "    'Recarga (REC_)': '#2196F3',\n",
    "    'Pagamento (PAG_)': '#FF9800',\n",
    "    'Faturamento (FAT_)': '#9C27B0',\n",
    "}\n",
    "\n",
    "def get_feature_color(feat):\n",
    "    if feat.startswith('REC_') or '__REC_' in feat: return BOOK_COLORS['Recarga (REC_)']\n",
    "    elif feat.startswith('PAG_') or '__PAG_' in feat: return BOOK_COLORS['Pagamento (PAG_)']\n",
    "    elif feat.startswith('FAT_') or '__FAT_' in feat: return BOOK_COLORS['Faturamento (FAT_)']\n",
    "    return BOOK_COLORS['Base (Telco+Score)']\n",
    "\n",
    "book_names = ['Base (Telco+Score)', 'Recarga (REC_)', 'Pagamento (PAG_)', 'Faturamento (FAT_)']\n",
    "\n",
    "# --- GRAFICO 1: SHAP Summary Beeswarm ---\n",
    "fig, ax = plt.subplots(figsize=(12, 14))\n",
    "shap.summary_plot(shap_vals, X_shap_transformed,\n",
    "                  feature_names=list(transformed_names), max_display=40, show=False)\n",
    "plt.title('SHAP Summary Plot - Top 40 Features (FPD)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/shap_summary_beeswarm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- GRAFICO 2: Top 30 colorido por Book ---\n",
    "top30 = df_shap_ranking.head(30)\n",
    "colors = [get_feature_color(f) for f in top30['feature']]\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.barh(range(len(top30)-1, -1, -1), top30['mean_abs_shap'].values,\n",
    "        color=colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "ax.set_yticks(range(len(top30)-1, -1, -1))\n",
    "ax.set_yticklabels(top30['feature'].values, fontsize=9)\n",
    "ax.set_xlabel('mean(|SHAP value|)', fontsize=11)\n",
    "ax.set_title('Top 30 Features por Importancia SHAP - Colorido por Book', fontsize=14, fontweight='bold')\n",
    "for i, (_, row) in enumerate(top30.iterrows()):\n",
    "    ax.text(row['mean_abs_shap'] + max(top30['mean_abs_shap'])*0.01,\n",
    "            len(top30)-1-i, f\"{row['pct_importance']:.1%}\", va='center', fontsize=8, color='#333')\n",
    "legend_elements = [Patch(facecolor=c, label=l) for l, c in BOOK_COLORS.items()]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.2, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/shap_top30_by_book.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Graficos 1-2 salvos')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# 12.4 VISUALIZACOES POR BOOK (Top 15 cada)\n",
    "# =============================================================================\n",
    "# --- GRAFICO 3: Top 15 por Book (4 subplots) ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Top 15 Features por Book - Importancia SHAP', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, book_name in enumerate(book_names):\n",
    "    ax = axes[idx // 2][idx % 2]\n",
    "    book_data = df_shap_ranking[df_shap_ranking['book'] == book_name].head(15)\n",
    "    if book_data.empty:\n",
    "        ax.set_title(f'{book_name} - sem features')\n",
    "        continue\n",
    "    color = BOOK_COLORS[book_name]\n",
    "    ax.barh(range(len(book_data)-1, -1, -1), book_data['mean_abs_shap'].values,\n",
    "            color=color, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "    ax.set_yticks(range(len(book_data)-1, -1, -1))\n",
    "    ax.set_yticklabels(book_data['feature'].values, fontsize=8)\n",
    "    ax.set_xlabel('mean(|SHAP value|)', fontsize=9)\n",
    "    total_book = df_shap_ranking[df_shap_ranking['book'] == book_name]['mean_abs_shap'].sum()\n",
    "    pct_global = total_book / total_shap * 100\n",
    "    n_total = len(df_shap_ranking[df_shap_ranking['book'] == book_name])\n",
    "    ax.set_title(f'{book_name}\\n{n_total} features | {pct_global:.1f}% importancia global',\n",
    "                fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.2, axis='x')\n",
    "    for i, (_, row) in enumerate(book_data.iterrows()):\n",
    "        ax.text(row['mean_abs_shap'] + max(book_data['mean_abs_shap'])*0.02,\n",
    "                len(book_data)-1-i, f\"{row['mean_abs_shap']:.4f}\", va='center', fontsize=7, color='#555')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig('/tmp/shap_top15_per_book.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- GRAFICO 4: Contribuicao por Book (Pie + Stacked) ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Contribuicao Agregada por Book', fontsize=14, fontweight='bold')\n",
    "ax1 = axes[0]\n",
    "book_pcts = []\n",
    "book_labels = []\n",
    "book_colors_list = []\n",
    "for bn in book_names:\n",
    "    tb = df_shap_ranking[df_shap_ranking['book'] == bn]['mean_abs_shap'].sum()\n",
    "    pct = tb / total_shap * 100\n",
    "    book_pcts.append(pct)\n",
    "    n = len(df_shap_ranking[df_shap_ranking['book'] == bn])\n",
    "    book_labels.append(f'{bn}\\n({n} vars, {pct:.1f}%)')\n",
    "    book_colors_list.append(BOOK_COLORS[bn])\n",
    "ax1.pie(book_pcts, labels=None, colors=book_colors_list,\n",
    "        autopct='%1.1f%%', startangle=90, pctdistance=0.7,\n",
    "        textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "ax1.legend(book_labels, loc='center left', bbox_to_anchor=(-0.3, 0.5), fontsize=9)\n",
    "ax1.set_title('% Importancia SHAP por Book', fontsize=12)\n",
    "ax2 = axes[1]\n",
    "bottom = np.zeros(1)\n",
    "for bn in book_names:\n",
    "    tb = df_shap_ranking[df_shap_ranking['book'] == bn]['mean_abs_shap'].sum()\n",
    "    ax2.bar(0, tb, bottom=bottom, color=BOOK_COLORS[bn], label=bn, edgecolor='white', linewidth=0.5, width=0.5)\n",
    "    mid = bottom[0] + tb / 2\n",
    "    pct = tb / total_shap * 100\n",
    "    if pct > 5:\n",
    "        ax2.text(0, mid, f'{pct:.1f}%', ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
    "    bottom += tb\n",
    "ax2.set_ylabel('Sum mean(|SHAP|)', fontsize=11)\n",
    "ax2.set_title('Importancia SHAP Empilhada', fontsize=12)\n",
    "ax2.set_xticks([0]); ax2.set_xticklabels(['Todas Features'])\n",
    "ax2.legend(loc='upper right', fontsize=9); ax2.grid(True, alpha=0.2, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/shap_book_contribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Graficos 3-4 salvos')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# 12.5 SELECAO FINAL — PARETO 90% CUMULATIVO\n",
    "# =============================================================================\n",
    "CUMULATIVE_THRESHOLD = 0.90\n",
    "\n",
    "# Grafico Pareto\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x_range = range(1, len(df_shap_ranking) + 1)\n",
    "colors_cum = [get_feature_color(f) for f in df_shap_ranking['feature']]\n",
    "ax.bar(x_range, df_shap_ranking['pct_importance'].values, color=colors_cum, alpha=0.7, width=1.0)\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x_range, df_shap_ranking['cumulative_pct'].values, color='red', linewidth=2)\n",
    "ax2.axhline(y=CUMULATIVE_THRESHOLD, color='red', linestyle='--', alpha=0.5)\n",
    "n_90 = (df_shap_ranking['cumulative_pct'] <= CUMULATIVE_THRESHOLD).sum()\n",
    "ax2.axvline(x=n_90, color='green', linestyle='--', alpha=0.7)\n",
    "ax2.annotate(f'{n_90} features\\n= 90% importancia',\n",
    "            xy=(n_90, 0.90), xytext=(n_90 + 20, 0.80),\n",
    "            arrowprops=dict(arrowstyle='->', color='green'),\n",
    "            fontsize=11, fontweight='bold', color='green')\n",
    "ax.set_xlabel('Feature (rank SHAP)', fontsize=11)\n",
    "ax.set_ylabel('Importancia Individual (%)', fontsize=11)\n",
    "ax2.set_ylabel('Cumulativo (%)', fontsize=11)\n",
    "ax.set_title(f'Curva de Pareto - {n_90} features capturam 90% da importancia SHAP',\n",
    "            fontsize=14, fontweight='bold')\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elems = [Patch(facecolor=c, label=l) for l, c in BOOK_COLORS.items()]\n",
    "legend_elems.append(Line2D([0],[0], color='red', linewidth=2, label='Cumulativo'))\n",
    "ax.legend(handles=legend_elems, loc='center right', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/shap_pareto_cumulative.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Selecionar features\n",
    "selected_mask = df_shap_ranking['cumulative_pct'] <= CUMULATIVE_THRESHOLD\n",
    "if not selected_mask.all():\n",
    "    first_over = selected_mask[~selected_mask].index[0]\n",
    "    selected_mask.iloc[:first_over + 1] = True\n",
    "df_selected = df_shap_ranking[selected_mask]\n",
    "final_set_features = df_selected['feature'].unique().tolist()\n",
    "\n",
    "print(f'Features selecionadas (SHAP >= {CUMULATIVE_THRESHOLD:.0%}): {len(final_set_features)}')\n",
    "print(f'Importancia capturada: {df_selected[\"pct_importance\"].sum():.1%}')\n",
    "print(f'\\nBreakdown por book:')\n",
    "for bn in book_names:\n",
    "    n_sel = len(df_selected[df_selected['book'] == bn])\n",
    "    n_all = len(df_shap_ranking[df_shap_ranking['book'] == bn])\n",
    "    print(f'  {bn}: {n_sel} / {n_all} selecionadas')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# 12.6 EXPORT SHAP ARTIFACTS\n",
    "# =============================================================================\n",
    "import os\n",
    "shap_dir = '/tmp/shap_artifacts'\n",
    "os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "# Salvar ranking CSV\n",
    "df_shap_ranking.to_csv(f'{shap_dir}/shap_feature_ranking.csv', index=False)\n",
    "\n",
    "# Salvar lista selecionada como pickle\n",
    "with open(f'{shap_dir}/selected_features_shap.pkl', 'wb') as f:\n",
    "    pickle.dump(final_set_features, f)\n",
    "\n",
    "# Log graficos no MLflow\n",
    "with mlflow.start_run(run_name='SHAP_Feature_Selection'):\n",
    "    mlflow.set_tag('task', 'feature_selection')\n",
    "    mlflow.set_tag('method', 'SHAP_TreeExplainer')\n",
    "    mlflow.log_param('n_features_total', len(feats_to_use))\n",
    "    mlflow.log_param('n_features_selected', len(final_set_features))\n",
    "    mlflow.log_param('cumulative_threshold', CUMULATIVE_THRESHOLD)\n",
    "    for fig_path in ['/tmp/shap_summary_beeswarm.png', '/tmp/shap_top30_by_book.png',\n",
    "                     '/tmp/shap_top15_per_book.png', '/tmp/shap_book_contribution.png',\n",
    "                     '/tmp/shap_pareto_cumulative.png']:\n",
    "        if os.path.exists(fig_path):\n",
    "            mlflow.log_artifact(fig_path, 'shap_plots')\n",
    "    mlflow.log_artifact(f'{shap_dir}/shap_feature_ranking.csv', 'feature_selection')\n",
    "    mlflow.log_artifact(f'{shap_dir}/selected_features_shap.pkl', 'feature_selection')\n",
    "\n",
    "print(f'Artifacts salvos em {shap_dir}')\n",
    "print(f'Features finais para modelo: {len(final_set_features)}')\n",
    "print(f'\\nfinal_set_features pronto para Cell 13 (Modelo Final)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Modelo Final com Features Selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 13. TREINO E AVALIACAO FINAL + MLFLOW\n",
    "# =============================================================================\n",
    "dimensions = ['NUM_CPF', 'SAFRA']\n",
    "final_features_with_dims = final_set_features + [d for d in dimensions if d not in final_set_features]\n",
    "\n",
    "X_tr_final_fs = X_train_final[final_features_with_dims]\n",
    "X_oos_fs = X_oos_agg[final_features_with_dims]\n",
    "X_oot_fs = X_oot_agg[final_features_with_dims]\n",
    "\n",
    "models = ['Reg Log', 'LGBM']\n",
    "list_results_fs = []\n",
    "best_model_name = None\n",
    "best_model_pipeline = None\n",
    "best_ks_oot = 0\n",
    "\n",
    "for model_name in models:\n",
    "    run_name = f\"Final_{model_name.replace(' ', '')}_FeatureSelection\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        pipe = update_pipeline(X_tr_final_fs, name_model=model_name)\n",
    "        pipe.fit(X_tr_final_fs, y_train_final)\n",
    "\n",
    "        mlflow.log_param('model_type', model_name)\n",
    "        mlflow.log_param('n_features', len(final_set_features))\n",
    "        mlflow.log_param('feature_selection', 'IV + L1_coefs + high_corr')\n",
    "        model_params = pipe.named_steps['model'].get_params()\n",
    "        for k, v in model_params.items():\n",
    "            if isinstance(v, (int, float, str, bool)):\n",
    "                mlflow.log_param(f'model__{k}', v)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f'MODELO FINAL: {model_name} ({len(final_set_features)} features)')\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        for key in dict_safras:\n",
    "            map_data = generate_map_step_data(\n",
    "                X_tr_final_fs, y_train_final,\n",
    "                X_oos_fs, y_oos_agg,\n",
    "                X_oot_fs, y_oot_agg,\n",
    "            )\n",
    "            X_f, y_f = filter_xy_by_safra(map_data[key]['X'], map_data[key]['Y'], dict_safras[key])\n",
    "            auc, ks = evaluation_auc_ks(X_f, y_f, pipe, key, verbose=True)\n",
    "\n",
    "            safe_key = _sanitize_mlflow_key(key)\n",
    "            mlflow.log_metric(f'AUC_{safe_key}', auc)\n",
    "            mlflow.log_metric(f'KS_{safe_key}', ks)\n",
    "            list_results_fs.append({'MODEL': model_name, 'BASE': key, 'AUC': auc, 'KS': ks})\n",
    "\n",
    "            if key == 'OOT GERAL (CONS)' and ks > best_ks_oot:\n",
    "                best_ks_oot = ks\n",
    "                best_model_name = model_name\n",
    "                best_model_pipeline = pipe\n",
    "\n",
    "        mlflow.sklearn.log_model(pipe, f\"model_final_{model_name.replace(' ', '_').lower()}\")\n",
    "        print(f'\\nMLflow Run ID ({model_name}): {run.info.run_id}')\n",
    "\n",
    "df_results_feat_selection = pd.DataFrame(list_results_fs)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f'MELHOR MODELO (KS OOT): {best_model_name} -- KS={best_ks_oot:.5f}')\n",
    "print(f'Benchmark KS: 33.1% (0.331)')\n",
    "print(f\"{'='*60}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Swap Analysis\n",
    "\n",
    "**Nota**: A swap analysis compara a estabilidade de ranking entre OOT1 e OOT2.\n",
    "Como sao periodos diferentes com clientes distintos, a comparacao e feita por\n",
    "**posicao ordinal** (top N% por score), nao por cliente individual.\n",
    "O objetivo e verificar se o modelo produz distribuicoes de ranking similares\n",
    "entre safras — swap% alto indica instabilidade temporal do modelo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 14. SWAP ANALYSIS (OOT1 vs OOT2)\n",
    "# =============================================================================\n",
    "\n",
    "def swap_analysis(df_ref, df_new, score_col='score', target_col='FPD', top_pct=0.1):\n",
    "    n = int(len(df_ref) * top_pct)\n",
    "    if n == 0:\n",
    "        return {'swap_in_%': 0, 'swap_out_%': 0, 'n_top': 0}\n",
    "    ref_top = df_ref.nlargest(n, score_col)\n",
    "    new_top = df_new.nlargest(n, score_col)\n",
    "    swap_in = len(set(new_top.index) - set(ref_top.index))\n",
    "    swap_out = len(set(ref_top.index) - set(new_top.index))\n",
    "    return {\n",
    "        'swap_in_%': round(swap_in / n * 100, 2),\n",
    "        'swap_out_%': round(swap_out / n * 100, 2),\n",
    "        'n_top': n,\n",
    "        'default_rate_ref': round(ref_top[target_col].mean(), 4) if target_col in ref_top.columns else None,\n",
    "        'default_rate_new': round(new_top[target_col].mean(), 4) if target_col in new_top.columns else None,\n",
    "    }\n",
    "\n",
    "\n",
    "print(f'Modelo utilizado: {best_model_name}')\n",
    "print('=' * 60)\n",
    "\n",
    "X_oot_feat = X_oot_fs.copy()\n",
    "scores_oot = best_model_pipeline.predict_proba(X_oot_feat)[:, 1]\n",
    "df_swap = X_oot_feat[['SAFRA']].copy()\n",
    "df_swap['score'] = scores_oot\n",
    "df_swap['FPD'] = y_oot_agg.values\n",
    "\n",
    "safras_oot_list = sorted(df_swap['SAFRA'].unique())\n",
    "print(f'Safras OOT: {safras_oot_list}')\n",
    "\n",
    "if len(safras_oot_list) >= 2:\n",
    "    for top_pct in [0.05, 0.10, 0.20, 0.30]:\n",
    "        df_ref = df_swap[df_swap['SAFRA'] == safras_oot_list[0]].reset_index(drop=True)\n",
    "        df_new = df_swap[df_swap['SAFRA'] == safras_oot_list[1]].reset_index(drop=True)\n",
    "        swap = swap_analysis(df_ref, df_new, top_pct=top_pct)\n",
    "        print(f\"\\nTop {top_pct:.0%} (n={swap['n_top']}):\")\n",
    "        print(f\"  Swap-in:  {swap['swap_in_%']:.1f}%\")\n",
    "        print(f\"  Swap-out: {swap['swap_out_%']:.1f}%\")\n",
    "        print(f\"  Default Rate OOT1 ({safras_oot_list[0]}): {swap['default_rate_ref']}\")\n",
    "        print(f\"  Default Rate OOT2 ({safras_oot_list[1]}): {swap['default_rate_new']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualizacoes Finais"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 15. VISUALIZACOES (KS Curve, Score Dist, Confusion Matrix, KS por Safra)\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "y_oot_vis = y_oot_agg.values\n",
    "scores_vis = best_model_pipeline.predict_proba(X_oot_fs)[:, 1]\n",
    "df_ks = pd.DataFrame({'y': y_oot_vis, 'score': scores_vis}).sort_values('score')\n",
    "df_ks['cum_good'] = (1 - df_ks['y']).cumsum() / (1 - df_ks['y']).sum()\n",
    "df_ks['cum_bad'] = df_ks['y'].cumsum() / df_ks['y'].sum()\n",
    "df_ks['ks_diff'] = np.abs(df_ks['cum_bad'] - df_ks['cum_good'])\n",
    "ks_max_idx = df_ks['ks_diff'].idxmax()\n",
    "ks_max_val = df_ks.loc[ks_max_idx, 'ks_diff']\n",
    "\n",
    "x_axis = np.linspace(0, 1, len(df_ks))\n",
    "ax1.plot(x_axis, df_ks['cum_good'].values, label='Bons (FPD=0)', color='blue')\n",
    "ax1.plot(x_axis, df_ks['cum_bad'].values, label='Maus (FPD=1)', color='red')\n",
    "ax1.axvline(x=x_axis[df_ks.index.get_loc(ks_max_idx)], color='green', linestyle='--', alpha=0.7)\n",
    "ax1.set_title(f'KS Curve - OOT ({best_model_name}) | KS = {ks_max_val:.4f}')\n",
    "ax1.set_xlabel('Populacao (%)')\n",
    "ax1.set_ylabel('CDF')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(scores_vis[y_oot_vis == 0], bins=50, alpha=0.6, label='Bons (FPD=0)', color='blue', density=True)\n",
    "ax2.hist(scores_vis[y_oot_vis == 1], bins=50, alpha=0.6, label='Maus (FPD=1)', color='red', density=True)\n",
    "ax2.set_title(f'Distribuicao de Scores - OOT ({best_model_name})')\n",
    "ax2.set_xlabel('Score (Prob FPD)')\n",
    "ax2.set_ylabel('Densidade')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "y_pred = (scores_vis >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_oot_vis, y_pred)\n",
    "ax3.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax3.set_title(f'Confusion Matrix - OOT ({best_model_name})')\n",
    "ax3.set_ylabel('Real')\n",
    "ax3.set_xlabel('Predito')\n",
    "ax3.set_xticks([0, 1])\n",
    "ax3.set_yticks([0, 1])\n",
    "ax3.set_xticklabels(['Bom (0)', 'Mau (1)'])\n",
    "ax3.set_yticklabels(['Bom (0)', 'Mau (1)'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax3.text(j, i, f'{cm[i, j]:,}', ha='center', va='center',\n",
    "                color='white' if cm[i, j] > cm.max() / 2 else 'black', fontsize=12)\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "df_oot_res = df_results_feat_selection[\n",
    "    (df_results_feat_selection['MODEL'] == best_model_name) &\n",
    "    (df_results_feat_selection['BASE'].str.contains('OOT|OOS'))\n",
    "]\n",
    "if not df_oot_res.empty:\n",
    "    bars = ax4.bar(range(len(df_oot_res)), df_oot_res['KS'].values, color='steelblue')\n",
    "    ax4.set_xticks(range(len(df_oot_res)))\n",
    "    ax4.set_xticklabels(df_oot_res['BASE'].values, rotation=45, ha='right', fontsize=8)\n",
    "    ax4.axhline(y=0.331, color='red', linestyle='--', label='Benchmark KS = 33.1%')\n",
    "    ax4.set_title(f'KS por Base - {best_model_name}')\n",
    "    ax4.set_ylabel('KS')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    for bar, val in zip(bars, df_oot_res['KS'].values):\n",
    "        ax4.text(bar.get_x() + bar.get_width() / 2, val + 0.005, f'{val:.3f}', ha='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('/tmp/final_model_visualizations.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "with mlflow.start_run(run_name='Final_Visualizations'):\n",
    "    mlflow.log_artifact('/tmp/final_model_visualizations.png', 'plots')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nModelo final: {best_model_name}')\n",
    "print(f'KS OOT: {best_ks_oot:.5f}')\n",
    "print(f'Benchmark: 0.331')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Export do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 16. EXPORT DO MODELO PARA MLFLOW REGISTRY\n",
    "# =============================================================================\n",
    "sys.path.insert(0, '/lakehouse/default/Files/projeto-final/5-treinamento-modelos')\n",
    "from export_model import export_model, promote_to_production\n",
    "\n",
    "feature_names_export = [f for f in final_set_features if f not in ['NUM_CPF', 'SAFRA']]\n",
    "\n",
    "X_oot_exp = X_oot_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore')\n",
    "X_oos_exp = X_oos_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore')\n",
    "\n",
    "print(f'Modelo a exportar: {best_model_name}')\n",
    "print(f'Features: {len(feature_names_export)}')\n",
    "print(f'KS OOT (mesmo pipeline da selecao): {best_ks_oot:.5f}')\n",
    "print('=' * 60)\n",
    "\n",
    "# --- LGBM (principal) ---\n",
    "if best_model_name == 'LGBM':\n",
    "    pipe_lgbm_export = best_model_pipeline\n",
    "else:\n",
    "    pipe_lgbm_export = update_pipeline(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), name_model='LGBM'\n",
    "    )\n",
    "    pipe_lgbm_export.fit(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), y_train_final\n",
    "    )\n",
    "\n",
    "ks_oot_lgbm = ks_stat(y_oot_agg, pipe_lgbm_export.predict_proba(X_oot_fs)[:, 1])\n",
    "auc_oot_lgbm = roc_auc_score(y_oot_agg, pipe_lgbm_export.predict_proba(X_oot_fs)[:, 1])\n",
    "ks_oos_lgbm = ks_stat(y_oos_agg, pipe_lgbm_export.predict_proba(X_oos_fs)[:, 1])\n",
    "auc_oos_lgbm = roc_auc_score(y_oos_agg, pipe_lgbm_export.predict_proba(X_oos_fs)[:, 1])\n",
    "\n",
    "ks_oos_202501 = None\n",
    "auc_oos_202501 = None\n",
    "X_oos_501, y_oos_501 = filter_xy_by_safra(X_oos_fs, y_oos_agg, [202501])\n",
    "if len(y_oos_501) > 0:\n",
    "    proba_501 = pipe_lgbm_export.predict_proba(X_oos_501)[:, 1]\n",
    "    ks_oos_202501 = ks_stat(y_oos_501, proba_501)\n",
    "    auc_oos_202501 = roc_auc_score(y_oos_501, proba_501)\n",
    "\n",
    "metrics_lgbm = {\n",
    "    'ks_oot': ks_oot_lgbm, 'auc_oot': auc_oot_lgbm,\n",
    "    'ks_oos': ks_oos_lgbm, 'auc_oos': auc_oos_lgbm,\n",
    "    'gini_oot': (2 * auc_oot_lgbm - 1) * 100,\n",
    "    'gini_oos': (2 * auc_oos_lgbm - 1) * 100,\n",
    "}\n",
    "if ks_oos_202501 is not None:\n",
    "    metrics_lgbm['ks_oos_202501'] = ks_oos_202501\n",
    "    metrics_lgbm['auc_oos_202501'] = auc_oos_202501\n",
    "    metrics_lgbm['gini_oos_202501'] = (2 * auc_oos_202501 - 1) * 100\n",
    "\n",
    "result_lgbm = export_model(\n",
    "    pipeline=pipe_lgbm_export, model_name='lgbm_baseline',\n",
    "    X_test=X_oot_exp, y_test=y_oot_agg,\n",
    "    feature_names=feature_names_export,\n",
    "    metrics_dict=metrics_lgbm,\n",
    ")\n",
    "print(f\"\\nLGBM exportado: {result_lgbm['registered_name']}\")\n",
    "print(f\"  MLflow Run ID: {result_lgbm['mlflow_run_id']}\")\n",
    "print(f\"  PKL: {result_lgbm['pkl_path']}\")\n",
    "print(f\"  KS OOT: {ks_oot_lgbm:.5f}\")\n",
    "print(f\"  KS OOS: {ks_oos_lgbm:.5f}\")\n",
    "if ks_oos_202501 is not None:\n",
    "    print(f\"  KS OOS 202501: {ks_oos_202501:.5f}\")\n",
    "\n",
    "# --- LR (benchmark) ---\n",
    "if best_model_name == 'Reg Log':\n",
    "    pipe_lr_export = best_model_pipeline\n",
    "else:\n",
    "    pipe_lr_export = update_pipeline(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), name_model='Reg Log'\n",
    "    )\n",
    "    pipe_lr_export.fit(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), y_train_final\n",
    "    )\n",
    "\n",
    "ks_oot_lr = ks_stat(y_oot_agg, pipe_lr_export.predict_proba(X_oot_fs)[:, 1])\n",
    "auc_oot_lr = roc_auc_score(y_oot_agg, pipe_lr_export.predict_proba(X_oot_fs)[:, 1])\n",
    "\n",
    "result_lr = export_model(\n",
    "    pipeline=pipe_lr_export, model_name='logistic_regression_l1',\n",
    "    X_test=X_oot_exp, y_test=y_oot_agg,\n",
    "    feature_names=feature_names_export,\n",
    "    metrics_dict={\n",
    "        'ks_oot': ks_oot_lr, 'auc_oot': auc_oot_lr,\n",
    "        'gini_oot': (2 * auc_oot_lr - 1) * 100,\n",
    "    },\n",
    ")\n",
    "print(f\"\\nLR exportado: {result_lr['registered_name']}\")\n",
    "print(f\"  MLflow Run ID: {result_lr['mlflow_run_id']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print('Export concluido! Modelos registrados no MLflow em Staging.')\n",
    "print('Proximo passo: executar scoring_batch e validacao_deploy')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}