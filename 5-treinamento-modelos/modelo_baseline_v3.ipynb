{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  },
  "microsoft": {
   "language": "python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Baseline de Risco – Telecom (v3 — Spark Read + Pandas Modeling)\n",
    "\n",
    "Este notebook implementa um **modelo baseline de risco de inadimplencia (FPD)** para clientes Claro.\n",
    "\n",
    "### Diferencas em relacao ao v1 e v2\n",
    "- **v1**: PySpark para limpeza + Pandas para modelagem (original)\n",
    "- **v2**: Python puro com `deltalake` (delta-rs) — falha no Fabric por falta de Spark context para MLflow\n",
    "- **v3 (este)**: Usa `spark.read` para carregar dados, converte para Pandas, e segue com modelagem 100% Pandas\n",
    "- Codigo limpo e organizado do v2, compatibilidade Fabric do v1\n",
    "\n",
    "### Principais etapas\n",
    "- Leitura do Gold Feature Store via `spark.read.format(\"delta\")`\n",
    "- Amostragem de **25%** por safra e FPD, de forma estratificada\n",
    "- Separacao em **Treino (2024-10 a 2024-12)**, **Validacao (2025-01)**, **OOS** e **OOT (2025-02 e 2025-03)**\n",
    "- Modelos: Logistic Regression (L1) + LightGBM (GBDT)\n",
    "- Ajuste de hiperparametros no conjunto de validacao\n",
    "- Metricas: AUC, KS, Gini\n",
    "- Analise incremental de KS por fonte de dados\n",
    "- Feature selection: IV + L1 coefs + alta correlacao\n",
    "- Swap analysis OOT1 vs OOT2\n",
    "- Export via MLflow Registry"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTS E CONFIGURACAO\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "from category_encoders import CountEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config centralizado do pipeline\n",
    "import sys; sys.path.insert(0, '/lakehouse/default/Files/projeto-final')\n",
    "from config.pipeline_config import (\n",
    "    PATH_FEATURE_STORE, EXPERIMENT_NAME, SAFRAS,\n",
    "    LEAKAGE_BLACKLIST, TARGET_COLUMNS\n",
    ")\n",
    "\n",
    "print('Imports OK')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 2. MLFLOW SETUP\n",
    "# =============================================================================\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.autolog(disable=True)  # Controle manual para evitar conflitos\n",
    "\n",
    "print(f'MLflow experiment: {EXPERIMENT_NAME}')\n",
    "print(f'Tracking URI: {mlflow.get_tracking_uri()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 3. LEITURA DO GOLD FEATURE STORE (Spark -> Pandas)\n",
    "# =============================================================================\n",
    "\n",
    "# Aumentar limite de resultado do driver para suportar toPandas() com 3.9M rows\n",
    "spark.conf.set('spark.driver.maxResultSize', '8g')\n",
    "\n",
    "print(f'Lendo feature store de: {PATH_FEATURE_STORE}')\n",
    "\n",
    "df_spark = spark.read.format('delta').load(PATH_FEATURE_STORE)\n",
    "print(f'Spark DataFrame: {df_spark.count()} rows, {len(df_spark.columns)} cols')\n",
    "\n",
    "# Converter para Pandas para modelagem\n",
    "df = df_spark.toPandas()\n",
    "\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'Colunas: {len(df.columns)}')\n",
    "print(f'SAFRAs disponiveis: {sorted(df[\"SAFRA\"].unique())}')\n",
    "print(f'Memory: {df.memory_usage(deep=True).sum() / 1e9:.2f} GB')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limpeza de Dados (Pandas puro)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 4.1 FUNCOES DE LIMPEZA\n",
    "# =============================================================================\n",
    "\n",
    "def clean_empty_keys(df):\n",
    "    \"\"\"Remove registros com chaves (CPF, SAFRA) vazias.\"\"\"\n",
    "    return df.dropna(subset=['NUM_CPF', 'SAFRA'])\n",
    "\n",
    "\n",
    "def convert_cep3_uf_regiao(df):\n",
    "    \"\"\"Converte CEP_3_digitos em UF e Regiao via mapeamento.\"\"\"\n",
    "    cep_map = {\n",
    "        '01': ('SP', 'SUDESTE'), '02': ('SP', 'SUDESTE'), '03': ('SP', 'SUDESTE'),\n",
    "        '04': ('SP', 'SUDESTE'), '05': ('SP', 'SUDESTE'), '06': ('SP', 'SUDESTE'),\n",
    "        '07': ('SP', 'SUDESTE'), '08': ('SP', 'SUDESTE'), '09': ('SP', 'SUDESTE'),\n",
    "        '20': ('RJ', 'SUDESTE'), '21': ('RJ', 'SUDESTE'), '22': ('RJ', 'SUDESTE'),\n",
    "        '23': ('RJ', 'SUDESTE'), '24': ('RJ', 'SUDESTE'),\n",
    "        '29': ('ES', 'SUDESTE'),\n",
    "        '30': ('MG', 'SUDESTE'), '31': ('MG', 'SUDESTE'), '32': ('MG', 'SUDESTE'),\n",
    "        '33': ('MG', 'SUDESTE'), '34': ('MG', 'SUDESTE'), '35': ('MG', 'SUDESTE'),\n",
    "        '36': ('MG', 'SUDESTE'), '37': ('MG', 'SUDESTE'), '38': ('MG', 'SUDESTE'),\n",
    "        '39': ('MG', 'SUDESTE'),\n",
    "        '40': ('BA', 'NORDESTE'), '41': ('BA', 'NORDESTE'), '42': ('BA', 'NORDESTE'),\n",
    "        '43': ('BA', 'NORDESTE'), '44': ('BA', 'NORDESTE'), '45': ('BA', 'NORDESTE'),\n",
    "        '46': ('BA', 'NORDESTE'), '47': ('BA', 'NORDESTE'), '48': ('BA', 'NORDESTE'),\n",
    "        '49': ('SE', 'NORDESTE'),\n",
    "        '50': ('PE', 'NORDESTE'), '51': ('PE', 'NORDESTE'), '52': ('PE', 'NORDESTE'),\n",
    "        '53': ('PE', 'NORDESTE'), '54': ('PE', 'NORDESTE'), '55': ('PE', 'NORDESTE'),\n",
    "        '56': ('AL', 'NORDESTE'), '57': ('AL', 'NORDESTE'),\n",
    "        '58': ('PB', 'NORDESTE'), '59': ('RN', 'NORDESTE'),\n",
    "        '60': ('CE', 'NORDESTE'), '61': ('CE', 'NORDESTE'), '62': ('CE', 'NORDESTE'),\n",
    "        '63': ('PI', 'NORDESTE'), '64': ('PI', 'NORDESTE'),\n",
    "        '65': ('MA', 'NORDESTE'),\n",
    "        '66': ('PA', 'NORTE'), '67': ('PA', 'NORTE'),\n",
    "        '68': ('AC', 'NORTE'), '69': ('AM', 'NORTE'),\n",
    "        '77': ('TO', 'NORTE'),\n",
    "        '70': ('DF', 'CENTRO-OESTE'), '71': ('DF', 'CENTRO-OESTE'),\n",
    "        '72': ('GO', 'CENTRO-OESTE'), '73': ('GO', 'CENTRO-OESTE'),\n",
    "        '74': ('GO', 'CENTRO-OESTE'), '75': ('GO', 'CENTRO-OESTE'),\n",
    "        '76': ('GO', 'CENTRO-OESTE'),\n",
    "        '78': ('MT', 'CENTRO-OESTE'), '79': ('MS', 'CENTRO-OESTE'),\n",
    "        '80': ('PR', 'SUL'), '81': ('PR', 'SUL'), '82': ('PR', 'SUL'),\n",
    "        '83': ('PR', 'SUL'), '84': ('PR', 'SUL'), '85': ('PR', 'SUL'),\n",
    "        '86': ('PR', 'SUL'), '87': ('PR', 'SUL'),\n",
    "        '88': ('SC', 'SUL'), '89': ('SC', 'SUL'),\n",
    "        '90': ('RS', 'SUL'), '91': ('RS', 'SUL'), '92': ('RS', 'SUL'),\n",
    "        '93': ('RS', 'SUL'), '94': ('RS', 'SUL'), '95': ('RS', 'SUL'),\n",
    "        '96': ('RS', 'SUL'), '97': ('RS', 'SUL'), '98': ('RS', 'SUL'),\n",
    "        '99': ('RS', 'SUL'),\n",
    "    }\n",
    "    if 'CEP_3_digitos' not in df.columns:\n",
    "        return df\n",
    "    cep2 = df['CEP_3_digitos'].astype(str).str[:2]\n",
    "    mapped = cep2.map(cep_map)\n",
    "    df['UF'] = mapped.apply(lambda x: x[0] if isinstance(x, tuple) else 'OUTROS')\n",
    "    df['REGIAO'] = mapped.apply(lambda x: x[1] if isinstance(x, tuple) else 'OUTROS')\n",
    "    df = df.drop(columns=['CEP_3_digitos'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def adjust_and_drop_date_cols(df):\n",
    "    \"\"\"Cria features datediff e remove colunas de data.\"\"\"\n",
    "    if 'var_12' in df.columns:\n",
    "        df['var_12'] = pd.to_datetime(df['var_12'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['DATA_REF_SAFRA'] = pd.to_datetime(df['SAFRA'].astype(str), format='%Y%m')\n",
    "    if 'var_12' in df.columns:\n",
    "        df['DIAS_VAR_12'] = (df['DATA_REF_SAFRA'] - df['var_12']).dt.days\n",
    "    if 'PAG_DT_PRIMEIRA_FATURA' in df.columns:\n",
    "        df['PAG_DT_PRIMEIRA_FATURA'] = pd.to_datetime(df['PAG_DT_PRIMEIRA_FATURA'], errors='coerce')\n",
    "        df['PAG_DIAS_DESDE_PRIMEIRA_FATURA'] = (df['DATA_REF_SAFRA'] - df['PAG_DT_PRIMEIRA_FATURA']).dt.days\n",
    "    date_cols = df.select_dtypes(include=['datetime64', 'datetimetz']).columns.tolist()\n",
    "    date_cols.append('DATA_REF_SAFRA')\n",
    "    df = df.drop(columns=[c for c in date_cols if c in df.columns])\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_high_missing(df, threshold=0.75):\n",
    "    \"\"\"Remove colunas com mais de threshold% de missing.\"\"\"\n",
    "    null_pct = df.isnull().mean()\n",
    "    cols_to_drop = null_pct[null_pct >= threshold].index.tolist()\n",
    "    print(f'  High missing (>= {threshold:.0%}): {len(cols_to_drop)} colunas removidas')\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "def remove_low_cardinality(df):\n",
    "    \"\"\"Remove colunas com apenas 1 valor unico.\"\"\"\n",
    "    low_card = [c for c in df.columns if df[c].nunique() <= 1]\n",
    "    print(f'  Low cardinality (== 1): {len(low_card)} colunas removidas')\n",
    "    return df.drop(columns=low_card)\n",
    "\n",
    "\n",
    "def remove_high_correlation(df, threshold=0.8, safras_train=None):\n",
    "    \"\"\"Remove colunas com correlacao > threshold (apenas nas safras de treino).\"\"\"\n",
    "    if safras_train is not None:\n",
    "        df_corr_base = df[df['SAFRA'].isin(safras_train)]\n",
    "    else:\n",
    "        df_corr_base = df\n",
    "    df_sample = df_corr_base.groupby(['SAFRA', 'FPD'], group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=0.25, random_state=42)\n",
    "    )\n",
    "    num_cols = df_sample.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns\n",
    "    num_cols = [c for c in num_cols if c != 'FPD']\n",
    "    corr_matrix = df_sample[num_cols].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = []\n",
    "    while True:\n",
    "        max_corr = upper.max().max()\n",
    "        if max_corr < threshold:\n",
    "            break\n",
    "        col_to_drop = upper.max().sort_values(ascending=False).index[0]\n",
    "        to_drop.append(col_to_drop)\n",
    "        upper = upper.drop(index=col_to_drop, columns=col_to_drop)\n",
    "    print(f'  High correlation (> {threshold}): {len(to_drop)} colunas removidas')\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "\n",
    "def remove_misused_columns(df):\n",
    "    \"\"\"Remove colunas de leakage e duplicatas conhecidas.\"\"\"\n",
    "    misused = ['PROD', 'flag_mig2', 'FAT_VLR_FPD', 'FAT_FLAG_MIG2_AQUISICAO']\n",
    "    existing = [c for c in misused if c in df.columns]\n",
    "    if existing:\n",
    "        print(f'  Misused columns removed: {existing}')\n",
    "    return df.drop(columns=existing, errors='ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 4.2 APLICAR LIMPEZAS\n",
    "# =============================================================================\n",
    "safras_train_val = SAFRAS[:4]  # 202410, 202411, 202412, 202501\n",
    "\n",
    "print('Aplicando limpezas...')\n",
    "print(f'Shape original: {df.shape}')\n",
    "\n",
    "df = clean_empty_keys(df)\n",
    "df = convert_cep3_uf_regiao(df)\n",
    "df = adjust_and_drop_date_cols(df)\n",
    "df = remove_high_missing(df)\n",
    "df = remove_low_cardinality(df)\n",
    "df = remove_high_correlation(df, threshold=0.8, safras_train=safras_train_val)\n",
    "df = remove_misused_columns(df)\n",
    "\n",
    "print(f'Shape apos limpezas: {df.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Temporal e Amostragem Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5. SPLIT TEMPORAL + AMOSTRAGEM ESTRATIFICADA\n",
    "# =============================================================================\n",
    "\n",
    "# Filtrar clientes pos (FLAG_INSTALACAO == 1)\n",
    "df_pos = df[df['FLAG_INSTALACAO'] == 1].drop(columns=['FLAG_INSTALACAO']).copy()\n",
    "df_reprovados = df[df['FLAG_INSTALACAO'] == 0].drop(columns=['FLAG_INSTALACAO']).copy()\n",
    "print(f'Clientes pos: {len(df_pos):,} | Reprovados: {len(df_reprovados):,}')\n",
    "\n",
    "# Separar safras\n",
    "safras_ord = sorted(df_pos['SAFRA'].unique())\n",
    "safras_train_oos = safras_ord[:4]  # 202410-202501\n",
    "safras_oot = safras_ord[4:]        # 202502-202503\n",
    "\n",
    "df_4_safras = df_pos[df_pos['SAFRA'].isin(safras_train_oos)]\n",
    "df_oot_full = df_pos[df_pos['SAFRA'].isin(safras_oot)]\n",
    "\n",
    "# Amostragem estratificada 25% por (SAFRA, FPD)\n",
    "df_sample = df_4_safras.groupby(['SAFRA', 'FPD'], group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.25, random_state=42)\n",
    ")\n",
    "df_oos = df_4_safras.drop(df_sample.index)\n",
    "\n",
    "# Reset indices\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "df_oos = df_oos.reset_index(drop=True)\n",
    "df_oot = df_oot_full.reset_index(drop=True)\n",
    "\n",
    "# Remover duplicatas\n",
    "df_sample = df_sample.drop_duplicates()\n",
    "df_oos = df_oos.drop_duplicates()\n",
    "df_oot = df_oot.drop_duplicates()\n",
    "\n",
    "print(f'\\nShapes finais:')\n",
    "print(f'  Sample (train+val): {df_sample.shape}')\n",
    "print(f'  OOS:                {df_oos.shape}')\n",
    "print(f'  OOT:                {df_oot.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5.1 VERIFICAR VOLUMETRIA POR SAFRA E TARGET\n",
    "# =============================================================================\n",
    "for name, data in [('Sample', df_sample), ('OOS', df_oos), ('OOT', df_oot)]:\n",
    "    print(f'\\n--- {name} ---')\n",
    "    print(data[['SAFRA', 'FPD']].value_counts().sort_index().to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Separacao Treino / Validacao e Preparacao X/Y"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 6. SEPARACAO TREINO / VALIDACAO / X / Y\n",
    "# =============================================================================\n",
    "safras_train = [202410, 202411, 202412]\n",
    "safras_val = [202501]\n",
    "\n",
    "df_train = df_sample[df_sample['SAFRA'].isin(safras_train)]\n",
    "df_val = df_sample[df_sample['SAFRA'].isin(safras_val)]\n",
    "\n",
    "X_train = df_train.drop(columns=['FPD'])\n",
    "y_train = df_train['FPD']\n",
    "\n",
    "X_val = df_val.drop(columns=['FPD'])\n",
    "y_val = df_val['FPD']\n",
    "\n",
    "# Train + Val combinado para treino final\n",
    "X_train_final = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_train_final = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# OOS e OOT\n",
    "X_oos_agg = df_oos.drop(columns=['FPD'])\n",
    "y_oos_agg = df_oos['FPD']\n",
    "\n",
    "X_oot_agg = df_oot.drop(columns=['FPD'])\n",
    "y_oot_agg = df_oot['FPD']\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_val:   {X_val.shape}')\n",
    "print(f'X_train_final: {X_train_final.shape}')\n",
    "print(f'X_oos: {X_oos_agg.shape}')\n",
    "print(f'X_oot: {X_oot_agg.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Separacao de Variaveis por Tipo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 7. VARIAVEIS NUMERICAS E CATEGORICAS\n",
    "# =============================================================================\n",
    "num_features = [\n",
    "    n for n in X_train.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns\n",
    "    if n != 'SAFRA'\n",
    "]\n",
    "cat_features = [\n",
    "    c for c in X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    if c != 'NUM_CPF'\n",
    "]\n",
    "\n",
    "print(f'Numericas: {len(num_features)}')\n",
    "print(f'Categoricas: {len(cat_features)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Montagem dos Pipelines sklearn"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 8. PIPELINES\n",
    "# =============================================================================\n",
    "\n",
    "# --- Regressao Logistica ---\n",
    "numeric_pipe_rl = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_pipe_rl = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', CountEncoder(normalize=True)),\n",
    "])\n",
    "preprocess_rl = ColumnTransformer([\n",
    "    ('num', numeric_pipe_rl, num_features),\n",
    "    ('cat', categorical_pipe_rl, cat_features),\n",
    "])\n",
    "pipeline_RL = Pipeline([\n",
    "    ('prep', preprocess_rl),\n",
    "    ('model', LogisticRegression(\n",
    "        solver='liblinear', penalty='l1',\n",
    "        max_iter=2000, tol=1e-3,\n",
    "        class_weight='balanced', random_state=42,\n",
    "    )),\n",
    "])\n",
    "\n",
    "# --- LightGBM ---\n",
    "numeric_pipe_lgbm = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "categorical_pipe_lgbm = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0)),\n",
    "])\n",
    "preprocess_lgbm = ColumnTransformer([\n",
    "    ('num', numeric_pipe_lgbm, num_features),\n",
    "    ('cat', categorical_pipe_lgbm, cat_features),\n",
    "], remainder='drop')\n",
    "pipeline_LGBM = Pipeline([\n",
    "    ('prep', preprocess_lgbm),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary', boosting_type='gbdt',\n",
    "        learning_rate=0.05, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1, verbosity=-1,\n",
    "    )),\n",
    "])\n",
    "\n",
    "print('Pipelines criados: RL (prep) + LGBM (prep)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ajuste de Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 9.1 GRID SEARCH - REGRESSAO LOGISTICA\n",
    "# =============================================================================\n",
    "param_grid_RL = {'model__C': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid_RL = GridSearchCV(\n",
    "    pipeline_RL, param_grid=param_grid_RL,\n",
    "    scoring='roc_auc', cv=cv, n_jobs=-1, verbose=3,\n",
    ")\n",
    "grid_RL.fit(X_val, y_val)\n",
    "\n",
    "print(f'Melhores HP RL: {grid_RL.best_params_}')\n",
    "print(f'Melhor AUC RL:  {grid_RL.best_score_:.5f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Treino final RL com best params (train + val)\n",
    "pipeline_RL.set_params(**grid_RL.best_params_)\n",
    "pipeline_RL.fit(X_train_final, y_train_final)\n",
    "print('RL treinado com train+val')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 9.2 GRID SEARCH - LIGHTGBM\n",
    "# =============================================================================\n",
    "param_grid_LGBM = {\n",
    "    'model__n_estimators': [250, 500],\n",
    "    'model__max_depth': [4, 7],\n",
    "}\n",
    "\n",
    "grid_LGBM = GridSearchCV(\n",
    "    pipeline_LGBM, param_grid=param_grid_LGBM,\n",
    "    scoring='roc_auc', cv=cv, n_jobs=-1, verbose=3, error_score='raise',\n",
    ")\n",
    "grid_LGBM.fit(X_val, y_val)\n",
    "\n",
    "print(f'Melhores HP LGBM: {grid_LGBM.best_params_}')\n",
    "print(f'Melhor AUC LGBM:  {grid_LGBM.best_score_:.5f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Treino final LGBM com best params (train + val)\n",
    "pipeline_LGBM.set_params(**grid_LGBM.best_params_)\n",
    "pipeline_LGBM.fit(X_train_final, y_train_final)\n",
    "print('LGBM treinado com train+val')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Avaliacao por Safra (AUC e KS)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 10. FUNCOES DE AVALIACAO\n",
    "# =============================================================================\n",
    "\n",
    "def ks_stat(y_true, y_score):\n",
    "    \"\"\"Calcula KS statistic.\"\"\"\n",
    "    df_ks = pd.DataFrame({'y': y_true.values, 'p': y_score})\n",
    "    df_ks = df_ks.sort_values('p')\n",
    "    df_ks['cum_good'] = (1 - df_ks['y']).cumsum() / (1 - df_ks['y']).sum()\n",
    "    df_ks['cum_bad'] = df_ks['y'].cumsum() / df_ks['y'].sum()\n",
    "    return np.max(np.abs(df_ks['cum_bad'] - df_ks['cum_good']))\n",
    "\n",
    "\n",
    "def evaluation_auc_ks(X, y, pipe, name='', verbose=True):\n",
    "    \"\"\"Calcula AUC e KS para um dado split.\"\"\"\n",
    "    proba = pipe.predict_proba(X)[:, 1]\n",
    "    auc = round(roc_auc_score(y, proba), 5)\n",
    "    ks = round(ks_stat(y, proba), 5)\n",
    "    if verbose:\n",
    "        print(f'AVALIACAO {name}: AUC={auc}, KS={ks}')\n",
    "        print('-' * 40)\n",
    "    return auc, ks\n",
    "\n",
    "\n",
    "def filter_xy_by_safra(X, y, list_safras):\n",
    "    \"\"\"Filtra X e y por lista de SAFRAs.\"\"\"\n",
    "    mask = X['SAFRA'].isin(list_safras)\n",
    "    return X[mask], y.loc[X[mask].index]\n",
    "\n",
    "\n",
    "def _sanitize_mlflow_key(key):\n",
    "    \"\"\"Sanitiza nome de metrica para MLflow Fabric.\n",
    "\n",
    "    Fabric MLflow rejeita backslash, barras e outros caracteres especiais.\n",
    "    Mantem apenas alfanumericos, underscore e hifen.\n",
    "    Colapsa underscores consecutivos em um unico.\n",
    "    \"\"\"\n",
    "    safe = re.sub(r'[^a-zA-Z0-9_\\-]', '_', key)\n",
    "    safe = re.sub(r'_+', '_', safe)\n",
    "    return safe.strip('_')\n",
    "\n",
    "\n",
    "# Mapa de splits para avaliacao\n",
    "dict_safras = {\n",
    "    'TREINO - 202410': [202410],\n",
    "    'TREINO - 202411': [202411],\n",
    "    'TREINO - 202412': [202412],\n",
    "    'TREINO / VAL - 202501': [202501],\n",
    "    'TREINO (CONS)': [202410, 202411, 202412, 202501],\n",
    "    'OOS - 202410': [202410],\n",
    "    'OOS - 202411': [202411],\n",
    "    'OOS - 202412': [202412],\n",
    "    'OOS - 202501': [202501],\n",
    "    'OOS (CONS)': [202410, 202411, 202412, 202501],\n",
    "    'OOT - 202502': [202502],\n",
    "    'OOT - 202503': [202503],\n",
    "    'OOT GERAL (CONS)': [202502, 202503],\n",
    "}\n",
    "\n",
    "\n",
    "def generate_map_step_data(X_train, y_train, X_oos, y_oos, X_oot, y_oot):\n",
    "    \"\"\"Gera mapa de datasets por split.\"\"\"\n",
    "    return {\n",
    "        'TREINO - 202410': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO - 202411': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO - 202412': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO / VAL - 202501': {'X': X_train, 'Y': y_train},\n",
    "        'TREINO (CONS)': {'X': X_train, 'Y': y_train},\n",
    "        'OOS - 202410': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS - 202411': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS - 202412': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS - 202501': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOS (CONS)': {'X': X_oos, 'Y': y_oos},\n",
    "        'OOT - 202502': {'X': X_oot, 'Y': y_oot},\n",
    "        'OOT - 202503': {'X': X_oot, 'Y': y_oot},\n",
    "        'OOT GERAL (CONS)': {'X': X_oot, 'Y': y_oot},\n",
    "    }\n",
    "\n",
    "\n",
    "def log_safra_metrics_mlflow(model_name, dict_safras, X_train, y_train,\n",
    "                              X_oos, y_oos, X_oot, y_oot, pipeline):\n",
    "    \"\"\"Loga metricas AUC e KS por safra no MLflow.\"\"\"\n",
    "    results = {}\n",
    "    for key in dict_safras:\n",
    "        map_data = generate_map_step_data(X_train, y_train, X_oos, y_oos, X_oot, y_oot)\n",
    "        X = map_data[key]['X']\n",
    "        y = map_data[key]['Y']\n",
    "        X_f, y_f = filter_xy_by_safra(X, y, dict_safras[key])\n",
    "        auc, ks = evaluation_auc_ks(X_f, y_f, pipeline, key)\n",
    "        safe_key = _sanitize_mlflow_key(key)\n",
    "        mlflow.log_metric(f'{model_name}_AUC_{safe_key}', auc)\n",
    "        mlflow.log_metric(f'{model_name}_KS_{safe_key}', ks)\n",
    "        results[key] = {'AUC': auc, 'KS': ks}\n",
    "    return results\n",
    "\n",
    "print('Funcoes de avaliacao carregadas')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 10.1 AVALIACAO - REGRESSAO LOGISTICA\n",
    "# =============================================================================\n",
    "with mlflow.start_run(run_name='LogisticRegression_Baseline') as run_rl:\n",
    "    params_rl = pipeline_RL.named_steps['model'].get_params()\n",
    "    mlflow.log_param('model_type', 'LogisticRegression')\n",
    "    mlflow.log_param('penalty', params_rl.get('penalty', 'l1'))\n",
    "    mlflow.log_param('solver', params_rl.get('solver'))\n",
    "    mlflow.log_param('C', params_rl.get('C'))\n",
    "    mlflow.log_param('max_iter', params_rl.get('max_iter'))\n",
    "    mlflow.log_param('n_features', len(X_train_final.columns))\n",
    "    mlflow.log_param('n_samples_train', len(X_train_final))\n",
    "\n",
    "    print('Avaliacao RL por base:')\n",
    "    results_rl = log_safra_metrics_mlflow(\n",
    "        'RL', dict_safras, X_train_final, y_train_final,\n",
    "        X_oos_agg, y_oos_agg, X_oot_agg, y_oot_agg, pipeline_RL,\n",
    "    )\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_RL, 'model_logistic_regression')\n",
    "\n",
    "    coefs = pipeline_RL.named_steps['model'].coef_[0]\n",
    "    feat_names = pipeline_RL.named_steps['prep'].get_feature_names_out()\n",
    "    df_coefs = pd.DataFrame({'feature': feat_names, 'coef': coefs}).sort_values('coef', key=abs, ascending=False)\n",
    "    df_coefs.to_csv('/tmp/lr_coefficients.csv', index=False)\n",
    "    mlflow.log_artifact('/tmp/lr_coefficients.csv', 'feature_analysis')\n",
    "\n",
    "    print(f'\\nMLflow Run ID (RL): {run_rl.info.run_id}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 10.2 AVALIACAO - LIGHTGBM\n",
    "# =============================================================================\n",
    "with mlflow.start_run(run_name='LightGBM_Baseline') as run_lgbm:\n",
    "    params_lgbm = pipeline_LGBM.named_steps['model'].get_params()\n",
    "    mlflow.log_param('model_type', 'LightGBM')\n",
    "    mlflow.log_param('n_estimators', params_lgbm.get('n_estimators'))\n",
    "    mlflow.log_param('max_depth', params_lgbm.get('max_depth'))\n",
    "    mlflow.log_param('learning_rate', params_lgbm.get('learning_rate'))\n",
    "    mlflow.log_param('num_leaves', params_lgbm.get('num_leaves'))\n",
    "    mlflow.log_param('boosting_type', params_lgbm.get('boosting_type', 'gbdt'))\n",
    "    mlflow.log_param('n_features', len(X_train_final.columns))\n",
    "    mlflow.log_param('n_samples_train', len(X_train_final))\n",
    "\n",
    "    print('Avaliacao LGBM por base:')\n",
    "    results_lgbm = log_safra_metrics_mlflow(\n",
    "        'LGBM', dict_safras, X_train_final, y_train_final,\n",
    "        X_oos_agg, y_oos_agg, X_oot_agg, y_oot_agg, pipeline_LGBM,\n",
    "    )\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_LGBM, 'model_lightgbm')\n",
    "\n",
    "    lgbm_model = pipeline_LGBM.named_steps['model']\n",
    "    feat_names_lgbm = pipeline_LGBM.named_steps['prep'].get_feature_names_out()\n",
    "    df_importance = pd.DataFrame({\n",
    "        'feature': feat_names_lgbm,\n",
    "        'importance': lgbm_model.feature_importances_,\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    df_importance.to_csv('/tmp/lgbm_feature_importance.csv', index=False)\n",
    "    mlflow.log_artifact('/tmp/lgbm_feature_importance.csv', 'feature_analysis')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_30 = df_importance.head(30)\n",
    "    ax.barh(range(len(top_30)), top_30['importance'].values)\n",
    "    ax.set_yticks(range(len(top_30)))\n",
    "    ax.set_yticklabels(top_30['feature'].values, fontsize=8)\n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_title('Top 30 Features - LightGBM')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('/tmp/lgbm_feature_importance.png', dpi=150)\n",
    "    mlflow.log_artifact('/tmp/lgbm_feature_importance.png', 'plots')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'\\nMLflow Run ID (LGBM): {run_lgbm.info.run_id}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Analise Incremental de KS por Fonte"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 11. FUNCAO AUXILIAR: UPDATE PIPELINE + VAR CLASSIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "def _var_num(col):\n",
    "    \"\"\"Extrai numero de colunas var_XX para comparacao numerica.\"\"\"\n",
    "    m = re.search(r'var_(\\d+)', col)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def update_pipeline(X, name_model):\n",
    "    \"\"\"Reconstroi pipeline com features atuais.\"\"\"\n",
    "    nf = [n for n in X.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns if n != 'SAFRA']\n",
    "    cf = [c for c in X.select_dtypes(include=['object', 'category']).columns if c != 'NUM_CPF']\n",
    "\n",
    "    if name_model == 'Reg Log':\n",
    "        num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "        cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', CountEncoder(normalize=True))])\n",
    "        prep = ColumnTransformer([('num', num_pipe, nf), ('cat', cat_pipe, cf)])\n",
    "        model = LogisticRegression(\n",
    "            solver='liblinear', penalty='l1', max_iter=2000,\n",
    "            C=grid_RL.best_params_['model__C'],\n",
    "            tol=1e-3, class_weight='balanced', random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "        cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                             ('encoder', CountEncoder(normalize=True, handle_unknown=0, handle_missing=0))])\n",
    "        prep = ColumnTransformer([('num', num_pipe, nf), ('cat', cat_pipe, cf)], remainder='drop')\n",
    "        model = LGBMClassifier(\n",
    "            objective='binary', boosting_type='gbdt', learning_rate=0.05,\n",
    "            max_depth=grid_LGBM.best_params_['model__max_depth'],\n",
    "            n_estimators=grid_LGBM.best_params_['model__n_estimators'],\n",
    "            colsample_bytree=0.8, random_state=42, n_jobs=-1, verbosity=-1,\n",
    "        )\n",
    "\n",
    "    return Pipeline([('prep', prep), ('model', model)])\n",
    "\n",
    "\n",
    "def current_step(step_num):\n",
    "    \"\"\"Nome do incremento de features.\"\"\"\n",
    "    return {\n",
    "        0: 'SC 1', 1: 'SC 1 + SC 2', 2: 'SC 1 + SC 2 + CAD',\n",
    "        3: 'SC 1 + SC 2 + CAD + TELCO', 4: 'SC 1 + SC 2 + CAD + TELCO + REC',\n",
    "        5: 'SC 1 + SC 2 + CAD + TELCO + REC + PAG',\n",
    "        6: 'SC 1 + SC 2 + CAD + TELCO + REC + PAG + FAT',\n",
    "    }[step_num]\n",
    "\n",
    "print('Funcoes auxiliares carregadas')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 11.1 KS INCREMENTAL POR FONTE\n",
    "# =============================================================================\n",
    "feat_score_1 = ['TARGET_SCORE_01']\n",
    "feat_score_2 = ['TARGET_SCORE_02']\n",
    "feats_cadastro = [x for x in X_train_final.columns if 'var_' in x and _var_num(x) <= 25] + ['STATUSRF', 'UF', 'REGIAO', 'DIAS_VAR_12']\n",
    "feats_telco = [x for x in X_train_final.columns if 'var_' in x and _var_num(x) >= 26]\n",
    "feats_recargas = [x for x in X_train_final.columns if x.startswith('REC_')]\n",
    "feats_pagamentos = [x for x in X_train_final.columns if x.startswith('PAG_')]\n",
    "feats_faturamento = [x for x in X_train_final.columns if x.startswith('FAT_')]\n",
    "\n",
    "list_sources = [feat_score_1, feat_score_2, feats_cadastro, feats_telco, feats_recargas, feats_pagamentos, feats_faturamento]\n",
    "list_features = ['NUM_CPF', 'SAFRA']\n",
    "list_dict_results = []\n",
    "list_models = ['Reg Log', 'LGBM']\n",
    "\n",
    "for idx, source in enumerate(list_sources):\n",
    "    list_features.extend(source)\n",
    "\n",
    "    X_tr_filt = X_train_final[list_features]\n",
    "    X_oos_filt = X_oos_agg[list_features]\n",
    "    X_oot_filt = X_oot_agg[list_features]\n",
    "\n",
    "    for model in list_models:\n",
    "        pipe = update_pipeline(X_tr_filt, name_model=model)\n",
    "        pipe.fit(X_tr_filt, y_train_final)\n",
    "\n",
    "        for key in dict_safras:\n",
    "            map_data = generate_map_step_data(\n",
    "                X_tr_filt, y_train_final,\n",
    "                X_oos_filt, y_oos_agg,\n",
    "                X_oot_filt, y_oot_agg,\n",
    "            )\n",
    "            X_f, y_f = filter_xy_by_safra(map_data[key]['X'], map_data[key]['Y'], dict_safras[key])\n",
    "            auc, ks = evaluation_auc_ks(X_f, y_f, pipe, key, verbose=False)\n",
    "            list_dict_results.append({\n",
    "                'MODELO': model, 'CONJ FEATURES': current_step(idx),\n",
    "                'BASE': key, 'AUC': auc, 'KS': ks,\n",
    "            })\n",
    "\n",
    "df_results_ks_inc = pd.DataFrame(list_dict_results)\n",
    "\n",
    "print('\\n--- TREINO (CONS) ---')\n",
    "display(df_results_ks_inc[df_results_ks_inc['BASE'] == 'TREINO (CONS)'])\n",
    "\n",
    "print('\\n--- OOT GERAL (CONS) ---')\n",
    "display(df_results_ks_inc[df_results_ks_inc['BASE'] == 'OOT GERAL (CONS)'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 12.1 REMOCAO DE CADASTRO (baixo ganho) + FILTRAGEM POR FONTE FINAL\n",
    "# =============================================================================\n",
    "list_sources_final = [feat_score_1, feat_score_2, feats_telco, feats_recargas, feats_pagamentos, feats_faturamento]\n",
    "list_source_final_columns = [col for src in list_sources_final for col in src]\n",
    "\n",
    "X_train_final_filtered_sources = X_train_final[list_source_final_columns]\n",
    "print(f'Features apos remocao Cadastro: {len(list_source_final_columns)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 12.2 FEATURE SELECTION - IV UNIVARIADO\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_iv_numericals(df_iv, feature, target, total_good, total_bad, bins=10):\n",
    "    s = df_iv[feature]\n",
    "    if s.nunique() < 2:\n",
    "        return 0.0\n",
    "    try:\n",
    "        bins_series = pd.qcut(s, q=bins, duplicates='drop')\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "    grouped = df_iv.assign(bin=bins_series).groupby('bin')[target].value_counts().unstack(fill_value=0)\n",
    "    good = grouped.get(0, 0) + 0.5\n",
    "    bad = grouped.get(1, 0) + 0.5\n",
    "    dist_good = good / total_good\n",
    "    dist_bad = bad / total_bad\n",
    "    return ((dist_bad - dist_good) * np.log(dist_bad / dist_good)).sum()\n",
    "\n",
    "\n",
    "def calculate_iv_categoricals(df_iv, feature, target, total_good, total_bad):\n",
    "    s = df_iv[feature].astype('str').fillna('MISSING')\n",
    "    grouped = df_iv.assign(cat=s).groupby('cat')[target].value_counts().unstack(fill_value=0)\n",
    "    good = grouped.get(0, 0) + 0.5\n",
    "    bad = grouped.get(1, 0) + 0.5\n",
    "    dist_good = good / total_good\n",
    "    dist_bad = bad / total_bad\n",
    "    return ((dist_bad - dist_good) * np.log(dist_bad / dist_good)).sum()\n",
    "\n",
    "\n",
    "df_iv = pd.concat([X_train_final_filtered_sources, y_train_final], axis=1)\n",
    "total_good = (df_iv['FPD'] == 0).sum()\n",
    "total_bad = (df_iv['FPD'] == 1).sum()\n",
    "\n",
    "num_cols_iv = [n for n in X_train_final_filtered_sources.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns if n != 'SAFRA']\n",
    "cat_cols_iv = [c for c in X_train_final_filtered_sources.select_dtypes(include=['object', 'category']).columns if c != 'NUM_CPF']\n",
    "\n",
    "dict_ivs = {}\n",
    "for col in num_cols_iv:\n",
    "    dict_ivs[col] = calculate_iv_numericals(df_iv, col, 'FPD', total_good, total_bad)\n",
    "for col in cat_cols_iv:\n",
    "    dict_ivs[col] = calculate_iv_categoricals(df_iv, col, 'FPD', total_good, total_bad)\n",
    "\n",
    "iv_min = 0.02\n",
    "df_ivs = pd.Series(dict_ivs, name='IV').reset_index().rename(columns={'index': 'feature'}).sort_values('IV', ascending=False)\n",
    "features_to_drop_iv = df_ivs[df_ivs['IV'] < iv_min]['feature'].unique()\n",
    "print(f'Features com IV < {iv_min}: {len(features_to_drop_iv)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 12.3 FEATURE SELECTION - COEFICIENTES L1\n",
    "# =============================================================================\n",
    "pipeline_coefs = update_pipeline(X_train_final_filtered_sources, name_model='Reg Log')\n",
    "pipeline_coefs.fit(X_train_final_filtered_sources, y_train_final)\n",
    "\n",
    "coefs = pipeline_coefs.named_steps['model'].coef_[0]\n",
    "feature_names_coefs = pipeline_coefs.named_steps['prep'].get_feature_names_out()\n",
    "\n",
    "df_coefs_sel = pd.DataFrame({'feature': feature_names_coefs, 'coef': coefs})\n",
    "df_coefs_sel['abs_coef'] = df_coefs_sel['coef'].abs()\n",
    "df_coefs_sel = df_coefs_sel.sort_values('abs_coef', ascending=False)\n",
    "\n",
    "features_to_drop_coefs = []\n",
    "for name in df_coefs_sel[df_coefs_sel['abs_coef'] == 0]['feature'].tolist():\n",
    "    raw_name = name.split('__', 1)[-1] if '__' in name else name\n",
    "    features_to_drop_coefs.append(raw_name)\n",
    "\n",
    "print(f'Features com coef L1 = 0: {len(features_to_drop_coefs)}')\n",
    "print(f'Features restantes: {len(feature_names_coefs) - len(features_to_drop_coefs)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 12.4 FEATURE SELECTION - ALTA CORRELACAO (> 0.95)\n",
    "# =============================================================================\n",
    "corr_threshold = 0.95\n",
    "num_cols_for_corr = X_train_final_filtered_sources.select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns.tolist()\n",
    "corr_matrix = X_train_final_filtered_sources[num_cols_for_corr].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "features_to_drop_corrs = [col for col in upper.columns if any(upper[col] > corr_threshold)]\n",
    "\n",
    "print(f'Features com correlacao > {corr_threshold}: {len(features_to_drop_corrs)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 12.5 FEATURE SELECTION - LGBM IMPORTANCE (TOP 70)\n",
    "# =============================================================================\n",
    "pipeline_lgbm_fi = update_pipeline(X_train_final_filtered_sources, name_model='LGBM')\n",
    "pipeline_lgbm_fi.fit(X_train_final_filtered_sources, y_train_final)\n",
    "\n",
    "fi_names = pipeline_lgbm_fi.named_steps['prep'].get_feature_names_out()\n",
    "fi_values = pipeline_lgbm_fi.named_steps['model'].feature_importances_\n",
    "df_lgbm_fi = pd.DataFrame({'feature': fi_names, 'importance': fi_values}).sort_values('importance', ascending=False)\n",
    "\n",
    "TOP_N = 70\n",
    "top_lgbm_features = df_lgbm_fi.head(TOP_N)['feature'].tolist()\n",
    "cum_imp = df_lgbm_fi.head(TOP_N)['importance'].sum() / df_lgbm_fi['importance'].sum()\n",
    "print(f'LGBM Top {TOP_N}: importance cumulativa = {cum_imp:.1%}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top30 = df_lgbm_fi.head(30)\n",
    "ax.barh(range(len(top30)), top30['importance'].values)\n",
    "ax.set_yticks(range(len(top30)))\n",
    "ax.set_yticklabels(top30['feature'].values, fontsize=8)\n",
    "ax.set_xlabel('Feature Importance (LGBM)')\n",
    "ax.set_title('Top 30 Features - LGBM')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 12.6 CONSOLIDAR FEATURE SELECTION\n",
    "# =============================================================================\n",
    "total_features_to_drop = set(features_to_drop_iv) | set(features_to_drop_coefs) | set(features_to_drop_corrs)\n",
    "final_set_features = list(set(list_source_final_columns) - total_features_to_drop)\n",
    "\n",
    "print(f'Drop IV:          {len(features_to_drop_iv)}')\n",
    "print(f'Drop L1 coefs:    {len(features_to_drop_coefs)}')\n",
    "print(f'Drop correlacao:  {len(features_to_drop_corrs)}')\n",
    "print(f'Total a dropar:   {len(total_features_to_drop)}')\n",
    "print(f'Features finais:  {len(final_set_features)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Modelo Final com Features Selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 13. TREINO E AVALIACAO FINAL + MLFLOW\n",
    "# =============================================================================\n",
    "dimensions = ['NUM_CPF', 'SAFRA']\n",
    "final_features_with_dims = final_set_features + [d for d in dimensions if d not in final_set_features]\n",
    "\n",
    "X_tr_final_fs = X_train_final[final_features_with_dims]\n",
    "X_oos_fs = X_oos_agg[final_features_with_dims]\n",
    "X_oot_fs = X_oot_agg[final_features_with_dims]\n",
    "\n",
    "models = ['Reg Log', 'LGBM']\n",
    "list_results_fs = []\n",
    "best_model_name = None\n",
    "best_model_pipeline = None\n",
    "best_ks_oot = 0\n",
    "\n",
    "for model_name in models:\n",
    "    run_name = f\"Final_{model_name.replace(' ', '')}_FeatureSelection\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        pipe = update_pipeline(X_tr_final_fs, name_model=model_name)\n",
    "        pipe.fit(X_tr_final_fs, y_train_final)\n",
    "\n",
    "        mlflow.log_param('model_type', model_name)\n",
    "        mlflow.log_param('n_features', len(final_set_features))\n",
    "        mlflow.log_param('feature_selection', 'IV + L1_coefs + high_corr')\n",
    "        model_params = pipe.named_steps['model'].get_params()\n",
    "        for k, v in model_params.items():\n",
    "            if isinstance(v, (int, float, str, bool)):\n",
    "                mlflow.log_param(f'model__{k}', v)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f'MODELO FINAL: {model_name} ({len(final_set_features)} features)')\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        for key in dict_safras:\n",
    "            map_data = generate_map_step_data(\n",
    "                X_tr_final_fs, y_train_final,\n",
    "                X_oos_fs, y_oos_agg,\n",
    "                X_oot_fs, y_oot_agg,\n",
    "            )\n",
    "            X_f, y_f = filter_xy_by_safra(map_data[key]['X'], map_data[key]['Y'], dict_safras[key])\n",
    "            auc, ks = evaluation_auc_ks(X_f, y_f, pipe, key, verbose=True)\n",
    "\n",
    "            safe_key = _sanitize_mlflow_key(key)\n",
    "            mlflow.log_metric(f'AUC_{safe_key}', auc)\n",
    "            mlflow.log_metric(f'KS_{safe_key}', ks)\n",
    "            list_results_fs.append({'MODEL': model_name, 'BASE': key, 'AUC': auc, 'KS': ks})\n",
    "\n",
    "            if key == 'OOT GERAL (CONS)' and ks > best_ks_oot:\n",
    "                best_ks_oot = ks\n",
    "                best_model_name = model_name\n",
    "                best_model_pipeline = pipe\n",
    "\n",
    "        mlflow.sklearn.log_model(pipe, f\"model_final_{model_name.replace(' ', '_').lower()}\")\n",
    "        print(f'\\nMLflow Run ID ({model_name}): {run.info.run_id}')\n",
    "\n",
    "df_results_feat_selection = pd.DataFrame(list_results_fs)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f'MELHOR MODELO (KS OOT): {best_model_name} -- KS={best_ks_oot:.5f}')\n",
    "print(f'Benchmark KS: 33.1% (0.331)')\n",
    "print(f\"{'='*60}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Swap Analysis\n",
    "\n",
    "**Nota**: A swap analysis compara a estabilidade de ranking entre OOT1 e OOT2.\n",
    "Como sao periodos diferentes com clientes distintos, a comparacao e feita por\n",
    "**posicao ordinal** (top N% por score), nao por cliente individual.\n",
    "O objetivo e verificar se o modelo produz distribuicoes de ranking similares\n",
    "entre safras — swap% alto indica instabilidade temporal do modelo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 14. SWAP ANALYSIS (OOT1 vs OOT2)\n",
    "# =============================================================================\n",
    "\n",
    "def swap_analysis(df_ref, df_new, score_col='score', target_col='FPD', top_pct=0.1):\n",
    "    n = int(len(df_ref) * top_pct)\n",
    "    if n == 0:\n",
    "        return {'swap_in_%': 0, 'swap_out_%': 0, 'n_top': 0}\n",
    "    ref_top = df_ref.nlargest(n, score_col)\n",
    "    new_top = df_new.nlargest(n, score_col)\n",
    "    swap_in = len(set(new_top.index) - set(ref_top.index))\n",
    "    swap_out = len(set(ref_top.index) - set(new_top.index))\n",
    "    return {\n",
    "        'swap_in_%': round(swap_in / n * 100, 2),\n",
    "        'swap_out_%': round(swap_out / n * 100, 2),\n",
    "        'n_top': n,\n",
    "        'default_rate_ref': round(ref_top[target_col].mean(), 4) if target_col in ref_top.columns else None,\n",
    "        'default_rate_new': round(new_top[target_col].mean(), 4) if target_col in new_top.columns else None,\n",
    "    }\n",
    "\n",
    "\n",
    "print(f'Modelo utilizado: {best_model_name}')\n",
    "print('=' * 60)\n",
    "\n",
    "X_oot_feat = X_oot_fs.copy()\n",
    "scores_oot = best_model_pipeline.predict_proba(X_oot_feat)[:, 1]\n",
    "df_swap = X_oot_feat[['SAFRA']].copy()\n",
    "df_swap['score'] = scores_oot\n",
    "df_swap['FPD'] = y_oot_agg.values\n",
    "\n",
    "safras_oot_list = sorted(df_swap['SAFRA'].unique())\n",
    "print(f'Safras OOT: {safras_oot_list}')\n",
    "\n",
    "if len(safras_oot_list) >= 2:\n",
    "    for top_pct in [0.05, 0.10, 0.20, 0.30]:\n",
    "        df_ref = df_swap[df_swap['SAFRA'] == safras_oot_list[0]].reset_index(drop=True)\n",
    "        df_new = df_swap[df_swap['SAFRA'] == safras_oot_list[1]].reset_index(drop=True)\n",
    "        swap = swap_analysis(df_ref, df_new, top_pct=top_pct)\n",
    "        print(f\"\\nTop {top_pct:.0%} (n={swap['n_top']}):\")\n",
    "        print(f\"  Swap-in:  {swap['swap_in_%']:.1f}%\")\n",
    "        print(f\"  Swap-out: {swap['swap_out_%']:.1f}%\")\n",
    "        print(f\"  Default Rate OOT1 ({safras_oot_list[0]}): {swap['default_rate_ref']}\")\n",
    "        print(f\"  Default Rate OOT2 ({safras_oot_list[1]}): {swap['default_rate_new']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualizacoes Finais"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 15. VISUALIZACOES (KS Curve, Score Dist, Confusion Matrix, KS por Safra)\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "y_oot_vis = y_oot_agg.values\n",
    "scores_vis = best_model_pipeline.predict_proba(X_oot_fs)[:, 1]\n",
    "df_ks = pd.DataFrame({'y': y_oot_vis, 'score': scores_vis}).sort_values('score')\n",
    "df_ks['cum_good'] = (1 - df_ks['y']).cumsum() / (1 - df_ks['y']).sum()\n",
    "df_ks['cum_bad'] = df_ks['y'].cumsum() / df_ks['y'].sum()\n",
    "df_ks['ks_diff'] = np.abs(df_ks['cum_bad'] - df_ks['cum_good'])\n",
    "ks_max_idx = df_ks['ks_diff'].idxmax()\n",
    "ks_max_val = df_ks.loc[ks_max_idx, 'ks_diff']\n",
    "\n",
    "x_axis = np.linspace(0, 1, len(df_ks))\n",
    "ax1.plot(x_axis, df_ks['cum_good'].values, label='Bons (FPD=0)', color='blue')\n",
    "ax1.plot(x_axis, df_ks['cum_bad'].values, label='Maus (FPD=1)', color='red')\n",
    "ax1.axvline(x=x_axis[df_ks.index.get_loc(ks_max_idx)], color='green', linestyle='--', alpha=0.7)\n",
    "ax1.set_title(f'KS Curve - OOT ({best_model_name}) | KS = {ks_max_val:.4f}')\n",
    "ax1.set_xlabel('Populacao (%)')\n",
    "ax1.set_ylabel('CDF')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(scores_vis[y_oot_vis == 0], bins=50, alpha=0.6, label='Bons (FPD=0)', color='blue', density=True)\n",
    "ax2.hist(scores_vis[y_oot_vis == 1], bins=50, alpha=0.6, label='Maus (FPD=1)', color='red', density=True)\n",
    "ax2.set_title(f'Distribuicao de Scores - OOT ({best_model_name})')\n",
    "ax2.set_xlabel('Score (Prob FPD)')\n",
    "ax2.set_ylabel('Densidade')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "y_pred = (scores_vis >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_oot_vis, y_pred)\n",
    "ax3.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax3.set_title(f'Confusion Matrix - OOT ({best_model_name})')\n",
    "ax3.set_ylabel('Real')\n",
    "ax3.set_xlabel('Predito')\n",
    "ax3.set_xticks([0, 1])\n",
    "ax3.set_yticks([0, 1])\n",
    "ax3.set_xticklabels(['Bom (0)', 'Mau (1)'])\n",
    "ax3.set_yticklabels(['Bom (0)', 'Mau (1)'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax3.text(j, i, f'{cm[i, j]:,}', ha='center', va='center',\n",
    "                color='white' if cm[i, j] > cm.max() / 2 else 'black', fontsize=12)\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "df_oot_res = df_results_feat_selection[\n",
    "    (df_results_feat_selection['MODEL'] == best_model_name) &\n",
    "    (df_results_feat_selection['BASE'].str.contains('OOT|OOS'))\n",
    "]\n",
    "if not df_oot_res.empty:\n",
    "    bars = ax4.bar(range(len(df_oot_res)), df_oot_res['KS'].values, color='steelblue')\n",
    "    ax4.set_xticks(range(len(df_oot_res)))\n",
    "    ax4.set_xticklabels(df_oot_res['BASE'].values, rotation=45, ha='right', fontsize=8)\n",
    "    ax4.axhline(y=0.331, color='red', linestyle='--', label='Benchmark KS = 33.1%')\n",
    "    ax4.set_title(f'KS por Base - {best_model_name}')\n",
    "    ax4.set_ylabel('KS')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    for bar, val in zip(bars, df_oot_res['KS'].values):\n",
    "        ax4.text(bar.get_x() + bar.get_width() / 2, val + 0.005, f'{val:.3f}', ha='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('/tmp/final_model_visualizations.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "with mlflow.start_run(run_name='Final_Visualizations'):\n",
    "    mlflow.log_artifact('/tmp/final_model_visualizations.png', 'plots')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nModelo final: {best_model_name}')\n",
    "print(f'KS OOT: {best_ks_oot:.5f}')\n",
    "print(f'Benchmark: 0.331')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Export do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 16. EXPORT DO MODELO PARA MLFLOW REGISTRY\n",
    "# =============================================================================\n",
    "sys.path.insert(0, '/lakehouse/default/Files/projeto-final/5-treinamento-modelos')\n",
    "from export_model import export_model, promote_to_production\n",
    "\n",
    "feature_names_export = [f for f in final_set_features if f not in ['NUM_CPF', 'SAFRA']]\n",
    "\n",
    "X_oot_exp = X_oot_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore')\n",
    "X_oos_exp = X_oos_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore')\n",
    "\n",
    "print(f'Modelo a exportar: {best_model_name}')\n",
    "print(f'Features: {len(feature_names_export)}')\n",
    "print(f'KS OOT (mesmo pipeline da selecao): {best_ks_oot:.5f}')\n",
    "print('=' * 60)\n",
    "\n",
    "# --- LGBM (principal) ---\n",
    "if best_model_name == 'LGBM':\n",
    "    pipe_lgbm_export = best_model_pipeline\n",
    "else:\n",
    "    pipe_lgbm_export = update_pipeline(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), name_model='LGBM'\n",
    "    )\n",
    "    pipe_lgbm_export.fit(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), y_train_final\n",
    "    )\n",
    "\n",
    "ks_oot_lgbm = ks_stat(y_oot_agg, pipe_lgbm_export.predict_proba(X_oot_fs)[:, 1])\n",
    "auc_oot_lgbm = roc_auc_score(y_oot_agg, pipe_lgbm_export.predict_proba(X_oot_fs)[:, 1])\n",
    "ks_oos_lgbm = ks_stat(y_oos_agg, pipe_lgbm_export.predict_proba(X_oos_fs)[:, 1])\n",
    "auc_oos_lgbm = roc_auc_score(y_oos_agg, pipe_lgbm_export.predict_proba(X_oos_fs)[:, 1])\n",
    "\n",
    "ks_oos_202501 = None\n",
    "auc_oos_202501 = None\n",
    "X_oos_501, y_oos_501 = filter_xy_by_safra(X_oos_fs, y_oos_agg, [202501])\n",
    "if len(y_oos_501) > 0:\n",
    "    proba_501 = pipe_lgbm_export.predict_proba(X_oos_501)[:, 1]\n",
    "    ks_oos_202501 = ks_stat(y_oos_501, proba_501)\n",
    "    auc_oos_202501 = roc_auc_score(y_oos_501, proba_501)\n",
    "\n",
    "metrics_lgbm = {\n",
    "    'ks_oot': ks_oot_lgbm, 'auc_oot': auc_oot_lgbm,\n",
    "    'ks_oos': ks_oos_lgbm, 'auc_oos': auc_oos_lgbm,\n",
    "    'gini_oot': (2 * auc_oot_lgbm - 1) * 100,\n",
    "    'gini_oos': (2 * auc_oos_lgbm - 1) * 100,\n",
    "}\n",
    "if ks_oos_202501 is not None:\n",
    "    metrics_lgbm['ks_oos_202501'] = ks_oos_202501\n",
    "    metrics_lgbm['auc_oos_202501'] = auc_oos_202501\n",
    "    metrics_lgbm['gini_oos_202501'] = (2 * auc_oos_202501 - 1) * 100\n",
    "\n",
    "result_lgbm = export_model(\n",
    "    pipeline=pipe_lgbm_export, model_name='lgbm_baseline',\n",
    "    X_test=X_oot_exp, y_test=y_oot_agg,\n",
    "    feature_names=feature_names_export,\n",
    "    metrics_dict=metrics_lgbm,\n",
    ")\n",
    "print(f\"\\nLGBM exportado: {result_lgbm['registered_name']}\")\n",
    "print(f\"  MLflow Run ID: {result_lgbm['mlflow_run_id']}\")\n",
    "print(f\"  PKL: {result_lgbm['pkl_path']}\")\n",
    "print(f\"  KS OOT: {ks_oot_lgbm:.5f}\")\n",
    "print(f\"  KS OOS: {ks_oos_lgbm:.5f}\")\n",
    "if ks_oos_202501 is not None:\n",
    "    print(f\"  KS OOS 202501: {ks_oos_202501:.5f}\")\n",
    "\n",
    "# --- LR (benchmark) ---\n",
    "if best_model_name == 'Reg Log':\n",
    "    pipe_lr_export = best_model_pipeline\n",
    "else:\n",
    "    pipe_lr_export = update_pipeline(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), name_model='Reg Log'\n",
    "    )\n",
    "    pipe_lr_export.fit(\n",
    "        X_tr_final_fs.drop(columns=['NUM_CPF', 'SAFRA'], errors='ignore'), y_train_final\n",
    "    )\n",
    "\n",
    "ks_oot_lr = ks_stat(y_oot_agg, pipe_lr_export.predict_proba(X_oot_fs)[:, 1])\n",
    "auc_oot_lr = roc_auc_score(y_oot_agg, pipe_lr_export.predict_proba(X_oot_fs)[:, 1])\n",
    "\n",
    "result_lr = export_model(\n",
    "    pipeline=pipe_lr_export, model_name='logistic_regression_l1',\n",
    "    X_test=X_oot_exp, y_test=y_oot_agg,\n",
    "    feature_names=feature_names_export,\n",
    "    metrics_dict={\n",
    "        'ks_oot': ks_oot_lr, 'auc_oot': auc_oot_lr,\n",
    "        'gini_oot': (2 * auc_oot_lr - 1) * 100,\n",
    "    },\n",
    ")\n",
    "print(f\"\\nLR exportado: {result_lr['registered_name']}\")\n",
    "print(f\"  MLflow Run ID: {result_lr['mlflow_run_id']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print('Export concluido! Modelos registrados no MLflow em Staging.')\n",
    "print('Proximo passo: executar scoring_batch e validacao_deploy')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}