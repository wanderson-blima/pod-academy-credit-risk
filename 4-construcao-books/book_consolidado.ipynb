{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# üèÜ Book com Feature Store Consolidada\n",
    "\n",
    "## Objetivo\n",
    "Consolidar todas as vari√°veis dispon√≠veis em um √∫nico dataset enriquecido para alimentar modelos de Machine Learning.\n",
    "\n",
    "## Arquitetura de Dados\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                          BOOK - FEATURE STORE                                                  ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                                                ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                                         ‚îÇ\n",
    "‚îÇ   ‚îÇ dados_cadastrais ‚îÇ ‚óÑ‚îÄ‚îÄ BASE PRINCIPAL (Chave: NUM_CPF + SAFRA)                             ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                                         ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                                                   ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ\n",
    "‚îÇ   ‚îÇ                  ‚îÇ                   ‚îÇ                   ‚îÇ                     ‚îÇ           ‚îÇ\n",
    "‚îÇ   ‚ñº                  ‚ñº                   ‚ñº                   ‚ñº                     ‚ñº           ‚îÇ\n",
    "‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ ‚îÇtelco ‚îÇ    ‚îÇscore_bureau_   ‚îÇ    ‚îÇass_recarga_ ‚îÇ    ‚îÇbook_recargas_‚îÇ    ‚îÇ book_faturamento ‚îÇ  ‚îÇ\n",
    "‚îÇ ‚îÇ      ‚îÇ    ‚îÇmovel (TARGET)  ‚îÇ    ‚îÇcmv_nova     ‚îÇ    ‚îÇpagamento     ‚îÇ    ‚îÇ                  ‚îÇ  ‚îÇ\n",
    "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ                                                                                                ‚îÇ\n",
    "‚îÇ                                                                                                ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Tabelas Fonte\n",
    "\n",
    "| Tabela | Camada | Tipo | Descri√ß√£o |\n",
    "|--------|--------|------|----------|\n",
    "| dados_cadastrais | Silver | Base | Dados cadastrais e perfil do cliente |\n",
    "| telco | Silver | Enriquecimento | Vari√°veis de comportamento telco |\n",
    "| score_bureau_movel | Silver | **Target** | Scores e vari√°veis resposta (FPD) |\n",
    "| ass_recarga_cmv_nova | Book | Features | Book de recargas CMV |\n",
    "| book_recargas_pagamento | Book | Features | Book de pagamentos |\n",
    "| book_faturamento | Book | Features | Book de faturamento |\n",
    "\n",
    "## Destino\n",
    "- **Lakehouse**: Gold\n",
    "- **Schema**: feature_store\n",
    "- **Tabela**: clientes\n",
    "\n",
    "---\n",
    "**Vers√£o**: 1.0  \n",
    "**Granularidade**: NUM_CPF + SAFRA\n"
   ],
   "metadata": {},
   "id": "f37b92fc-f091-4654-bf37-05f5b2698ce1"
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# CONFIGURA√á√ÉO DO AMBIENTE (importado do config centralizado)\n# =============================================================================\nimport sys; sys.path.insert(0, \"/lakehouse/default/Files/projeto-final\")\nfrom config.pipeline_config import (\n    SILVER_BASE, GOLD_BASE,\n    PATH_DADOS_CADASTRAIS, PATH_TELCO, PATH_SCORE_BUREAU,\n    PATH_BOOK_RECARGA_CMV, PATH_BOOK_PAGAMENTO, PATH_BOOK_FATURAMENTO,\n    PATH_FEATURE_STORE\n)\n\n# Lakehouse paths (para compatibilidade com print abaixo)\nLAKEHOUSE_SILVER = SILVER_BASE\nLAKEHOUSE_GOLD = GOLD_BASE\n\n# =============================================================================\n# PATHS DE SA√çDA (Gold)\n# =============================================================================\nPATH_OUTPUT = PATH_FEATURE_STORE\n\nprint(\"‚úÖ Configura√ß√£o carregada com sucesso\")\nprint(f\"\\nüì• Origem (Silver): {LAKEHOUSE_SILVER.split('/')[-1][:8]}...\")\nprint(f\"üì§ Destino (Gold): {LAKEHOUSE_GOLD.split('/')[-1][:8]}...\")\nprint(f\"\\nüìÅ Output: feature_store.clientes_consolidado\")",
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "57889da2-fa4e-4379-a3f8-0b18d77280a7"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# CARREGAMENTO DAS TABELAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Carregando tabelas...\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TABELA BASE: dados_cadastrais\n",
    "# -----------------------------------------------------------------------------\n",
    "df_cadastro = spark.read.format(\"delta\").load(PATH_DADOS_CADASTRAIS)\n",
    "print(f\"‚úÖ dados_cadastrais: {df_cadastro.count():,} registros | {len(df_cadastro.columns)} colunas\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TABELAS DE ENRIQUECIMENTO (Raw)\n",
    "# -----------------------------------------------------------------------------\n",
    "df_telco = spark.read.format(\"delta\").load(PATH_TELCO)\n",
    "print(f\"‚úÖ telco: {df_telco.count():,} registros | {len(df_telco.columns)} colunas\")\n",
    "\n",
    "df_score_bureau = spark.read.format(\"delta\").load(PATH_SCORE_BUREAU)\n",
    "print(f\"‚úÖ score_bureau_movel: {df_score_bureau.count():,} registros | {len(df_score_bureau.columns)} colunas\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# BOOKS DE FEATURES\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    df_book_recarga = spark.read.format(\"delta\").load(PATH_BOOK_RECARGA_CMV)\n",
    "    print(f\"‚úÖ book_recarga_cmv: {df_book_recarga.count():,} registros | {len(df_book_recarga.columns)} colunas\")\n",
    "    HAS_BOOK_RECARGA = True\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è book_recarga_cmv: N√£o encontrado - ser√° ignorado\")\n",
    "    HAS_BOOK_RECARGA = False\n",
    "\n",
    "try:\n",
    "    df_book_pagamento = spark.read.format(\"delta\").load(PATH_BOOK_PAGAMENTO)\n",
    "    print(f\"‚úÖ book_pagamento: {df_book_pagamento.count():,} registros | {len(df_book_pagamento.columns)} colunas\")\n",
    "    HAS_BOOK_PAGAMENTO = True\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è book_pagamento: N√£o encontrado - ser√° ignorado\")\n",
    "    HAS_BOOK_PAGAMENTO = False\n",
    "\n",
    "try:\n",
    "    df_book_faturamento = spark.read.format(\"delta\").load(PATH_BOOK_FATURAMENTO)\n",
    "    print(f\"‚úÖ book_faturamento: {df_book_faturamento.count():,} registros | {len(df_book_faturamento.columns)} colunas\")\n",
    "    HAS_BOOK_FATURAMENTO = True\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è book_faturamento: N√£o encontrado - ser√° ignorado\")\n",
    "    HAS_BOOK_FATURAMENTO = False\n",
    "\n",
    "print(\"\\n‚úÖ Carregamento conclu√≠do\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 4,
       "statement_ids": [
        4
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:29.1938659Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:10:40.2633148Z",
       "execution_finish_time": "2026-01-15T00:11:05.8705657Z",
       "parent_msg_id": "64383a5d-1d17-45f4-ac0a-2445223365c3"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 4, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä Carregando tabelas...\n\n‚úÖ dados_cadastrais: 3,900,378 registros | 36 colunas\n‚úÖ telco: 1,367,104 registros | 77 colunas\n‚úÖ score_bureau_movel: 1,290,526 registros | 11 colunas\n‚úÖ book_recarga_cmv: 32,882,218 registros | 105 colunas\n‚úÖ book_pagamento: 12,633,614 registros | 157 colunas\n‚úÖ book_faturamento: 15,023,012 registros | 111 colunas\n\n‚úÖ Carregamento conclu√≠do\n"
     ]
    }
   ],
   "execution_count": 2,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "eadd182b-994f-439d-bd02-4e5592a470ef"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# REGISTRO DE VIEWS TEMPOR√ÅRIAS\n",
    "# =============================================================================\n",
    "\n",
    "df_cadastro.createOrReplaceTempView(\"dados_cadastrais\")\n",
    "df_telco.createOrReplaceTempView(\"telco\")\n",
    "df_score_bureau.createOrReplaceTempView(\"score_bureau_movel\")\n",
    "\n",
    "if HAS_BOOK_RECARGA:\n",
    "    df_book_recarga.createOrReplaceTempView(\"book_recarga_cmv\")\n",
    "    \n",
    "if HAS_BOOK_PAGAMENTO:\n",
    "    df_book_pagamento.createOrReplaceTempView(\"book_pagamento\")\n",
    "    \n",
    "if HAS_BOOK_FATURAMENTO:\n",
    "    df_book_faturamento.createOrReplaceTempView(\"book_faturamento\")\n",
    "\n",
    "print(\"‚úÖ Views tempor√°rias registradas\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 5,
       "statement_ids": [
        5
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:29.6379492Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:11:05.8733777Z",
       "execution_finish_time": "2026-01-15T00:11:06.5563433Z",
       "parent_msg_id": "0a5c0499-6746-4756-af5d-903e7c2a2652"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 5, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Views tempor√°rias registradas\n"
     ]
    }
   ],
   "execution_count": 3,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "5e4dea9c-98f9-4b7d-be70-fdf2b8577465"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# IDENTIFICA√á√ÉO DE COLUNAS A EXCLUIR\n",
    "# =============================================================================\n",
    "\n",
    "# Colunas de metadados que devem ser removidas de todas as tabelas\n",
    "COLUNAS_METADADOS = [\n",
    "    '_execution_id',\n",
    "    '_data_inclusao',\n",
    "    '_data_alteracao_silver',\n",
    "    'DT_PROCESSAMENTO'  # Coluna de controle dos books\n",
    "]\n",
    "\n",
    "# Colunas de chave que s√≥ devem vir da tabela base (dados_cadastrais)\n",
    "COLUNAS_CHAVE = ['NUM_CPF', 'SAFRA']\n",
    "\n",
    "# Colunas duplicadas entre tabelas (manter apenas da base)\n",
    "COLUNAS_DUPLICADAS_TELCO = ['FLAG_INSTALACAO', 'FPD', 'PROD', 'flag_mig2']\n",
    "COLUNAS_DUPLICADAS_SCORE = ['FLAG_INSTALACAO', 'FPD', 'PROD', 'flag_mig2']\n",
    "\n",
    "print(\"‚úÖ Colunas de exclus√£o definidas\")\n",
    "print(f\"   - Metadados: {COLUNAS_METADADOS}\")\n",
    "print(f\"   - Chaves (s√≥ da base): {COLUNAS_CHAVE}\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 6,
       "statement_ids": [
        6
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:29.9521272Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:11:06.5583749Z",
       "execution_finish_time": "2026-01-15T00:11:06.8774194Z",
       "parent_msg_id": "7ad9bb7f-88a2-4de5-9124-a05a2d39b7ad"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 6, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Colunas de exclus√£o definidas\n   - Metadados: ['_execution_id', '_data_inclusao', '_data_alteracao_silver', 'DT_PROCESSAMENTO']\n   - Chaves (s√≥ da base): ['NUM_CPF', 'SAFRA']\n"
     ]
    }
   ],
   "execution_count": 4,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "b6ce6470-1560-4e93-84e6-52ea639ec545"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# FUN√á√ïES AUXILIARES\n",
    "# =============================================================================\n",
    "\n",
    "def get_columns_to_select(df, table_alias, exclude_cols, prefix=None):\n",
    "    \"\"\"\n",
    "    Retorna lista de colunas formatadas para SELECT, excluindo as especificadas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame Spark\n",
    "        table_alias: Alias da tabela no SQL\n",
    "        exclude_cols: Lista de colunas a excluir\n",
    "        prefix: Prefixo opcional para renomear colunas\n",
    "    \n",
    "    Returns:\n",
    "        String com colunas formatadas para SQL\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if col.lower() not in [c.lower() for c in exclude_cols]:\n",
    "            if prefix:\n",
    "                cols.append(f\"{table_alias}.{col} AS {prefix}_{col}\")\n",
    "            else:\n",
    "                cols.append(f\"{table_alias}.{col}\")\n",
    "    return cols\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes auxiliares carregadas\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 7,
       "statement_ids": [
        7
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:30.2685897Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:11:06.8794824Z",
       "execution_finish_time": "2026-01-15T00:11:07.3115634Z",
       "parent_msg_id": "cc4c89af-6e70-46a4-953f-ece680665aaa"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 7, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Fun√ß√µes auxiliares carregadas\n"
     ]
    }
   ],
   "execution_count": 5,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "50d52815-ee1e-471d-80d9-740c9b5fda2f"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# CONSTRU√á√ÉO DIN√ÇMICA DA QUERY\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. COLUNAS DA TABELA BASE (dados_cadastrais)\n",
    "# -----------------------------------------------------------------------------\n",
    "cols_cadastro = get_columns_to_select(\n",
    "    df_cadastro, \n",
    "    'c', \n",
    "    COLUNAS_METADADOS\n",
    ")\n",
    "print(f\"üìä dados_cadastrais: {len(cols_cadastro)} colunas selecionadas\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. COLUNAS DA TABELA TELCO (excluir chaves e duplicadas)\n",
    "# -----------------------------------------------------------------------------\n",
    "exclude_telco = COLUNAS_METADADOS + COLUNAS_CHAVE + COLUNAS_DUPLICADAS_TELCO\n",
    "cols_telco = get_columns_to_select(\n",
    "    df_telco, \n",
    "    't', \n",
    "    exclude_telco\n",
    ")\n",
    "print(f\"üìä telco: {len(cols_telco)} colunas selecionadas\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. COLUNAS DO SCORE BUREAU (TARGET - vari√°veis resposta)\n",
    "# -----------------------------------------------------------------------------\n",
    "exclude_score = COLUNAS_METADADOS + COLUNAS_CHAVE + COLUNAS_DUPLICADAS_SCORE\n",
    "cols_score = get_columns_to_select(\n",
    "    df_score_bureau, \n",
    "    's', \n",
    "    exclude_score\n",
    ")\n",
    "# Renomear scores para identificar como TARGET\n",
    "cols_score_renamed = []\n",
    "for col in cols_score:\n",
    "    if 'SCORE_' in col:\n",
    "        cols_score_renamed.append(col.replace('s.SCORE_', 's.SCORE_') + ' AS TARGET_SCORE_' + col.split('SCORE_')[1])\n",
    "    else:\n",
    "        cols_score_renamed.append(col)\n",
    "cols_score = cols_score_renamed\n",
    "print(f\"üìä score_bureau_movel (TARGET): {len(cols_score)} colunas selecionadas\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. COLUNAS DO BOOK RECARGA CMV\n",
    "# -----------------------------------------------------------------------------\n",
    "if HAS_BOOK_RECARGA:\n",
    "    exclude_recarga = COLUNAS_METADADOS + COLUNAS_CHAVE\n",
    "    cols_recarga = get_columns_to_select(\n",
    "        df_book_recarga, \n",
    "        'r', \n",
    "        exclude_recarga,\n",
    "        prefix='REC'  # Prefixo para identificar origem\n",
    "    )\n",
    "    print(f\"üìä book_recarga_cmv: {len(cols_recarga)} colunas selecionadas\")\n",
    "else:\n",
    "    cols_recarga = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. COLUNAS DO BOOK PAGAMENTO\n",
    "# -----------------------------------------------------------------------------\n",
    "if HAS_BOOK_PAGAMENTO:\n",
    "    exclude_pagamento = COLUNAS_METADADOS + COLUNAS_CHAVE\n",
    "    cols_pagamento = get_columns_to_select(\n",
    "        df_book_pagamento, \n",
    "        'p', \n",
    "        exclude_pagamento,\n",
    "        prefix='PAG'  # Prefixo para identificar origem\n",
    "    )\n",
    "    print(f\"üìä book_pagamento: {len(cols_pagamento)} colunas selecionadas\")\n",
    "else:\n",
    "    cols_pagamento = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. COLUNAS DO BOOK FATURAMENTO\n",
    "# -----------------------------------------------------------------------------\n",
    "if HAS_BOOK_FATURAMENTO:\n",
    "    exclude_faturamento = COLUNAS_METADADOS + COLUNAS_CHAVE\n",
    "    cols_faturamento = get_columns_to_select(\n",
    "        df_book_faturamento, \n",
    "        'f', \n",
    "        exclude_faturamento,\n",
    "        prefix='FAT'  # Prefixo para identificar origem\n",
    "    )\n",
    "    print(f\"üìä book_faturamento: {len(cols_faturamento)} colunas selecionadas\")\n",
    "else:\n",
    "    cols_faturamento = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TOTAL DE COLUNAS\n",
    "# -----------------------------------------------------------------------------\n",
    "total_colunas = len(cols_cadastro) + len(cols_telco) + len(cols_score) + \\\n",
    "                len(cols_recarga) + len(cols_pagamento) + len(cols_faturamento) + 1  # +1 para DT_PROCESSAMENTO\n",
    "\n",
    "print(f\"\\nüìä TOTAL DE COLUNAS NO SUPER BOOK: {total_colunas}\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 8,
       "statement_ids": [
        8
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:30.569777Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:11:07.3138155Z",
       "execution_finish_time": "2026-01-15T00:11:07.6540255Z",
       "parent_msg_id": "a67a138f-8588-4a04-ab80-bd1f385522d4"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 8, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä dados_cadastrais: 33 colunas selecionadas\nüìä telco: 68 colunas selecionadas\nüìä score_bureau_movel (TARGET): 2 colunas selecionadas\nüìä book_recarga_cmv: 102 colunas selecionadas\nüìä book_pagamento: 154 colunas selecionadas\nüìä book_faturamento: 108 colunas selecionadas\n\nüìä TOTAL DE COLUNAS NO SUPER BOOK: 468\n"
     ]
    }
   ],
   "execution_count": 6,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "305b823b-5c0f-4795-b9c1-0fa3e0479386"
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# MONTAGEM DA QUERY SQL\n# =============================================================================\n\n# Concatenar todas as colunas\nall_columns = cols_cadastro + cols_telco + cols_score + cols_recarga + cols_pagamento + cols_faturamento\nall_columns.append(\"CURRENT_TIMESTAMP() AS DT_PROCESSAMENTO\")\n\n# Formatar colunas para SQL\ncolumns_sql = \",\\n        \".join(all_columns)\n\n# Construir JOINs dinamicamente\njoins_sql = \"\"\"\n    -- JOIN com Telco (vari√°veis de comportamento)\n    LEFT JOIN telco t \n        ON c.NUM_CPF = t.NUM_CPF \n        AND c.SAFRA = t.SAFRA\n    \n    -- JOIN com Score Bureau (vari√°veis TARGET/resposta)\n    LEFT JOIN score_bureau_movel s \n        ON c.NUM_CPF = s.NUM_CPF \n        AND c.SAFRA = s.SAFRA\n\"\"\"\n\nif HAS_BOOK_RECARGA:\n    joins_sql += \"\"\"\n    -- JOIN com Book Recarga CMV (SAFRA agora √© INT em ambos os lados)\n    LEFT JOIN book_recarga_cmv r \n        ON c.NUM_CPF = r.NUM_CPF \n        AND c.SAFRA = r.SAFRA\n\"\"\"\n\nif HAS_BOOK_PAGAMENTO:\n    joins_sql += \"\"\"\n    -- JOIN com Book Pagamento (SAFRA agora √© INT em ambos os lados)\n    LEFT JOIN book_pagamento p \n        ON c.NUM_CPF = p.NUM_CPF \n        AND c.SAFRA = p.SAFRA\n\"\"\"\n\nif HAS_BOOK_FATURAMENTO:\n    joins_sql += \"\"\"\n    -- JOIN com Book Faturamento (SAFRA agora √© INT em ambos os lados)\n    LEFT JOIN book_faturamento f \n        ON c.NUM_CPF = f.NUM_CPF \n        AND c.SAFRA = f.SAFRA\n\"\"\"\n\n# Query final\nquery_super_book = f\"\"\"\n-- =============================================================================\n-- SUPER BOOK - FEATURE STORE CONSOLIDADA\n-- =============================================================================\n-- Granularidade: NUM_CPF + SAFRA\n-- Destino: Gold.feature_store.clientes_consolidado\n-- =============================================================================\n\nSELECT \n        {columns_sql}\n\nFROM dados_cadastrais c\n{joins_sql}\n\"\"\"\n\nprint(\"‚úÖ Query SQL constru√≠da com sucesso\")\nprint(f\"\\nüìù Preview da query (primeiros 2000 caracteres):\")\nprint(query_super_book[:2000] + \"...\")",
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "9649847a-3c77-4548-84ce-27729a33b920"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# EXECU√á√ÉO DA QUERY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"‚è≥ Executando query do Super Book...\")\n",
    "\n",
    "df_super_book = spark.sql(query_super_book)\n",
    "\n",
    "# Cache para otimiza√ß√£o\n",
    "df_super_book.cache()\n",
    "\n",
    "# Contagens\n",
    "total_registros = df_super_book.count()\n",
    "total_colunas_final = len(df_super_book.columns)\n",
    "\n",
    "print(f\"\\n‚úÖ Super Book gerado com sucesso!\")\n",
    "print(f\"üìä Total de registros: {total_registros:,}\")\n",
    "print(f\"üìä Total de vari√°veis: {total_colunas_final}\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 10,
       "statement_ids": [
        10
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:31.044886Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:11:07.963273Z",
       "execution_finish_time": "2026-01-15T00:15:25.2516856Z",
       "parent_msg_id": "8433ad42-d6c2-4b04-96a7-c4f83ecb6d0e"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 10, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚è≥ Executando query do Super Book...\n\n‚úÖ Super Book gerado com sucesso!\nüìä Total de registros: 3,900,378\nüìä Total de vari√°veis: 468\n"
     ]
    }
   ],
   "execution_count": 8,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "e1980bf6-553f-4f76-8c9d-890bae24b615"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# VALIDA√á√ÉO DO SCHEMA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìã Schema do Super Book:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Agrupar colunas por origem\n",
    "colunas_por_origem = {\n",
    "    'CADASTRO': [],\n",
    "    'TELCO': [],\n",
    "    'TARGET (SCORE_BUREAU)': [],\n",
    "    'BOOK_RECARGA': [],\n",
    "    'BOOK_PAGAMENTO': [],\n",
    "    'BOOK_FATURAMENTO': [],\n",
    "    'CONTROLE': []\n",
    "}\n",
    "\n",
    "for col in df_super_book.columns:\n",
    "    if col.startswith('REC_'):\n",
    "        colunas_por_origem['BOOK_RECARGA'].append(col)\n",
    "    elif col.startswith('PAG_'):\n",
    "        colunas_por_origem['BOOK_PAGAMENTO'].append(col)\n",
    "    elif col.startswith('FAT_'):\n",
    "        colunas_por_origem['BOOK_FATURAMENTO'].append(col)\n",
    "    elif col.startswith('TARGET_') or col.startswith('SCORE_'):\n",
    "        colunas_por_origem['TARGET (SCORE_BUREAU)'].append(col)\n",
    "    elif col.startswith('var_'):\n",
    "        colunas_por_origem['TELCO'].append(col)\n",
    "    elif col == 'DT_PROCESSAMENTO':\n",
    "        colunas_por_origem['CONTROLE'].append(col)\n",
    "    else:\n",
    "        colunas_por_origem['CADASTRO'].append(col)\n",
    "\n",
    "for origem, colunas in colunas_por_origem.items():\n",
    "    if colunas:\n",
    "        print(f\"\\nüìÅ {origem} ({len(colunas)} colunas):\")\n",
    "        for col in colunas[:10]:  # Mostrar apenas 10 primeiras\n",
    "            print(f\"   - {col}\")\n",
    "        if len(colunas) > 10:\n",
    "            print(f\"   ... e mais {len(colunas) - 10} colunas\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 11,
       "statement_ids": [
        11
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:31.2374724Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:15:25.2542582Z",
       "execution_finish_time": "2026-01-15T00:15:25.5749683Z",
       "parent_msg_id": "4bf23685-943e-48a9-949b-59c1ea35ffac"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 11, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìã Schema do Super Book:\n======================================================================\n\nüìÅ CADASTRO (9 colunas):\n   - NUM_CPF\n   - SAFRA\n   - FLAG_INSTALACAO\n   - FPD\n   - PROD\n   - flag_mig2\n   - STATUSRF\n   - DATADENASCIMENTO\n   - CEP_3_digitos\n\nüìÅ TELCO (92 colunas):\n   - var_03\n   - var_02\n   - var_04\n   - var_05\n   - var_06\n   - var_07\n   - var_08\n   - var_09\n   - var_10\n   - var_11\n   ... e mais 82 colunas\n\nüìÅ TARGET (SCORE_BUREAU) (2 colunas):\n   - TARGET_SCORE_01\n   - TARGET_SCORE_02\n\nüìÅ BOOK_RECARGA (102 colunas):\n   - REC_QTD_RECARGAS_TOTAL\n   - REC_QTD_LINHAS_DISTINTAS\n   - REC_QTD_DIAS_COM_RECARGA\n   - REC_QTD_DIAS_ATIVOS\n   - REC_QTD_RECARGAS_POR_DIA_ATIVO\n   - REC_VLR_CREDITO_TOTAL\n   - REC_VLR_CREDITO_MEDIO\n   - REC_VLR_CREDITO_MAXIMO\n   - REC_VLR_CREDITO_MINIMO\n   - REC_VLR_CREDITO_DESVPAD\n   ... e mais 92 colunas\n\nüìÅ BOOK_PAGAMENTO (154 colunas):\n   - PAG_QTD_PAGAMENTOS_TOTAL\n   - PAG_QTD_CONTRATOS_DISTINTOS\n   - PAG_QTD_FATURAS_DISTINTAS\n   - PAG_QTD_DIAS_COM_PAGAMENTO\n   - PAG_QTD_BANCOS_UTILIZADOS\n   - PAG_QTD_FORMAS_PAGAMENTO_DISTINTAS\n   - PAG_QTD_INSTITUICOES_DISTINTAS\n   - PAG_QTD_TIPOS_ATIVIDADE\n   - PAG_QTD_PARCELAS_DISTINTAS\n   - PAG_VLR_TOTAL_PAGAMENTO_FATURA\n   ... e mais 144 colunas\n\nüìÅ BOOK_FATURAMENTO (108 colunas):\n   - FAT_QTD_FATURAS_TOTAL\n   - FAT_QTD_FATURAS_UNICAS\n   - FAT_QTD_CONTRATOS\n   - FAT_QTD_PLATAFORMAS\n   - FAT_QTD_TIPOS_FATURAMENTO\n   - FAT_QTD_CICLOS_DISTINTOS\n   - FAT_QTD_OFERTAS_DISTINTAS\n   - FAT_VLR_FATURAMENTO_BRUTO_TOTAL\n   - FAT_VLR_FATURAMENTO_BRUTO_MEDIO\n   - FAT_VLR_FATURAMENTO_BRUTO_MAX\n   ... e mais 98 colunas\n\nüìÅ CONTROLE (1 colunas):\n   - DT_PROCESSAMENTO\n"
     ]
    }
   ],
   "execution_count": 9,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "b529bea8-d597-4af3-be7b-def86907b8c4"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# ESTAT√çSTICAS DAS VARI√ÅVEIS TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Estat√≠sticas das Vari√°veis TARGET (score_bureau_movel):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Identificar colunas target\n",
    "target_cols = [col for col in df_super_book.columns if 'TARGET_' in col or col in ['FPD', 'FLAG_INSTALACAO']]\n",
    "\n",
    "if target_cols:\n",
    "    df_super_book.select(target_cols).describe().show()\n",
    "    \n",
    "    # Distribui√ß√£o do FPD (First Payment Default)\n",
    "    print(\"\\nüìä Distribui√ß√£o do FPD (First Payment Default):\")\n",
    "    df_super_book.groupBy('FPD').count().orderBy('FPD').show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhuma coluna TARGET identificada\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 12,
       "statement_ids": [
        12
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:31.4633018Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:15:25.5770879Z",
       "execution_finish_time": "2026-01-15T00:15:29.223227Z",
       "parent_msg_id": "0b7a5871-1ec9-48ad-81d4-5c7a96cdda0e"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 12, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä Estat√≠sticas das Vari√°veis TARGET (score_bureau_movel):\n======================================================================\n+-------+------------------+-------------------+-----------------+-----------------+\n|summary|   FLAG_INSTALACAO|                FPD|  TARGET_SCORE_01|  TARGET_SCORE_02|\n+-------+------------------+-------------------+-----------------+-----------------+\n|  count|           3900378|            2696621|          1281087|          1289950|\n|   mean|0.6913742719295412|0.21272177291506666|586.9003986458375|627.5538416217682|\n| stddev|0.4619263390952239|0.40923255289268035|57.48067205746377|96.07561713749614|\n|    min|                 0|                  0|                0|                1|\n|    max|                 1|                  1|              778|              917|\n+-------+------------------+-------------------+-----------------+-----------------+\n\n\nüìä Distribui√ß√£o do FPD (First Payment Default):\n+----+-------+\n| FPD|  count|\n+----+-------+\n|NULL|1203757|\n|   0|2122991|\n|   1| 573630|\n+----+-------+\n\n"
     ]
    }
   ],
   "execution_count": 10,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "537da18a-730b-48f9-9849-095e713103a0"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# AN√ÅLISE DE COMPLETUDE (MISSING VALUES)\n",
    "# =============================================================================\n",
    "\n",
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "\n",
    "print(\"üìä An√°lise de Completude (% de valores n√£o nulos):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calcular completude por grupo de colunas\n",
    "total = df_super_book.count()\n",
    "\n",
    "completude_por_origem = {}\n",
    "\n",
    "for origem, colunas in colunas_por_origem.items():\n",
    "    if colunas and origem != 'CONTROLE':\n",
    "        # Calcular m√©dia de completude do grupo\n",
    "        completude_media = 0\n",
    "        for c in colunas:\n",
    "            try:\n",
    "                nao_nulos = df_super_book.filter(col(c).isNotNull()).count()\n",
    "                completude_media += (nao_nulos / total) * 100\n",
    "            except:\n",
    "                pass\n",
    "        completude_media = completude_media / len(colunas) if colunas else 0\n",
    "        completude_por_origem[origem] = completude_media\n",
    "        print(f\"   {origem}: {completude_media:.1f}% completo\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 13,
       "statement_ids": [
        13
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:31.6458763Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:15:29.2252027Z",
       "execution_finish_time": "2026-01-15T00:22:28.1931476Z",
       "parent_msg_id": "40402c92-48cf-4862-8e1f-5e30b7e1cd81"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 13, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä An√°lise de Completude (% de valores n√£o nulos):\n======================================================================\n   CADASTRO: 81.0% completo\n   TELCO: 34.9% completo\n   TARGET (SCORE_BUREAU): 33.0% completo\n   BOOK_RECARGA: 71.1% completo\n   BOOK_PAGAMENTO: 17.3% completo\n   BOOK_FATURAMENTO: 21.7% completo\n"
     ]
    }
   ],
   "execution_count": 11,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "e3eea21b-d90d-4772-aa55-961e7cf131bd"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# AMOSTRA DOS DADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìã Amostra dos dados (5 primeiros registros):\")\n",
    "\n",
    "# Selecionar algumas colunas representativas para visualiza√ß√£o\n",
    "colunas_amostra = ['NUM_CPF', 'SAFRA', 'PROD', 'FPD']\n",
    "\n",
    "# Adicionar algumas colunas de cada origem\n",
    "for origem, colunas in colunas_por_origem.items():\n",
    "    if colunas and origem not in ['CADASTRO', 'CONTROLE']:\n",
    "        colunas_amostra.extend(colunas[:2])  # 2 colunas de cada origem\n",
    "\n",
    "df_super_book.select(colunas_amostra[:15]).show(5, truncate=False)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 14,
       "statement_ids": [
        14
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:31.8432954Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:22:28.1955228Z",
       "execution_finish_time": "2026-01-15T00:22:29.1404781Z",
       "parent_msg_id": "1f19f10e-9865-4d38-b802-bd39344dc61b"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 14, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìã Amostra dos dados (5 primeiros registros):\n+-----------+------+----+----+------+------+---------------+---------------+----------------------+------------------------+------------------------+---------------------------+---------------------+----------------------+\n|NUM_CPF    |SAFRA |PROD|FPD |var_03|var_02|TARGET_SCORE_01|TARGET_SCORE_02|REC_QTD_RECARGAS_TOTAL|REC_QTD_LINHAS_DISTINTAS|PAG_QTD_PAGAMENTOS_TOTAL|PAG_QTD_CONTRATOS_DISTINTOS|FAT_QTD_FATURAS_TOTAL|FAT_QTD_FATURAS_UNICAS|\n+-----------+------+----+----+------+------+---------------+---------------+----------------------+------------------------+------------------------+---------------------------+---------------------+----------------------+\n|777N8ZTXWZZ|202502|CMV |0   |37    |NULL  |NULL           |NULL           |3                     |2                       |NULL                    |NULL                       |NULL                 |NULL                  |\n|777T8UZUYZZ|202412|CMV |0   |33    |NULL  |516            |549            |5                     |2                       |NULL                    |NULL                       |NULL                 |NULL                  |\n|777TNX8T9ZZ|202501|CMV |NULL|4     |NULL  |NULL           |NULL           |1                     |1                       |1                       |1                          |1                    |1                     |\n|777WZUW79TW|202501|CMV |0   |4     |NULL  |721            |741            |6                     |2                       |NULL                    |NULL                       |NULL                 |NULL                  |\n|777XNX9X77Y|202412|CMV |0   |37    |NULL  |NULL           |NULL           |2                     |1                       |NULL                    |NULL                       |NULL                 |NULL                  |\n+-----------+------+----+----+------+------+---------------+---------------+----------------------+------------------------+------------------------+---------------------------+---------------------+----------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "execution_count": 12,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "fdb2e36f-ff66-452e-bda4-1ad4fec91c31"
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SALVAMENTO NO LAKEHOUSE GOLD\n# =============================================================================\n\nprint(\"‚è≥ Salvando Super Book no Lakehouse Gold...\")\n\n# dynamic partition overwrite e incompativel com overwriteSchema;\n# como o consolidado faz overwrite total, usar static temporariamente\nspark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n\ndf_super_book.write \\\n    .format(\"delta\") \\\n    .mode(\"overwrite\") \\\n    .partitionBy(\"SAFRA\") \\\n    .option(\"overwriteSchema\", \"true\") \\\n    .save(PATH_OUTPUT)\n\nspark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n\nprint(f\"\\n‚úÖ Super Book salvo com sucesso!\")\nprint(f\"üìÅ Destino: {PATH_OUTPUT}\")",
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "aff73388-7660-4380-bcc2-acd1075120d1"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# VALIDA√á√ÉO DO SALVAMENTO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"‚è≥ Validando salvamento...\")\n",
    "\n",
    "# Recarregar e validar\n",
    "df_validacao = spark.read.format(\"delta\").load(PATH_OUTPUT)\n",
    "\n",
    "registros_salvos = df_validacao.count()\n",
    "colunas_salvas = len(df_validacao.columns)\n",
    "\n",
    "print(f\"\\n‚úÖ Valida√ß√£o conclu√≠da:\")\n",
    "print(f\"   - Registros salvos: {registros_salvos:,}\")\n",
    "print(f\"   - Colunas salvas: {colunas_salvas}\")\n",
    "print(f\"   - Match com gera√ß√£o: {'‚úÖ OK' if registros_salvos == total_registros else '‚ùå DIVERG√äNCIA'}\")\n",
    "\n",
    "# Listar parti√ß√µes\n",
    "print(f\"\\nüìÅ Parti√ß√µes (SAFRAs) dispon√≠veis:\")\n",
    "df_validacao.select('SAFRA').distinct().orderBy('SAFRA').show(20)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 16,
       "statement_ids": [
        16
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:32.1890325Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:23:07.610622Z",
       "execution_finish_time": "2026-01-15T00:23:15.9374472Z",
       "parent_msg_id": "8b6d91cd-3399-49be-8846-9dd731b05038"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 16, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚è≥ Validando salvamento...\n\n‚úÖ Valida√ß√£o conclu√≠da:\n   - Registros salvos: 3,900,378\n   - Colunas salvas: 468\n   - Match com gera√ß√£o: ‚úÖ OK\n\nüìÅ Parti√ß√µes (SAFRAs) dispon√≠veis:\n+------+\n| SAFRA|\n+------+\n|202410|\n|202411|\n|202412|\n|202501|\n|202502|\n|202503|\n+------+\n\n"
     ]
    }
   ],
   "execution_count": 14,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "cebf3519-b618-4fff-8fe4-1b906f54bce5"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# REGISTRO NA FEATURE STORE (METADADOS)\n",
    "# =============================================================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Metadados do Super Book\n",
    "metadata = {\n",
    "    \"nome\": \"super_book_clientes\",\n",
    "    \"schema\": \"feature_store\",\n",
    "    \"lakehouse\": \"Gold\",\n",
    "    \"granularidade\": \"NUM_CPF + SAFRA\",\n",
    "    \"total_registros\": registros_salvos,\n",
    "    \"total_colunas\": colunas_salvas,\n",
    "    \"particionamento\": \"SAFRA\",\n",
    "    \"fontes\": {\n",
    "        \"dados_cadastrais\": len(cols_cadastro),\n",
    "        \"telco\": len(cols_telco),\n",
    "        \"score_bureau_movel\": len(cols_score),\n",
    "        \"book_recarga_cmv\": len(cols_recarga) if HAS_BOOK_RECARGA else 0,\n",
    "        \"book_pagamento\": len(cols_pagamento) if HAS_BOOK_PAGAMENTO else 0,\n",
    "        \"book_faturamento\": len(cols_faturamento) if HAS_BOOK_FATURAMENTO else 0\n",
    "    },\n",
    "    \"variaveis_target\": target_cols,\n",
    "    \"dt_criacao\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "print(\"üìã Metadados do Super Book:\")\n",
    "print(\"=\" * 70)\n",
    "for key, value in metadata.items():\n",
    "    print(f\"   {key}: {value}\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 17,
       "statement_ids": [
        17
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:32.3406126Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:23:15.9397602Z",
       "execution_finish_time": "2026-01-15T00:23:16.2714844Z",
       "parent_msg_id": "9a0dea27-203a-42ef-8d34-ed12801e1872"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 17, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìã Metadados do Super Book:\n======================================================================\n   nome: super_book_clientes\n   schema: feature_store\n   lakehouse: Gold\n   granularidade: NUM_CPF + SAFRA\n   total_registros: 3900378\n   total_colunas: 468\n   particionamento: SAFRA\n   fontes: {'dados_cadastrais': 33, 'telco': 68, 'score_bureau_movel': 2, 'book_recarga_cmv': 102, 'book_pagamento': 154, 'book_faturamento': 108}\n   variaveis_target: ['FLAG_INSTALACAO', 'FPD', 'TARGET_SCORE_01', 'TARGET_SCORE_02']\n   dt_criacao: 2026-01-15T00:23:16.042225\n"
     ]
    }
   ],
   "execution_count": 15,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "b420b498-6ee1-44b0-98f7-7b358de30a5a"
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# LIMPEZA DE CACHE\n",
    "# =============================================================================\n",
    "\n",
    "df_super_book.unpersist()\n",
    "print(\"‚úÖ Cache liberado\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèÜ SUPER BOOK FINALIZADO COM SUCESSO!\")\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 18,
       "statement_ids": [
        18
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "25913bcf-a55d-42cd-92a0-be21e43bd2d6",
       "normalized_state": "finished",
       "queued_time": "2026-01-15T00:10:32.5129803Z",
       "session_start_time": null,
       "execution_start_time": "2026-01-15T00:23:16.273782Z",
       "execution_finish_time": "2026-01-15T00:23:16.6335324Z",
       "parent_msg_id": "66e1a7bc-e4ee-4e98-8bb9-577c6fef73fe"
      },
      "text/plain": "StatementMeta(, 25913bcf-a55d-42cd-92a0-be21e43bd2d6, 18, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Cache liberado\n\n======================================================================\nüèÜ SUPER BOOK FINALIZADO COM SUCESSO!\n======================================================================\n"
     ]
    }
   ],
   "execution_count": 16,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "15822f9f-83d7-40b1-b61b-90b27920509d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# üìñ Documenta√ß√£o do Book Cpnsolidado\n",
    "\n",
    "## Resumo\n",
    "\n",
    "| M√©trica | Valor |\n",
    "|---------|-------|\n",
    "| **Tabela** | `feature_store.clientes_consolidado` |\n",
    "| **Lakehouse** | Gold |\n",
    "| **Granularidade** | NUM_CPF + SAFRA |\n",
    "| **Particionamento** | SAFRA |\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura de Colunas por Origem\n",
    "\n",
    "### 1. üìã CADASTRO (dados_cadastrais)\n",
    "Dados cadastrais e perfil b√°sico do cliente.\n",
    "\n",
    "| Coluna | Tipo | Descri√ß√£o |\n",
    "|--------|------|----------|\n",
    "| NUM_CPF | string | CPF mascarado (chave) |\n",
    "| SAFRA | int | Per√≠odo YYYYMM (chave) |\n",
    "| FLAG_INSTALACAO | int | Flag de instala√ß√£o |\n",
    "| FPD | int | First Payment Default |\n",
    "| PROD | string | Produto (DTH, NET, CMV) |\n",
    "| STATUSRF | string | Status Receita Federal |\n",
    "| DATADENASCIMENTO | date | Data de nascimento |\n",
    "| var_02 a var_25 | diversos | Vari√°veis de perfil |\n",
    "| CEP_3_digitos | string | Regi√£o geogr√°fica |\n",
    "\n",
    "### 2. üì° TELCO (telco)\n",
    "Vari√°veis de comportamento de uso de telecomunica√ß√µes.\n",
    "\n",
    "| Coluna | Tipo | Descri√ß√£o |\n",
    "|--------|------|----------|\n",
    "| var_26 a var_93 | decimal | M√©tricas de uso e perfil telco |\n",
    "\n",
    "### 3. üéØ TARGET (score_bureau_movel)\n",
    "**Vari√°veis resposta para modelagem.**\n",
    "\n",
    "| Coluna | Tipo | Descri√ß√£o |\n",
    "|--------|------|----------|\n",
    "| TARGET_SCORE_01 | int | Score de bureau 1 |\n",
    "| TARGET_SCORE_02 | int | Score de bureau 2 |\n",
    "\n",
    "### 4. üí≥ BOOK_RECARGA (ass_recarga_cmv_nova)\n",
    "Vari√°veis derivadas de recargas (prefixo `REC_`).\n",
    "\n",
    "### 5. üí∞ BOOK_PAGAMENTO (book_recargas_pagamento)\n",
    "Vari√°veis derivadas de pagamentos (prefixo `PAG_`).\n",
    "\n",
    "### 6. üìÑ BOOK_FATURAMENTO (book_faturamento)\n",
    "Vari√°veis derivadas de faturamento (prefixo `FAT_`).\n",
    "\n",
    "---\n",
    "\n",
    "## Vari√°veis TARGET para Modelagem\n",
    "\n",
    "O Super Book inclui as seguintes vari√°veis resposta do `score_bureau_movel`:\n",
    "\n",
    "| Vari√°vel | Descri√ß√£o | Uso |\n",
    "|----------|-----------|-----|\n",
    "| **FPD** | First Payment Default | Target bin√°rio para inadimpl√™ncia |\n",
    "| **TARGET_SCORE_01** | Score de bureau 1 | Target cont√≠nuo/ordinal |\n",
    "| **TARGET_SCORE_02** | Score de bureau 2 | Target cont√≠nuo/ordinal |\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo de Uso\n",
    "\n",
    "```python\n",
    "# Carregar Super Book\n",
    "df = spark.read.format(\"delta\").load(\n",
    "    \"abfss://.../Tables/feature_store/clientes_consolidado\"\n",
    ")\n",
    "\n",
    "# Filtrar por SAFRA\n",
    "df_202401 = df.filter(df.SAFRA == 202401)\n",
    "\n",
    "# Separar features e target\n",
    "target_cols = ['FPD', 'TARGET_SCORE_01', 'TARGET_SCORE_02']\n",
    "feature_cols = [c for c in df.columns if c not in target_cols + ['NUM_CPF', 'SAFRA']]\n",
    "\n",
    "# Preparar para modelagem\n",
    "X = df_202401.select(feature_cols)\n",
    "y = df_202401.select('FPD')  # ou TARGET_SCORE_01/02\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Colunas Removidas\n",
    "\n",
    "As seguintes colunas foram **intencionalmente exclu√≠das**:\n",
    "\n",
    "| Coluna | Motivo |\n",
    "|--------|--------|\n",
    "| `_execution_id` | Metadado de pipeline |\n",
    "| `_data_inclusao` | Metadado de ingest√£o |\n",
    "| `_data_alteracao_silver` | Metadado de ETL |\n",
    "| `DT_PROCESSAMENTO` (dos books) | Evitar conflito |\n",
    "| Chaves duplicadas | Mantidas apenas da tabela base |\n",
    "\n",
    "---\n",
    "\n",
    "## Notas T√©cnicas\n",
    "\n",
    "1. **JOINs**: Todos LEFT JOIN para preservar base de dados_cadastrais\n",
    "2. **Particionamento**: Por SAFRA para otimiza√ß√£o de consultas\n",
    "3. **Formato**: Delta Lake (ACID, time travel, schema evolution)\n",
    "4. **Prefixos**: Colunas dos books t√™m prefixo para rastreabilidade\n",
    "5. **Compatibilidade**: Spark SQL 3.x no Microsoft Fabric\n",
    "\n",
    "---\n",
    "\n",
    "**Fim da Documenta√ß√£o**\n"
   ],
   "metadata": {},
   "id": "18fe4a84-1160-4832-9a8d-4beb64a03e7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synapse_pyspark",
   "display_name": "Synapse PySpark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "dependencies": {
   "lakehouse": {
    "known_lakehouses": [
     {
      "id": "6a7135c7-0d8d-4625-815d-c4c4a02e4ed4"
     },
     {
      "id": "5f8a4808-6f65-401b-a427-b0dd9d331b35"
     }
    ],
    "default_lakehouse": "6a7135c7-0d8d-4625-815d-c4c4a02e4ed4",
    "default_lakehouse_name": "Gold",
    "default_lakehouse_workspace_id": "febb8631-d5c0-43d8-bf08-5e89c8f2d17e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}